{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Initial Setup and Data Load"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\nimport os\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom scipy.stats import norm, skew\n\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\n#from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nimport category_encoders as ce\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import mean_squared_log_error\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox\n\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"PATH = \"../input/house-prices-advanced-regression-techniques/\"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv(f'{PATH}train.csv')#, index_col='Id')\ndf_test=pd.read_csv(f'{PATH}test.csv')#, index_col='Id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Y (target value) to Log, as stated at Kaggle Evaluation page"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# for the purpose of evaluation of current competition we transform target value\ndf_train.SalePrice = np.log1p(df_train.SalePrice)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Number of Training Examples = {}'.format(df_train.shape[0]))\nprint('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\nprint('Training X Shape = {}'.format(df_train.shape))\nprint('Training y Shape = {}\\n'.format(df_train['SalePrice'].shape[0]))\nprint('Test X Shape = {}'.format(df_test.shape))\nprint('Test y Shape = {}\\n'.format(df_test.shape[0]))\n#print(df_train.columns)\n#print(df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#print(df_train.info())\n#df_train.sample(3)\n#print(df_test.info())\n#df_test.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dealing with Outliers"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Deleting outliers\ndf_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n\n#Check the graphic again\nfig, ax = plt.subplots()\nax.scatter(df_train['GrLivArea'], df_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DataFrame concatination and Y separation"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def concat_df(train_data, test_data):\n    # Returns a concatenated df of training and test set on axis 0\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n\ndf_all = concat_df(df_train, df_test)\n\ndf_train.name = 'Training Set'\ndf_test.name = 'Test Set'\ndf_all.name = 'All Set' \n\ndfs = [df_train, df_test]\n\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#remember where to divide train and test\nntrain = df_train.shape[0]\nntest = df_test.shape[0]\n\n#Save the 'Id' column\ntrain_ID = df_train['Id']\ntest_ID = df_test['Id']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Dividing Target column (Y)\ny_train_full = df_train.SalePrice.values\ndf_all.drop(['SalePrice'], axis=1, inplace=True)\ndf_all.drop('Id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dealing with Missing Values"},{"metadata":{"scrolled":true},"cell_type":"markdown","source":"### Create columns to mark originally missed values"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mark_missing (df):\n    for col in df.columns:\n        if df_all[col].isnull().sum()>0:\n            df_all[col+'_missed']=df_all[col].isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mark_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"markdown","source":"### Replace Missing"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def display_missing(df):\n    for col in df.columns:\n        print(col, df[col].isnull().sum())\n    print('\\n')\n    \nfor df in dfs:\n    print(format(df.name))\n    display_missing(df)\n    \n    \n    \n#Check remaining missing values if any \ndef display_only_missing(df):\n    all_data_na = (df.isnull().sum() / len(df)) * 100\n    all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n    missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n    print(missing_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replace non-missing but \"NA\", \"None\", etc values by Data description"},{"metadata":{},"cell_type":"markdown","source":"##### Replace NA in Object columns, based on information from description"},{"metadata":{},"cell_type":"raw","source":"\"\"\"\nAlley: Type of alley access to property\n       NA \tNo alley access\nMasVnrType: Masonry veneer type\n       None\tNone\nBsmtQual: Evaluates the height of the basement\n       NA\tNo Basement\nBsmtCond: Evaluates the general condition of the basement\n       NA\tNo Basement\nBsmtExposure: Refers to walkout or garden level walls\n       No\tNo Exposure\n       NA\tNo Basement\nBsmtFinType1: Rating of basement finished area\n       NA\tNo Basement\nBsmtFinType2: Rating of basement finished area (if multiple types)\n       NA\tNo Basement\nCentralAir: Central air conditioning\n       N\tNo\nFireplaceQu: Fireplace quality\n       NA\tNo Fireplace\nGarageType: Garage location\n       NA\tNo Garage\nGarageFinish: Interior finish of the garage\n       NA\tNo Garage\nGarageQual: Garage quality\n       NA\tNo Garage\nGarageCond: Garage condition\n       NA\tNo Garage\nPavedDrive: Paved driveway\n       N\tDirt/Gravel\nPoolQC: Pool quality\n       NA\tNo Pool\nFence: Fence quality\n       NA\tNo Fence\nMiscFeature: Miscellaneous feature not covered in other categories\n       NA\tNone\n\"\"\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill NA values (not missed) with None - based on data description -  - for non-Numerical (object) Columns\nfor col in ('Alley','MasVnrType','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n            'BsmtFinType2','FireplaceQu','GarageType', 'GarageFinish', 'GarageQual', \n            'GarageCond','PoolQC','Fence','MiscFeature'):\n    df_all[col] = df_all[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Replace NA in Numerical columns, based on information from description"},{"metadata":{"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#fill NA numerical value with '0' - based on data description of correspondent Object columns - for Numerical Columns\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath','MasVnrArea'):\n    df_all[col] = df_all[col].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replacing real missing values"},{"metadata":{},"cell_type":"markdown","source":"We also have REAL missing values, that we can't just replace based on description that if missed - use 'None' or 0. Hence, we will work here"},{"metadata":{},"cell_type":"markdown","source":"#### Iteration 1 - replacing by logic and deduction of human"},{"metadata":{},"cell_type":"markdown","source":"##### Replace NA missing values by most often in column (only for columns with 2 and less NA values, where do not make sense to invest hugely into Analysis)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Fill missing value in corresponding columns with most frequent value in column\nfor col in ('Utilities','Functional','SaleType','KitchenQual','Exterior2nd','Exterior1st','Electrical'):\n    df_all[col].fillna(df_all[col].mode()[0], inplace=True)\n    \n# Functional : data description says NA means typical\n# BTW we just used df_all.Functional.mode() = use most frequent value (as 'Typ' is most frequent value)\n#df_all[\"Functional\"] = df_all[\"Functional\"].fillna(\"Typ\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dealing with missing values left"},{"metadata":{"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"##### Dealing with MSZoning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.MSZoning.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In MSZoning we have 4 missing values. \nWe can replace them either by most common in column, or I have decided just with 'None' object values"},{"metadata":{},"cell_type":"raw","source":"\"\"\"\"\nMSZoning: Identifies the general zoning classification of the sale.\n       A\tAgriculture\n       C\tCommercial\n       FV\tFloating Village Residential\n       I\tIndustrial\n       RH\tResidential High Density\n       RL\tResidential Low Density\n       RP\tResidential Low Density Park \n       RM\tResidential Medium Density\n\"\"\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all[\"MSZoning\"] = df_all[\"MSZoning\"].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Iteration 2 - replacing by machine learning","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"##### Dealing with LotFrontage"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['LotFrontage'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\ndf_all[\"LotFrontage\"] = df_all.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['LotFrontage'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_all.info()","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"##### Seems no missed values\nMissing Values = DONE"},{"metadata":{},"cell_type":"markdown","source":"# Pre-Evaluation - benchmarking before Feature Generation"},{"metadata":{},"cell_type":"markdown","source":"## Making Training, Validation, Test Dataset"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n# split Validational/Test set from Training set after Categorical Value Engeneering\n#X_test=df_all.iloc[ntrain:] # Test set\nX_train_full=df_all.iloc[:ntrain] # Train set","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#df_all.shape, y_train_full.shape, X_test.shape, X_train_full.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train.shape, X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting function (train/valid)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def quick_get_dumm(df):\n    X_train_full=df.iloc[:ntrain] # Full Train set\n#    X_test=df_all.iloc[ntrain:] # Test set\n    \n    # Creating train and validation sets\n    X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full, random_state=42)\n    return X_train, X_valid, y_train, y_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = quick_get_dumm(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_valid.shape, y_train.shape, y_valid.shape, X_train_full.shape, y_train_full.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m,X_train=X_train, X_valid=X_valid, y_train=y_train, y_valid=y_valid):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Experimenting with Random Forest"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"m_rf = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True, random_state=42)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Experimenting with Lasso"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lasso_score(X,y):\n    lasso = ElasticNet(random_state=1)\n    param = {'l1_ratio' : [0],\n             'alpha' : [0.017]}\n    lasso = GridSearchCV(lasso, param, cv=5, scoring='neg_mean_squared_error')\n    lasso.fit(X,y)\n    print('Lasso:', np.sqrt(lasso.best_score_*-1))\n    return lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"m_xgb = XGBRegressor(n_estimators=160, learning_rate=0.05, random_state=42)\n# using early_stop to find out where validation scores don't improve\n#m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n%time m_xgb.fit(X_train, y_train)\nprint_score(m_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dealing with missing"},{"metadata":{},"cell_type":"markdown","source":"We will try ML techniques to predict all real missing values. We'll see how it will improve accuracy"},{"metadata":{},"cell_type":"markdown","source":"##### Once again dealing with missed LotFrontage feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We created function to return NA values of feature/column back in place, \n# based on _missed column, we created to state what values was missed in original dataset\n\n# returning original NA values back\ndef return_original_na(df, feature):\n    df[feature].loc[df.index[df[feature+'_missed'] == True].tolist()]=np.nan\n    return df[feature]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Returning original NA values of MSZoning back in place\ndf_all['LotFrontage']=return_original_na(df_all, 'LotFrontage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filling_na_with_predictions(df, feature):\n    \"\"\"\n    df - DataFrame without target column y. Train+Test DataFrame (df_all)\n    feature - feature (column), containing real NA values we will fill\n\n    Assumption:\n    All other columns do not have NA values. In case of having we have to impute with some Statistical method (Median, etc)\n    We do not do it inside this function\n    \"\"\"\n\n    flag_object=0\n    \n    if df[feature].isnull().sum()>0:\n        ## Store Indexes of rows with NA values (we can just call \"_missed\" column with True values, to check those indexes as well)\n        ## Creating index based on NA values present in column\n        na_rows_idxs=df[df[feature].isnull()].index \n            ## Creating index based on NA values being present in original DF column\n            #na_rows_idxs=df.index[df[feature+'_missed'] == True].tolist()\n\n        ## For fitting and predictiong - convert DF to dummies DF, ready for ML\n        #df=pd.get_dummies(df)\n        ## If feature object we cant just dummy all, we shouldn't dummy feature column\n        df=pd.concat([ pd.Series(df[feature]), pd.get_dummies(df.drop([feature], axis=1)) ], axis=1)\n\n\n        ## Splitting DF to Feature_Train_X, Feature_Train_y, Feature_Predict_X:\n        ## Feature_Train_X = DF without NA values in \"feature_with_NA\"column\n        ## Feature_Train_y = target values that we have. All values in \"feature_with_NA\" except NA values\n        ## Feature_Predict_X = DF of correcponding to NA values in \"feature_with_NA\" without target vales (basically because they is equal to NA)\n        Feature_Train_X=df.drop(df[df[feature].isnull()].index).drop([feature], axis=1)\n        Feature_Train_y=df[feature].drop(df[df[feature].isnull()].index).values\n        Feature_Predict_X=df[df[feature].isnull()].drop([feature], axis=1)\n\n        ## If feature is NOT Numerical\n        ## Label encoding of y values in case it is not numerical\n        if is_string_dtype(df[feature]) or is_categorical_dtype(df[feature]):\n            flag_object=1\n            from sklearn.preprocessing import LabelEncoder\n            le = LabelEncoder()\n            le.fit(Feature_Train_y)\n            Feature_Train_y=le.transform(Feature_Train_y)\n             \n        ## Making predictions, what might be in NA fields based on Train DF\n        #m_xgb = XGBRegressor(n_estimators=160, learning_rate=0.05)\n        #m_xgb.fit(Feature_Train_X, Feature_Train_y)\n        lasso = ElasticNet(random_state=1)\n        param = {'l1_ratio' : [0],\n             'alpha' : [0.017]}\n        lasso = GridSearchCV(lasso, param, cv=5, scoring='neg_mean_squared_error')\n        lasso.fit(Feature_Train_X,Feature_Train_y)\n    \n        ## Creating (Predicting) values to impute NA\n        #fillna_values=m_xgb.predict(Feature_Predict_X)\n        fillna_values=lasso.predict(Feature_Predict_X)\n\n        ## If feature is NOT Numerical\n        ## Return Encoded values back to Object/Category if feature NOT numerical\n        if flag_object==1:\n            fillna_values=le.inverse_transform(np.around(fillna_values).astype(int))\n        \n        ## Replacing NA values with predicted Series of values\n        df[feature]=df[feature].fillna(pd.Series(index=na_rows_idxs,data=fillna_values))\n\n        ## Returning feature column without NA values    \n        return df[feature]\n    else:\n        print ('There were no NA values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['LotFrontage']=filling_na_with_predictions(df_all, \"LotFrontage\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(df):\n    # Split dataset for train-validation\n    X_train, X_valid, y_train, y_valid = quick_get_dumm(df)\n    \n    #Lasso\n    lasso_score(X_train, y_train)\n\n    #XGBoost\n    m_xgb.fit(X_train, y_train)\n    print('XGBoost')\n    print_score(m_xgb,X_train, X_valid, y_train, y_valid)\n\n    # Random Forest\n    m_rf.fit(X_train, y_train)\n    print('Random Forest')\n    print_score(m_rf,X_train, X_valid, y_train, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(df_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! As we can see in all 3 models scores improved using ML algorithms to replace missing values"},{"metadata":{},"cell_type":"markdown","source":"##### Once again dealing with missed MSZoning feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Returning original NA values of MSZoning back in place\ndf_all['MSZoning']=return_original_na(df_all, 'MSZoning')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_only_missing(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all[df_all['MSZoning'].isnull()].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['MSZoning']=filling_na_with_predictions(df_all, 'MSZoning')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['MSZoning'].loc[df_all.index[df_all['MSZoning'+'_missed'] == True].tolist()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see we had all 'RL' values for MSZoning column, but ML algorithms proposed to change it a little bit. Let's check score"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Dealing with Missing values we replaced with most common - now replacing them with ML predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"We will deal with next features\nUtilities         0.068517\nFunctional        0.068517\nSaleType          0.034258\nKitchenQual       0.034258\nExterior2nd       0.034258\nExterior1st       0.034258\nElectrical        0.034258"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('Utilities','Functional','SaleType','KitchenQual','Exterior2nd','Exterior1st','Electrical'):\n    print ('Filling with most common:\\n',df_all[col].loc[df_all.index[df_all[col+'_missed'] == True].tolist()])\n    df_all[col]=return_original_na(df_all, col)\n    df_all[col]=filling_na_with_predictions(df_all, col)\n    print ('Filling with predictions:\\n',df_all[col].loc[df_all.index[df_all[col+'_missed'] == True].tolist()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(df_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see - nothing in scores changed, so it was unnecessary step, possibly because these last features weren't important for models"},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fi[:50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoding"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deprecated, unnessesary\ndef select_encoding (df_all,encoding='onehot'):\n    if encoding=='label':\n        # Label Encoding\n        cols=[]\n        cols.extend(ordinal_features)\n        cols.extend(categorical_features)\n        cols.extend(df_all.select_dtypes(object).columns)\n        # process columns, apply LabelEncoder to categorical features\n        for c in cols:\n            if c in df_all.columns:\n                lbl = LabelEncoder() \n                lbl.fit(list(df_all[c].values)) \n                df_all[c] = lbl.transform(list(df_all[c].values))\n    if encoding=='binary':\n        # Binary Encoding\n        cols=[]\n        #cols.extend(ordinal_features)\n        cols.extend(categorical_features)\n        cols.extend(df_all.select_dtypes(object).columns)\n        # process columns, apply BinaryEncoder to categorical features\n        for c in cols:\n            if c in df_all.columns:\n                bnr = ce.binary.BinaryEncoder() \n                bnr.fit(list(df_all[c].values)) \n                df_all[c] = bnr.transform(list(df_all[c].values))\n    if encoding=='onehot':\n        df_all=pd.get_dummies(df_all)\n    return df_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def encoding_check_score(df):\n    X_train, X_valid, y_train, y_valid=quick_get_dumm(df)\n    # Lasso\n    print ('Lasso Score: ')\n    lasso_score(X_train, y_train)\n\n\"\"\"    # Random Forest\n    m_rf.fit(X_train, y_train)\n    print ('Random Forest Score: ')#; print_score(m_rf)\n    res = [rmse(m_rf.predict(X_train), y_train), rmse(m_rf.predict(X_valid), y_valid),\n                m_rf.score(X_train, y_train), m_rf.score(X_valid, y_valid)]\n    if hasattr(m_rf, 'oob_score_'): res.append(m_rf.oob_score_)\n    print(res)\n    \n    # XGBoost\n    m_xgb.fit(X_train, y_train)\n    print ('XGBoost Score: ')#; print_score(m_xgb)\n    res = [rmse(m_xgb.predict(X_train), y_train), rmse(m_xgb.predict(X_valid), y_valid),\n                m_xgb.score(X_train, y_train), m_xgb.score(X_valid, y_valid)]\n    #if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    \n    print(res)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def encoding_measure (df, feature):\n    enc=['ordinal','onehot','label','binary']#, 'BackwardDifferenceEncoder','HashingEncoder','HelmertEncoder','PolynomialEncoder']#'LeaveOneOutEncoder','TargetEncoder','WOEEncoder',\n    for encoding in enc:\n        if encoding=='ordinal':\n        # As Is encoding\n            df_ordinal=df.copy()\n            print (feature, 'Ordinal Encoding')\n            encoding_check_score(df_ordinal)\n        if encoding=='onehot':\n        # OneHot encoding\n            df_onehot=df.copy()\n            df_onehot[feature]=df_onehot[feature].astype(str)\n            df_onehot=pd.get_dummies(df_onehot)\n            print (feature, 'OneHot Encoding')\n            encoding_check_score(df_onehot)\n        if encoding=='label':\n        # Label Encoding\n            df_le=df.copy()\n            df_le[feature]=df_le[feature].astype(str)\n            lbl = LabelEncoder() \n            lbl.fit(list(df_le[feature].values)) \n            df_le[feature] = lbl.transform(list(df_le[feature].values))\n            print (feature, 'Label Encoding')\n            encoding_check_score(df_le)\n        if encoding=='binary':\n        # Binary Encoding\n            df_be=df.copy()\n            df_be[feature]=df_be[feature].astype(str)\n            bnr = ce.binary.BinaryEncoder() \n            bnr.fit(list(df_be[feature].values)) \n            df_be[feature] = bnr.transform(list(df_be[feature].values))\n            print (feature, 'Binary Encoding')\n            encoding_check_score(df_be)\n        if encoding=='LeaveOneOutEncoder':\n        # LeaveOneOutEncoder\n        #category_encoders.leave_one_out.LeaveOneOutEncoder\n            df_loo=df.copy()\n            df_loo[feature]=df_loo[feature].astype(str)\n            loo = ce.leave_one_out.LeaveOneOutEncoder() \n#            X_train_full=df_loo.iloc[:ntrain] # Train set\n            loo.fit(list(df_loo[feature].values),y_train_full) \n            df_loo[feature] = loo.transform(list(df_loo[feature].values))\n            print (feature, 'LeaveOneOutEncoder')\n            encoding_check_score(df_loo)\n        if encoding=='BackwardDifferenceEncoder':\n        # Backward Difference Coding\n        #category_encoders.backward_difference.BackwardDifferenceEncoder\n            df=df.copy()\n            df[feature]=df[feature].astype(str)\n            enc = ce.hashing.HashingEncoder() \n            enc.fit(list(df[feature].values)) \n            df[feature] = enc.transform(list(df[feature].values))\n            print (feature, encoding)\n            encoding_check_score(df)\n        if encoding=='HashingEncoder':\n        # Hashing\n        #category_encoders.hashing.HashingEncoder\n            df=df.copy()\n            df[feature]=df[feature].astype(str)\n            enc = ce.hashing.HashingEncoder() \n            enc.fit(list(df[feature].values)) \n            df[feature] = enc.transform(list(df[feature].values))\n            print (feature, encoding)\n            encoding_check_score(df)\n        if encoding=='HelmertEncoder':\n        # Helmert\n        #category_encoders.helmert.HelmertEncoder\n            df=df.copy()\n            df[feature]=df[feature].astype(str)\n            enc = ce.helmert.HelmertEncoder() \n            enc.fit(list(df[feature].values)) \n            df[feature] = enc.transform(list(df[feature].values))\n            print (feature, encoding)\n            encoding_check_score(df)        \n        if encoding=='PolynomialEncoder':\n        # Polinomial Coding\n        #category_encoders.polynomial.PolynomialEncoder\n            df=df.copy()\n            df[feature]=df[feature].astype(str)\n            enc = ce.polynomial.PolynomialEncoder() \n            enc.fit(list(df[feature].values)) \n            df[feature] = enc.transform(list(df[feature].values))\n            print (feature, encoding)\n            encoding_check_score(df)        \n        if encoding=='TargetEncoder':\n        # Target\n        #category_encoders.target_encoder.TargetEncoder\n            df=df.copy()\n            df[feature]=df[feature].astype(str)\n            enc = ce.target_encoder.TargetEncoder() \n#            X_train_full=df.iloc[:ntrain] # Train set\n            enc.fit(list(df[feature].values),y_train_full) \n            df[feature] = enc.transform(list(df[feature].values))\n            print (feature, encoding)\n            encoding_check_score(df)        \n        if encoding=='WOEEncoder':\n        #Weight of Evidence\n        #category_encoders.woe.WOEEncoder\n            df=df.copy()\n            df[feature]=df[feature].astype(str)\n            enc = ce.woe.WOEEncoder() \n            X_train_full=df.iloc[:ntrain] # Train set\n            enc.fit(list(X_train_full[feature].values),y_train_full) \n            df[feature] = enc.transform(list(df[feature].values))\n            print (feature, encoding, df.feature)\n#            encoding_check_score(df)\n        \n#        print ('\\n\\n')\n        #return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dealing with Ordinal values"},{"metadata":{},"cell_type":"markdown","source":"## Ordinal Data Encoding"},{"metadata":{},"cell_type":"markdown","source":"### Encoding quality columns with dictionary"},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\"\nEncode Quality columns with:\nEx\tExcellent\nGd\tGood\nTA\tAverage/Typical\nFa\tFair\nPo\tPoor\nNA\tNo \"Garage/Basement/Fireplace/...\"\n\nTo decode we use same Disctionary as used in other dataset columns:\nOverallCond: Rates the overall condition of the house\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\t\n       5\tAverage\n       4\tBelow Average\t\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\"\"\"\n\nqual_cleanup = {\"Ex\": 9, \"Gd\": 7, \"TA\": 5, \"Fa\": 3,\"Po\": 2, \"None\": 0}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\nfor col in ('ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual',\n            'FireplaceQu','GarageQual','GarageCond','PoolQC'):\n    df_all_tmp=df_all.copy()\n    df_all_tmp[col].replace(qual_cleanup, inplace=True)\n    df_all_tmp[col]=df_all_tmp[col].astype(float)\n    encoding_measure (df_all_tmp, feature=col)\n    print ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"onehot_features=[]\nonehot_features.append('KitchenQual')\nonehot_features.append('PoolQC')\nlabel_features=[]\nlabel_features.append('GarageQual')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"np.unique(df_all['BsmtCond'])"},{"metadata":{},"cell_type":"raw","source":"df_all.ExterQual"},{"metadata":{},"cell_type":"raw","source":"df_all['BsmtCond'].value_counts()"},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\"\nBsmtFinType1: Rating of basement finished area\nBsmtFinType2: Rating of basement finished area (if multiple types)\n       GLQ\tGood Living Quarters\n       ALQ\tAverage Living Quarters\n       BLQ\tBelow Average Living Quarters\t\n       Rec\tAverage Rec Room\n       LwQ\tLow Quality\n       Unf\tUnfinshed\n       NA\tNo Basement\n\"\"\"\n\nqual_cleanup = {\"GLQ\": 10, \"ALQ\": 8, \"BLQ\": 6, \"Rec\": 4, \"LwQ\": 3,\"Unf\": 2, \"None\": 0}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\nfor col in ('BsmtFinType1','BsmtFinType2'):\n    df_all_tmp=df_all.copy()\n    df_all_tmp[col].replace(qual_cleanup, inplace=True)\n    df_all_tmp[col]=df_all_tmp[col].astype(float)    \n    encoding_measure (df_all_tmp, feature=col)\n    print ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"label_features.append('BsmtFinType2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\nBsmtExposure: Refers to walkout or garden level walls\n       Gd\tGood Exposure\n       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n       Mn\tMimimum Exposure\n       No\tNo Exposure\n       NA\tNo Basement\n\"\"\"\nqual_cleanup = {\"Gd\": 10, \"Av\": 7, \"Mn\": 4, \"No\": 2, \"None\": 0}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\ndf_all_tmp=df_all.copy()\ndf_all_tmp['BsmtExposure'].replace(qual_cleanup, inplace=True)\ndf_all_tmp['BsmtExposure']=df_all_tmp['BsmtExposure'].astype(float)\nencoding_measure (df_all_tmp, feature='BsmtExposure')\nprint ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Working on Functional (seems decrease score, not used now)"},{"metadata":{},"cell_type":"raw","source":"np.unique(df_all['Functional'])"},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\"\nFunctional: Home functionality (Assume typical unless deductions are warranted)\n       Typ\tTypical Functionality\n       Min1\tMinor Deductions 1\n       Min2\tMinor Deductions 2\n       Mod\tModerate Deductions\n       Maj1\tMajor Deductions 1\n       Maj2\tMajor Deductions 2\n       Sev\tSeverely Damaged\n       Sal\tSalvage only\n\n\"\"\"\n\nqual_cleanup = {\"Typ\": 10, \"Min1\": 9, \"Min2\": 8, \"Mod\": 6, \"Maj1\": 4,\"Maj2\": 3, \"Sev\": 1, \"Sal\": 0}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\ndf_all_tmp=df_all.copy()\ndf_all_tmp['Functional'].replace(qual_cleanup, inplace=True)\ndf_all_tmp['Functional']=df_all_tmp['Functional'].astype(float)\nencoding_measure (df_all_tmp, feature='Functional')\nprint ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"df_all['Functional'].value_counts()"},{"metadata":{},"cell_type":"raw","source":"#### Working with Garage"},{"metadata":{},"cell_type":"raw","source":"np.unique(df_all['GarageFinish'])"},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\nGarageFinish: Interior finish of the garage\n\n       Fin\tFinished\n       RFn\tRough Finished\t\n       Unf\tUnfinished\n       NA\tNo Garage\n\"\"\"\n\nqual_cleanup = {\"Fin\": 10, \"RFn\": 7, \"Unf\": 4, \"None\": 0}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\ndf_all_tmp=df_all.copy()\ndf_all_tmp['GarageFinish'].replace(qual_cleanup, inplace=True)\ndf_all_tmp['GarageFinish']=df_all_tmp['GarageFinish'].astype(float)\nencoding_measure (df_all_tmp, feature='GarageFinish')\nprint ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"label_features.append('GarageFinish')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\nGarageType: Garage location\n\t\t\n       2Types\tMore than one type of garage\n       Attchd\tAttached to home\n       Basment\tBasement Garage\n       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n       CarPort\tCar Port\n       Detchd\tDetached from home\n       NA\tNo Garage\n\"\"\"\n\n\nqual_cleanup = {\"2Types\": 10, \"Attchd\": 8, \"Basment\": 6, \"BuiltIn\": 4, \"CarPort\": 3,\"Detchd\": 2, \"None\": 0}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\ndf_all_tmp=df_all.copy()\ndf_all_tmp['GarageType'].replace(qual_cleanup, inplace=True)\ndf_all_tmp['GarageType']=df_all_tmp['GarageType'].astype(float)\nencoding_measure (df_all_tmp, feature='GarageType')\nprint ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"label_features.append('GarageType')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dealing with BldgType"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['BldgType'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\nBldgType: Type of dwelling\n       1Fam\tSingle-family Detached\t\n       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n       Duplx\tDuplex\n       TwnhsE\tTownhouse End Unit\n       TwnhsI\tTownhouse Inside Unit\n\"\"\"\n\nqual_cleanup = {\"Twnhs\": 5, \"TwnhsE\": 4, \"Duplex\": 3, \"2fmCon\": 2, \"1Fam\": 1}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\ndf_all_tmp=df_all.copy()\ndf_all_tmp['BldgType'].replace(qual_cleanup, inplace=True)\ndf_all_tmp['BldgType']=df_all_tmp['BldgType'].astype(float)\nencoding_measure (df_all_tmp, feature='BldgType')\nprint ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dealing with HouseStyle"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['HouseStyle'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\"\nHouseStyle: Style of dwelling\n       1Story\tOne story\n       1.5Fin\tOne and one-half story: 2nd level finished\n       1.5Unf\tOne and one-half story: 2nd level unfinished\n       2Story\tTwo story\n       2.5Fin\tTwo and one-half story: 2nd level finished\n       2.5Unf\tTwo and one-half story: 2nd level unfinished\n       SFoyer\tSplit Foyer\n       SLvl\tSplit Level\n\"\"\"\nqual_cleanup = {\"SFoyer\":8,\"SLvl\":7,\"2.5Fin\":6,\"2.5Unf\": 5, \"2Story\": 4, \"1.5Fin\": 3, \"1.5Unf\": 2, \"1Story\": 1}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\ndf_all_tmp=df_all.copy()\ndf_all_tmp['HouseStyle'].replace(qual_cleanup, inplace=True)\ndf_all_tmp['HouseStyle']=df_all_tmp['HouseStyle'].astype(float)\nencoding_measure (df_all_tmp, feature='HouseStyle')\nprint ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dealing with Electrical"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Electrical'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"\"\nElectrical: Electrical system\n       SBrkr\tStandard Circuit Breakers & Romex\n       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n       Mix\tMixed\n\"\"\"\nqual_cleanup = {\"SBrkr\": 5, \"FuseA\": 4, \"FuseF\": 3, \"FuseP\": 2, \"Mix\": 1}\n\n# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\ndf_all_tmp=df_all.copy()\ndf_all_tmp['Electrical'].replace(qual_cleanup, inplace=True)\ndf_all_tmp['Electrical']=df_all_tmp['Electrical'].astype(float)\nencoding_measure (df_all_tmp, feature='Electrical')\nprint ('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Chosing encoding for ordinal data"},{"metadata":{"trusted":false},"cell_type":"code","source":"ordinal_features=[]\ncategorical_features=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"Ex\": 9, \"Gd\": 7, \"TA\": 5, \"Fa\": 3,\"Po\": 2, \"None\": 0}\n\n#Ordinal encoding\nfor col in ('ExterQual','ExterCond','BsmtQual','BsmtCond','KitchenQual',\n            'HeatingQC','FireplaceQu','GarageQual','GarageCond','PoolQC'):\n    ordinal_features.append(col)\n    df_all[col].replace(qual_cleanup, inplace=True)\n    df_all[col]=df_all[col].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"GLQ\": 10, \"ALQ\": 8, \"BLQ\": 6, \"Rec\": 4, \"LwQ\": 3,\"Unf\": 2, \"None\": 0}\n\nfor col in ('BsmtFinType1','BsmtFinType2'):\n    ordinal_features.append(col)\n    df_all[col].replace(qual_cleanup, inplace=True)\n    df_all[col]=df_all[col].astype(float)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"Gd\": 10, \"Av\": 7, \"Mn\": 4, \"No\": 2, \"None\": 0}\n\nordinal_features.append('BsmtExposure')\ndf_all['BsmtExposure'].replace(qual_cleanup, inplace=True)\ndf_all['BsmtExposure']=df_all['BsmtExposure'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"Typ\": 10, \"Min1\": 9, \"Min2\": 8, \"Mod\": 6, \"Maj1\": 4,\"Maj2\": 3, \"Sev\": 1, \"Sal\": 0}\n\nordinal_features.append('Functional')\ndf_all['Functional'].replace(qual_cleanup, inplace=True)\ndf_all['Functional']=df_all['Functional'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"Fin\": 10, \"RFn\": 7, \"Unf\": 4, \"None\": 0}\n\nordinal_features.append('GarageFinish')\ndf_all['GarageFinish'].replace(qual_cleanup, inplace=True)\ndf_all['GarageFinish']=df_all['GarageFinish'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"2Types\": 10, \"Attchd\": 8, \"Basment\": 6, \"BuiltIn\": 4, \"CarPort\": 3,\"Detchd\": 2, \"None\": 0}\n\nordinal_features.append('GarageType')\ndf_all['GarageType'].replace(qual_cleanup, inplace=True)\ndf_all['GarageType']=df_all['GarageFinish'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"SFoyer\":8,\"SLvl\":7,\"2.5Fin\":6,\"2.5Unf\": 5, \"2Story\": 4, \"1.5Fin\": 3, \"1.5Unf\": 2, \"1Story\": 1}\n\nordinal_features.append('HouseStyle')\ndf_all['HouseStyle'].replace(qual_cleanup, inplace=True)\ndf_all['HouseStyle']=df_all['HouseStyle'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Chosing Ordinal Encoding for Ordinal Data as most effective\nqual_cleanup = {\"SBrkr\": 5, \"FuseA\": 4, \"FuseF\": 3, \"FuseP\": 2, \"Mix\": 1}\n\nordinal_features.append('Electrical')\ndf_all['Electrical'].replace(qual_cleanup, inplace=True)\ndf_all['Electrical']=df_all['Electrical'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ordinal_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"categorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"label_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"onehot_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lbl = LabelEncoder() \nfor feature in label_features:\n    # Label Encoding\n#    df_all[feature]=df_all[feature].astype(str)  \n#    lbl.fit(list(df_all[feature].values)) \n#    df_all[feature] = lbl.fit_transform(list(df_all[feature].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.GarageQual","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dealing with Categorical values"},{"metadata":{"trusted":false},"cell_type":"code","source":"def show_object_columns(df):\n    for col in df:\n        if is_string_dtype(df[col]):\n            print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"show_object_columns(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"categorical_features=[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"#CentralAir\nCentralAir_cleanup = {\"Y\": 1, \"N\": 0}\n\ndf_all_tmp=df_all.copy()\ndf_all_tmp['CentralAir'].replace(CentralAir_cleanup, inplace=True)\n#categorical_features.append('CentralAir')\n#df_all['CentralAir']=df_all['CentralAir'].astype(str)\nencoding_measure (df_all_tmp, feature='CentralAir')"},{"metadata":{},"cell_type":"raw","source":"# Encoding CentralAir\nCentralAir_cleanup = {\"Y\": 1, \"N\": 0}\n\ncategorical_features.append('CentralAir')\ndf_all['CentralAir'].replace(CentralAir_cleanup, inplace=True)\ndf_all['CentralAir']=df_all['CentralAir'].astype(str)"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.MSSubClass.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Transforming some numerical variables that are really categorical\n\n# MSSubClass=The building class\n\"\"\"\nMSSubClass: Identifies the type of dwelling involved in the sale.\t\n        20\t1-STORY 1946 & NEWER ALL STYLES\n        30\t1-STORY 1945 & OLDER\n        40\t1-STORY W/FINISHED ATTIC ALL AGES\n        45\t1-1/2 STORY - UNFINISHED ALL AGES\n        50\t1-1/2 STORY FINISHED ALL AGES\n        60\t2-STORY 1946 & NEWER\n        70\t2-STORY 1945 & OLDER\n        75\t2-1/2 STORY ALL AGES\n        80\tSPLIT OR MULTI-LEVEL\n        85\tSPLIT FOYER\n        90\tDUPLEX - ALL STYLES AND AGES\n       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n       150\t1-1/2 STORY PUD - ALL AGES\n       160\t2-STORY PUD - 1946 & NEWER\n       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n\"\"\"\nencoding_measure (df_all, feature='MSSubClass')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['MSSubClass'] = df_all['MSSubClass'].astype(str)\ncategorical_features.append('MSSubClass')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.MSSubClass.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Changing OverallCond into a categorical variable\n\"\"\"\nOverallCond: Rates the overall condition of the house\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\t\n       5\tAverage\n       4\tBelow Average\t\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\"\"\"\nencoding_measure (df_all, feature='OverallCond')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"lblb_enc_features=[]"},{"metadata":{},"cell_type":"raw","source":"#df_all['OverallCond'] = df_all['OverallCond'].astype(str)\n#categorical_features.append('OverallCond')"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Changing OverallQual into a categorical variable\n\"\"\"\nOverallQual: Rates the overall material and finish of the house\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\n       5\tAverage\n       4\tBelow Average\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\"\"\"\nencoding_measure (df_all, feature='OverallQual')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"#df_all['OverallQual'] = df_all['OverallQual'].astype(str)\n#categorical_features.append('OverallQual')"},{"metadata":{"trusted":false},"cell_type":"code","source":"## still under question how to encode MoSold\n# Year and month sold are transformed into categorical features.\n#df_all['YrSold'] = df_all['YrSold'].astype(str)\n#df_all['MoSold'] = df_all['MoSold'].astype(str)\n#categorical_features.append('YrSold')\nencoding_measure (df_all, feature='YrSold')\n#categorical_features.append('MoSold')\nencoding_measure (df_all, feature='MoSold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all['YearBuilt']=df_all['YearBuilt'].astype(str)\n#categorical_features.append('YearBuilt')\nencoding_measure (df_all, feature='YearBuilt')\n\n#df_all['YearRemodAdd']=df_all['YearRemodAdd'].astype(str)\n#categorical_features.append('YearRemodAdd')\nencoding_measure (df_all, feature='YearRemodAdd')\n\n#df_all['GarageYrBlt']=df_all['GarageYrBlt'].astype(str)\n#categorical_features.append('GarageYrBlt')\nencoding_measure (df_all, feature='GarageYrBlt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.info(all)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"raw","source":"# convert object columns to categorical\ndef conv_obj_to_categories(df):\n    \"\"\"\n    Convert Object columns to Categorical\n    \"\"\"\n    for col in df:\n        if is_string_dtype(df[col]):\n            df[col]=df[col].astype('category')\n"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"#conv_obj_to_categories(df_all)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"def show_categorical_columns(df):\n    \"\"\"\n    Print only categorical columns Number, Name and Codes of unique values in corresponding column \n    \"\"\"\n    for col in df:\n        if is_categorical_dtype(df[col]):\n            print(sum(np.unique(df[col].cat.categories,return_counts=True)[1]), col ,df[col].cat.categories)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"show_categorical_columns(df_all)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"def unique_categories(df,n=float(\"inf\")):\n    \"\"\"\n    Print only categorical columns Names and Number of unique values in corresponding column \n    df - DataFrame\n    n - show only columns with less then N unique values, \n        as default - not show column if more than 10000 unique value - not pseudo categorical\n    \"\"\"\n    for col in df:\n        if is_categorical_dtype(df[col]):\n            if sum(np.unique(df[col].cat.categories,return_counts=True)[1])<n:\n                print(col, sum(np.unique(df[col].cat.categories,return_counts=True)[1]))"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"unique_categories(df_all)"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{},"cell_type":"markdown","source":"# Scewed data"},{"metadata":{"trusted":false},"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nskewness = df_all.select_dtypes(include=numerics).apply(lambda x: skew(x))\nskew_index = skewness[abs(skewness) >= 0.75].index\nskewness[skew_index].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"'''BoxCox Transform'''\nlam = 0.15\nfor column in skew_index:\n    df_all[column] = boxcox1p(df_all[column], lam)\n    #continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check numeric columns (if they are actually Categorical, like Year)"},{"metadata":{},"cell_type":"markdown","source":"### Experimenting - heavily convert NUMERICAL to CATEGORICAL"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"df_allcats=df_all.copy()"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"### Experimenting with Numerical Categories\ndef conv_num_cat (df):\n    for col in df:\n        if is_numeric_dtype(df[col]): \n            df[col]=df[col].astype('category')\n        else:\n            df.drop(columns=col, inplace=True)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"conv_num_cat(df_allcats)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"unique_categories(df_allcats,20)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"conv_to_cat_shortlist=['MSSubClass', 'MoSold','YrSold']#'OverallCond', 'OverallQual']"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"#for cat in conv_to_cat_longlist:\n#    df_all[cat]=df_all[cat].astype('category')\n\nfor cat in conv_to_cat_shortlist:\n    df_all[cat]=df_all[cat].astype('category')"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"#conv_to_cat_longlist=['BedroomAbvGr', 'BsmtFullBath','BsmtHalfBath', 'Fireplaces', 'FullBath',\\\n#             'GarageCars','HalfBath','KitchenAbvGr','MSSubClass','MoSold','OverallCond',\\\n#             'OverallQual','PoolArea','TotRmsAbvGrd','YrSold']"},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{},"cell_type":"markdown","source":"# using list of quntative and qualitative"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.select_dtypes(object).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ordinal_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"categorical_features","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Feature Importance Dropping"},{"metadata":{"hidden":true},"cell_type":"raw","source":"fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"fi[:20]"},{"metadata":{"hidden":true},"cell_type":"raw","source":"fi.tail(20)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"df_all = df_all.drop(['Utilities', 'Street', 'PoolQC',], axis=1)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"df_all = df_all.drop(['Utilities_missed','TotalBsmtSF_missed','SaleType_missed','MSZoning_missed',\n                      'KitchenQual_missed','GarageCars_missed','GarageArea_missed','Exterior2nd_missed',\n                     'Exterior1st_missed','BsmtFinSF2_missed','BsmtFullBath_missed','BsmtUnfSF_missed',\n                     'BsmtHalfBath_missed','Functional_missed'],  axis=1)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"df_all = df_all.drop(['Condition2','Heating','Exterior1st','BsmtFinSF1_missed','Foundation',\n                      'RoofMatl','Exterior2nd','Electrical_missed'],  axis=1)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"X_train.shape"},{"metadata":{"hidden":true},"cell_type":"raw","source":"fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"fi[:50]\n#fi.tail(50)"},{"metadata":{"hidden":true},"cell_type":"raw","source":"#df_all = df_all.drop(['Electrical','Heating','Exterior1st','BsmtFinSF1_missed','Foundation','RoofMatl','Exterior2nd','Electrical_missed'],  axis=1)"},{"metadata":{"hidden":true},"cell_type":"markdown","source":"### Finding which Features to Drop by function and visualisation"},{"metadata":{"hidden":true,"scrolled":true},"cell_type":"raw","source":"def find_features_to_drop(X_train, X_valid, y_train, y_valid):\n    \"\"\" Using RandomForest identifies important feature \n    and one by one drop least important features from DataFrame to improve model score\n    input - X_train, X_valid, y_train, y_valid, same as used in training and evaluation model using train/valid split\n    \"\"\"\n    m_feature_to_drop = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=False)\n    # to try - not use actual feature importance each iteration, but use only first one\n    #        m_feature_to_drop.fit(X_train, y_train)\n    #        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n    \n    # Number of features in DataFrame\n    num_of_features=X_train.shape[1]\n    \n    list_of_original_columns=X_train.columns\n    \n    best_grade=1\n    list_of_feature_to_drop=pd.DataFrame()\n    grades={}\n    \n    for iteration in range(0, num_of_features):\n            \n        # Iteratively fit model with features without 1 least important (dropped in previos iteration)\n        m_feature_to_drop.fit(X_train, y_train)\n        # Evaluating performance withot this feature\n        grade=math.sqrt(mean_squared_error(y_valid, m_feature_to_drop.predict(X_valid)))\n\n        # Updating based on new model list of feature importance\n        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n\n        # Finding best score\n        if grade<best_grade:\n            best_grade=grade\n            best_num_of_features=(num_of_features-iteration)\n            list_of_feature_to_drop=list_of_original_columns.difference(fi.feature)\n\n        # Dropping last 1 (least important feature)\n        X_train=X_train.drop(columns=fi.feature[-1:])\n        X_valid=X_valid.drop(columns=fi.feature[-1:])\n\n        print ((num_of_features-iteration),grade, fi.feature[-1:])\n        grades.update({(num_of_features-iteration):grade})\n    print(best_grade,best_num_of_features) \n    #return list_of_feature_to_drop\n    return grades"},{"metadata":{"hidden":true,"scrolled":true},"cell_type":"raw","source":"#features_to_drop=find_features_to_drop(X_train, X_valid, y_train, y_valid)"},{"metadata":{"hidden":true,"scrolled":true},"cell_type":"raw","source":"grades=find_features_to_drop(X_train, X_valid, y_train, y_valid)\n#features_to_drop\n#fi.feature==fi.feature"},{"metadata":{"hidden":true,"scrolled":true},"cell_type":"raw","source":"x=list(grades.keys())\ny=list(grades.values())\n\nax = plt.axes()\nplt.plot(x,y)\nplt.show()"},{"metadata":{"hidden":true,"scrolled":true},"cell_type":"raw","source":"\nax = plt.axes()\nplt.xlim(150,300)\nplt.ylim(0.10,0.145)\nplt.plot(x,y)\nplt.show()"},{"metadata":{"hidden":true,"scrolled":true},"cell_type":"raw","source":"df_all.shape"},{"metadata":{"hidden":true,"scrolled":true},"cell_type":"raw","source":"#df_all=df_all.drop(columns=features_to_drop)\n#df_all=df_all.drop(columns=fi.feature[150:])"},{"metadata":{},"cell_type":"markdown","source":"# Features generation"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Age_Build']=df_all['YrSold'].astype(int)-df_all['YearBuilt'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all.drop(['Age_Build'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Age_Remod']=df_all['YrSold'].astype(int)-df_all['YearRemodAdd'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all.drop(['Age_Remod'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Sizes_Total']=df_all['GrLivArea']+df_all['GarageCars']+df_all['GarageArea']+df_all['TotalBsmtSF']+df_all['1stFlrSF']+df_all['2ndFlrSF']+df_all['OpenPorchSF']+df_all['MasVnrArea']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"df_all['Quantity_Total']=df_all['Fireplaces']+df_all['FullBath']+df_all['KitchenAbvGr']+df_all['TotRmsAbvGrd']+df_all['BedroomAbvGr']+df_all['BsmtFullBath']\n"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all.drop(['Quantity_Total'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Garage_Age_Build']=df_all['YrSold'].astype(float)-df_all['GarageYrBlt'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['Garage_Age_Build'],axis=1,inplace=True)"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['YrBltAndRemod']=df_all['YearBuilt']+df_all['YearRemodAdd']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all.drop(['YrBltAndRemod'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['TotalSF']=df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Total_sqr_footage'] = (df_all['BsmtFinSF1'] + df_all['BsmtFinSF2'] +\n                                 df_all['1stFlrSF'] + df_all['2ndFlrSF'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['Total_sqr_footage'],axis=1,inplace=True)"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Total_Bathrooms'] = (df_all['FullBath'] + (0.5 * df_all['HalfBath']) +\n                               df_all['BsmtFullBath'] + (0.5 * df_all['BsmtHalfBath']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['Total_Bathrooms'],axis=1,inplace=True)"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Total_porch_sf'] = (df_all['OpenPorchSF'] + df_all['3SsnPorch'] +\n                              df_all['EnclosedPorch'] + df_all['ScreenPorch'] +\n                              df_all['WoodDeckSF'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"df_all['haspool'] = df_all['PoolArea'].apply(lambda x: 1 if x > 0 else 0)"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all.drop(['haspool'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['has2ndfloor'] = df_all['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['has2ndfloor'],axis=1,inplace=True)"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['hasgarage'] = df_all['GarageArea'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['hasgarage'],axis=1,inplace=True)"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['hasbsmt'] = df_all['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['hasbsmt'],axis=1,inplace=True)"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['hasfireplace'] = df_all['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all.drop(['hasfireplace'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all['Basement']=(df_all['TotalBsmtSF']+df_all['BsmtFinSF1']+df_all['BsmtFinSF2']-df_all['BsmtUnfSF'])*(df_all['BsmtQual']+df_all['BsmtCond'].astype(int)+df_all['BsmtFinType1']+df_all['BsmtExposure'].astype(int)+df_all['BsmtFinType2'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['Basement'],axis=1,inplace=True)"},{"metadata":{},"cell_type":"raw","source":"df_all['Garage']=(df_all['GarageArea'])*(df_all['GarageQual']+df_all['GarageCond']+df_all['GarageType'])*df_all['GarageCars']\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['Garage'],axis=1,inplace=True)"},{"metadata":{"trusted":false},"cell_type":"code","source":"#House=","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data examining"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.info(all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.select_dtypes(object).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Housing Crisis Data 2008-2009"},{"metadata":{},"cell_type":"markdown","source":"#### Shiller index Monthly"},{"metadata":{},"cell_type":"raw","source":"# Case-Shiller U.S. National Home Price Index (CSUSHPISA)\ncsi=pd.read_csv(f'{PATH}CSUSHPISA.csv')#, index_col='Id')"},{"metadata":{},"cell_type":"raw","source":"csi['DATE']=pd.to_datetime(csi['DATE'])"},{"metadata":{},"cell_type":"raw","source":"csi['YrSold']=csi.DATE.dt.year\ncsi['MoSold']=csi.DATE.dt.month\ncsi.drop(['DATE'],axis=1, inplace=True)"},{"metadata":{},"cell_type":"raw","source":"csi.head()"},{"metadata":{},"cell_type":"raw","source":"df_all=df_all.merge(csi, how='left')"},{"metadata":{},"cell_type":"raw","source":"df_all[['YrSold','MoSold','CSUSHPISA']].head()"},{"metadata":{},"cell_type":"raw","source":"encoding_measure (df_all, feature='CSUSHPISA')"},{"metadata":{},"cell_type":"raw","source":"#df_all['CSUSHPISA']=df_all['CSUSHPISA'].astype(str)\n#categorical_features.append('CSUSHPISA')"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{},"cell_type":"raw","source":"#df_all.drop(['CSUSHPISA'],axis=1,inplace=True)"},{"metadata":{},"cell_type":"raw","source":"#### HPI index Quarterly"},{"metadata":{},"cell_type":"raw","source":"# All-Transactions House Price Index for the United States\nhpi=pd.read_csv(f'{PATH}USSTHPI.csv')#, index_col='Id')"},{"metadata":{},"cell_type":"raw","source":"hpi['DATE']=pd.to_datetime(hpi['DATE'])"},{"metadata":{},"cell_type":"raw","source":"hpi['YrSold']=hpi.DATE.dt.year\nhpi['MoSold']=hpi.DATE.dt.month\nhpi.drop(['DATE'],axis=1, inplace=True)"},{"metadata":{},"cell_type":"raw","source":"hpi.head()"},{"metadata":{},"cell_type":"raw","source":"df_all=df_all.merge(hpi, how='left')"},{"metadata":{},"cell_type":"raw","source":"df_all[['YrSold','MoSold','USSTHPI']].head()"},{"metadata":{},"cell_type":"raw","source":"#df_all['USSTHPI']=df_all['USSTHPI'].astype(str)\n#categorical_features.append('USSTHPI')"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['USSTHPI'],axis=1, inplace=True)"},{"metadata":{},"cell_type":"raw","source":"#### Purchase Only House Price Index for the United States (Monthly)"},{"metadata":{},"cell_type":"raw","source":"# Purchase Only House Price Index for the United States (Monthly)\npi=pd.read_csv(f'{PATH}HPIPONM226S.csv')#, index_col='Id')"},{"metadata":{},"cell_type":"raw","source":"pi['DATE']=pd.to_datetime(pi['DATE'])"},{"metadata":{},"cell_type":"raw","source":"pi['YrSold']=pi.DATE.dt.year\npi['MoSold']=pi.DATE.dt.month\npi.drop(['DATE'],axis=1, inplace=True)"},{"metadata":{},"cell_type":"raw","source":"pi.head()"},{"metadata":{},"cell_type":"raw","source":"df_all=df_all.merge(pi, how='left')"},{"metadata":{},"cell_type":"raw","source":"df_all[['YrSold','MoSold','HPIPONM226S']].head()"},{"metadata":{},"cell_type":"raw","source":"#df_all['HPIPONM226S']=df_all['HPIPONM226S'].astype(str)\n#categorical_features.append('HPIPONM226S')"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{},"cell_type":"raw","source":"df_all.drop(['HPIPONM226S'],axis=1,inplace=True)"},{"metadata":{},"cell_type":"raw","source":"#### Case-Shiller 20-City Home Price Sales Pair Counts (Monthly)"},{"metadata":{},"cell_type":"raw","source":"# Case-Shiller 20-City Home Price Sales Pair Counts (Monthly)\nhsi=pd.read_csv(f'{PATH}SPCS20RPSNSA.csv')#, index_col='Id')"},{"metadata":{},"cell_type":"raw","source":"hsi['DATE']=pd.to_datetime(hsi['DATE'])"},{"metadata":{},"cell_type":"raw","source":"hsi['YrSold']=hsi.DATE.dt.year\nhsi['MoSold']=hsi.DATE.dt.month\nhsi.drop(['DATE'],axis=1, inplace=True)"},{"metadata":{},"cell_type":"raw","source":"hsi.head()"},{"metadata":{},"cell_type":"raw","source":"df_all=df_all.merge(hsi, how='left')"},{"metadata":{},"cell_type":"raw","source":"df_all[['YrSold','MoSold','SPCS20RPSNSA']].head()"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nm_rf.fit(X_train, y_train)\nprint_score(m_rf)\nm_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{},"cell_type":"raw","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)"},{"metadata":{},"cell_type":"raw","source":"#df_all.drop(['SPCS20RPSNSA'],axis=1,inplace=True)"},{"metadata":{},"cell_type":"raw","source":"#df_all['SPCS20RPSNSA']=df_all['SPCS20RPSNSA'].astype(str)\n#categorical_features.append('SPCS20RPSNSA')"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoding"},{"metadata":{},"cell_type":"raw","source":"def select_encoding (df_all,encoding='onehot'):\n    if encoding=='label':\n        # Label Encoding\n        cols=[]\n        cols.extend(ordinal_features)\n        cols.extend(categorical_features)\n        cols.extend(df_all.select_dtypes(object).columns)\n        # process columns, apply LabelEncoder to categorical features\n        for c in cols:\n            if c in df_all.columns:\n                lbl = LabelEncoder() \n                lbl.fit(list(df_all[c].values)) \n                df_all[c] = lbl.transform(list(df_all[c].values))\n    if encoding=='binary':\n        # Binary Encoding\n        cols=[]\n        #cols.extend(ordinal_features)\n        cols.extend(categorical_features)\n        cols.extend(df_all.select_dtypes(object).columns)\n        # process columns, apply BinaryEncoder to categorical features\n        for c in cols:\n            if c in df_all.columns:\n                bnr = ce.binary.BinaryEncoder() \n                bnr.fit(list(df_all[c].values)) \n                df_all[c] = bnr.transform(list(df_all[c].values))\n    if encoding=='onehot':\n        df_all=pd.get_dummies(df_all)\n    return df_all"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"df_all=select_encoding(df_all,'label')"},{"metadata":{},"cell_type":"markdown","source":"# Dummies"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all=pd.get_dummies(df_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_all.columns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n# split Validational/Test set from Training set after Categorical Value Engeneering\n#def original_train_test(df_all):\nX_test=df_all.iloc[ntrain:] # Test set\nX_train_full=df_all.iloc[:ntrain] # Train set","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"m_xgb.fit(X_train, y_train)\nprint_score(m_xgb)"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dropping low variance features"},{"metadata":{},"cell_type":"raw","source":"\"\"\"\"\nFeatures that have too low variance can negatively impact the model, so we need to remove them by the number of repetitive equal values. In this case, we used a threshold of 99.2% (not 0 or 1 values). Therefore, if any feature has more than 99.2% reps of 1 or 0 it will be excluded. When doing this,\n\"\"\""},{"metadata":{"trusted":false},"cell_type":"code","source":"# Saving all features for future comparison.\nall_features = df_all.keys()\n# Removing features.\ndf_all = df_all.drop(df_all.loc[:,(df_all==0).sum()>=(df_all.shape[0]*0.992)],axis=1)\ndf_all = df_all.drop(df_all.loc[:,(df_all==1).sum()>=(df_all.shape[0]*0.992)],axis=1) \n# Getting and printing the remaining features.\nremain_features = df_all.keys()\nremov_features = [st for st in all_features if st not in remain_features]\nprint(len(remov_features), 'features were removed:', remov_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalization"},{"metadata":{"scrolled":true},"cell_type":"raw","source":"#Normalization, the Sigmoid, Log, Cube Root and the Hyperbolic Tangent. \n#It all depends on what one is trying to accomplish."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import preprocessing\n\nscaler = preprocessing.RobustScaler()\ndf_all = pd.DataFrame(scaler.fit_transform(df_all))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\nlasso_score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning"},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_all = df_all.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove all ,[] symbols from dataframe columns and values\n#df_all.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df_all.columns.values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n# split Validational/Test set from Training set after Categorical Value Engeneering\n#def original_train_test(df_all):\nX_test=df_all.iloc[ntrain:] # Test set\nX_train_full=df_all.iloc[:ntrain] # Train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"m_xgb.fit(X_train, y_train)\nprint_score(m_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def cv_train():\n    lasso = ElasticNet(random_state=1)\n    param = {'l1_ratio' : [0],\n             'alpha' : [0.017]}\n    lasso = GridSearchCV(lasso, param, cv=5, scoring='neg_mean_squared_error')\n    lasso.fit(X_train_full, y_train_full)\n    print('Lasso:', np.sqrt(lasso.best_score_*-1))\n    return lasso\nlasso = cv_train()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions for submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred=np.expm1(lasso.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = y_pred\nsub.to_csv('submittions/submission_31Aug19.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacking"},{"metadata":{},"cell_type":"raw","source":"X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape"},{"metadata":{},"cell_type":"raw","source":"m_lasso_1 = ElasticNet(random_state=1, alpha=0.017)\nm_lasso_1.fit(X_train, y_train)"},{"metadata":{},"cell_type":"raw","source":"m_lasso_2 = ElasticNet(random_state=1, alpha=0.017)\nm_lasso_2.fit(X_train, y_train)"},{"metadata":{},"cell_type":"raw","source":"preds_lasso_1=m_lasso_1.predict(X_valid)\npreds_lasso_2=m_lasso_2.predict(X_valid)\n\ntest_preds_lasso_1=m_lasso_1.predict(X_test)\ntest_preds_lasso_2=m_lasso_2.predict(X_test)"},{"metadata":{},"cell_type":"raw","source":"stacked_predictions=np.column_stack((preds_lasso_1,preds_lasso_2))\nstacked_test_predictions=np.column_stack((test_preds_lasso_1,test_preds_lasso_2))"},{"metadata":{},"cell_type":"raw","source":"meta_model=ElasticNet(random_state=1, alpha=0.017)"},{"metadata":{},"cell_type":"raw","source":"meta_model.fit(stacked_predictions,y_valid)"},{"metadata":{},"cell_type":"raw","source":"# testing of very simple stacking\ny_pred = np.expm1(meta_model.predict(stacked_test_predictions))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}