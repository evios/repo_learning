{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup and Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"../../../data/house_pricing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(f'{PATH}train.csv')#, index_col='Id')\n",
    "df_test=pd.read_csv(f'{PATH}test.csv')#, index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y (target value) to Log, as stated at Kaggle Evaluation page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for the purpose of evaluation of current competition\n",
    "#df_train.SalePrice = np.log1p(df_train.SalePrice)\n",
    "df_train.SalePrice = np.log1p(df_train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['SalePrice'].shape[0]))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "#print(df_train.columns)\n",
    "#print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df_train.info())\n",
    "#df_train.sample(3)\n",
    "#print(df_test.info())\n",
    "#df_test.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting outliers\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n",
    "\n",
    "#Check the graphic again\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_train['GrLivArea'], df_train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame concatination and Y separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set on axis 0\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remember where to divide train and test\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = df_train['Id']\n",
    "test_ID = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dividing Target column (Y)\n",
    "y_train_full = df_train.SalePrice.values\n",
    "df_all.drop(['SalePrice'], axis=1, inplace=True)\n",
    "df_all.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Create columns to mark originally missed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_missing (df):\n",
    "    for col in df.columns:\n",
    "        if df_all[col].isnull().sum()>0:\n",
    "            df_all[col+'_missed']=df_all[col].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Replace Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_missing(df):\n",
    "    for col in df.columns:\n",
    "        print(col, df[col].isnull().sum())\n",
    "    print('\\n')\n",
    "    \n",
    "for df in dfs:\n",
    "    print(format(df.name))\n",
    "    display_missing(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Check remaining missing values if any \n",
    "def display_only_missing(df):\n",
    "    all_data_na = (df.isnull().sum() / len(df)) * 100\n",
    "    all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "    print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace non-missing but \"NA\", \"None\", etc values by Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace NA in Object columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Alley: Type of alley access to property\n",
    "       NA \tNo alley access\n",
    "MasVnrType: Masonry veneer type\n",
    "       None\tNone\n",
    "BsmtQual: Evaluates the height of the basement\n",
    "       NA\tNo Basement\n",
    "BsmtCond: Evaluates the general condition of the basement\n",
    "       NA\tNo Basement\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "BsmtFinType1: Rating of basement finished area\n",
    "       NA\tNo Basement\n",
    "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "       NA\tNo Basement\n",
    "CentralAir: Central air conditioning\n",
    "       N\tNo\n",
    "FireplaceQu: Fireplace quality\n",
    "       NA\tNo Fireplace\n",
    "GarageType: Garage location\n",
    "       NA\tNo Garage\n",
    "GarageFinish: Interior finish of the garage\n",
    "       NA\tNo Garage\n",
    "GarageQual: Garage quality\n",
    "       NA\tNo Garage\n",
    "GarageCond: Garage condition\n",
    "       NA\tNo Garage\n",
    "PavedDrive: Paved driveway\n",
    "       N\tDirt/Gravel\n",
    "PoolQC: Pool quality\n",
    "       NA\tNo Pool\n",
    "Fence: Fence quality\n",
    "       NA\tNo Fence\n",
    "MiscFeature: Miscellaneous feature not covered in other categories\n",
    "       NA\tNone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values (not missed) with None - based on data description -  - for non-Numerical (object) Columns\n",
    "for col in ('Alley','MasVnrType','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "            'BsmtFinType2','FireplaceQu','GarageType', 'GarageFinish', 'GarageQual', \n",
    "            'GarageCond','PoolQC','Fence','MiscFeature'):\n",
    "    df_all[col] = df_all[col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace NA in Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fill NA numerical value with '0' - based on data description of correspondent Object columns - for Numerical Columns\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath','MasVnrArea'):\n",
    "    df_all[col] = df_all[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace NA missing values by most often in column (only for columns with 2 and less NA values, where do not make sense to invest hugely into Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill missing value in corresponding columns with most frequent value in column\n",
    "for col in ('Utilities','Functional','SaleType','KitchenQual','Exterior2nd','Exterior1st','Electrical'):\n",
    "    df_all[col].fillna(df_all[col].mode()[0], inplace=True)\n",
    "    \n",
    "# Functional : data description says NA means typical\n",
    "# BTW we just used df_all.Functional.mode() = use most frequent value (as 'Typ' is most frequent value)\n",
    "#df_all[\"Functional\"] = df_all[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing real missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with missing values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with MSZoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.MSZoning.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\"\n",
    "! To reconsider MSZoning - we can specify \"None\" or something like this\n",
    "Also we can try to use most frequent value (as we can se only 4 NA values)\n",
    "MSZoning: Identifies the general zoning classification of the sale.\n",
    "       A\tAgriculture\n",
    "       C\tCommercial\n",
    "       FV\tFloating Village Residential\n",
    "       I\tIndustrial\n",
    "       RH\tResidential High Density\n",
    "       RL\tResidential Low Density\n",
    "       RP\tResidential Low Density Park \n",
    "       RM\tResidential Medium Density\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"MSZoning\"] = df_all[\"MSZoning\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_na_with_predictions(df, feature):\n",
    "    \"\"\"\n",
    "    df - DataFrame without target column y. Train+Test DataFrame (df_all)\n",
    "    feature - feature (column), containing real NA values we will fill\n",
    "\n",
    "    Assumption:\n",
    "    All other columns do not have NA values. In case of having we have to impute with some Statistical method (Median, etc)\n",
    "    We do not do it inside this function\n",
    "    \"\"\"\n",
    "\n",
    "    flag_object=0\n",
    "    \n",
    "    if df[feature].isnull().sum()>0:\n",
    "        ## Store Indexes of rows with NA values (we can just call \"_missed\" column with True values, to check those indexes as well)\n",
    "        ## Creating index based on NA values present in column\n",
    "        na_rows_idxs=df[df[feature].isnull()].index \n",
    "            ## Creating index based on NA values being present in original DF column\n",
    "            #na_rows_idxs=df.index[df[feature+'_missed'] == True].tolist()\n",
    "\n",
    "        ## For fitting and predictiong - convert DF to dummies DF, ready for ML\n",
    "        #df=pd.get_dummies(df)\n",
    "        ## If feature object we cant just dummy all, we shouldn't dummy feature column\n",
    "        df=pd.concat([ pd.Series(df[feature]), pd.get_dummies(df.drop([feature], axis=1)) ], axis=1)\n",
    "\n",
    "\n",
    "        ## Splitting DF to Feature_Train_X, Feature_Train_y, Feature_Predict_X:\n",
    "        ## Feature_Train_X = DF without NA values in \"feature_with_NA\"column\n",
    "        ## Feature_Train_y = target values that we have. All values in \"feature_with_NA\" except NA values\n",
    "        ## Feature_Predict_X = DF of correcponding to NA values in \"feature_with_NA\" without target vales (basically because they is equal to NA)\n",
    "        Feature_Train_X=df.drop(df[df[feature].isnull()].index).drop([feature], axis=1)\n",
    "        Feature_Train_y=df[feature].drop(df[df[feature].isnull()].index).values\n",
    "        Feature_Predict_X=df[df[feature].isnull()].drop([feature], axis=1)\n",
    "\n",
    "        ## If feature is NOT Numerical\n",
    "        ## Label encoding of y values in case it is not numerical\n",
    "        if is_string_dtype(df[feature]) or is_categorical_dtype(df[feature]):\n",
    "            flag_object=1\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            le.fit(Feature_Train_y)\n",
    "            Feature_Train_y=le.transform(Feature_Train_y)\n",
    "             \n",
    "        ## Making predictions, what might be in NA fields based on Train DF\n",
    "        m_xgb = XGBRegressor(n_estimators=160, learning_rate=0.05)\n",
    "        m_xgb.fit(Feature_Train_X, Feature_Train_y)\n",
    "    \n",
    "        ## Creating (Predicting) values to impute NA\n",
    "        fillna_values=m_xgb.predict(Feature_Predict_X)\n",
    "\n",
    "        ## If feature is NOT Numerical\n",
    "        ## Return Encoded values back to Object/Category if feature NOT numerical\n",
    "        if flag_object==1:\n",
    "            fillna_values=le.inverse_transform(np.around(fillna_values).astype(int))\n",
    "        \n",
    "        ## Replacing NA values with predicted Series of values\n",
    "        df[feature]=df[feature].fillna(pd.Series(index=na_rows_idxs,data=fillna_values))\n",
    "\n",
    "        ## Returning feature column without NA values    \n",
    "        return df[feature]\n",
    "    else:\n",
    "        print ('There were no NA values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['LotFrontage']=filling_na_with_predictions(df_all, \"LotFrontage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Once again dealing with missed MSZoning values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returning original NA back\n",
    "\n",
    "def return_original_na(df, feature):\n",
    "    df[feature].loc[df.index[df[feature+'_missed'] == True].tolist()]=np.nan\n",
    "    return df[feature]\n",
    "    \n",
    "df_all['MSZoning']=return_original_na(df_all, 'MSZoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['MSZoning'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MSZoning']=filling_na_with_predictions(df_all, 'MSZoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MSZoning'].loc[df_all.index[df_all['MSZoning'+'_missed'] == True].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with Missing values we replaced with most common - now replacing them with predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Utilities         0.068517\n",
    "Functional        0.068517\n",
    "SaleType          0.034258\n",
    "KitchenQual       0.034258\n",
    "Exterior2nd       0.034258\n",
    "Exterior1st       0.034258\n",
    "Electrical        0.034258"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for col in ('Utilities','Functional','SaleType','KitchenQual','Exterior2nd','Exterior1st','Electrical'):\n",
    "    print ('Filling with most common:\\n',df_all[col].loc[df_all.index[df_all[col+'_missed'] == True].tolist()])\n",
    "    df_all[col]=return_original_na(df_all, col)\n",
    "    df_all[col]=filling_na_with_predictions(df_all, col)\n",
    "    print ('Filling with predictions:\\n',df_all[col].loc[df_all.index[df_all[col+'_missed'] == True].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Seems no missed values\n",
    "Missing Values = DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Evaluation - benchmarking before Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Training, Validation, Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n",
    "# split Validational/Test set from Training set after Categorical Value Engeneering\n",
    "#def original_train_test(df_all):\n",
    "#X_test=df_all.iloc[ntrain:] # Test set\n",
    "X_train_full=df_all.iloc[:ntrain] # Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all.shape, y_train_full.shape, X_test.shape, X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting function (train/valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_get_dumm(df):\n",
    "    X_train_full=df.iloc[:ntrain] # Full Train set\n",
    "#    X_test=df_all.iloc[ntrain:] # Test set\n",
    "    \n",
    "    # Creating train and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full, random_state=42)\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = quick_get_dumm(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape, X_train_full.shape, y_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_rf = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True, random_state=42)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_xgb = XGBRegressor(n_estimators=160, learning_rate=0.05, random_state=42)\n",
    "# using early_stop to find out where validation scores don't improve\n",
    "#m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "%time m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated, unnessesary\n",
    "def select_encoding (df_all,encoding='onehot'):\n",
    "    if encoding=='label':\n",
    "        # Label Encoding\n",
    "        cols=[]\n",
    "        cols.extend(ordinal_features)\n",
    "        cols.extend(categorical_features)\n",
    "        cols.extend(df_all.select_dtypes(object).columns)\n",
    "        # process columns, apply LabelEncoder to categorical features\n",
    "        for c in cols:\n",
    "            if c in df_all.columns:\n",
    "                lbl = LabelEncoder() \n",
    "                lbl.fit(list(df_all[c].values)) \n",
    "                df_all[c] = lbl.transform(list(df_all[c].values))\n",
    "    if encoding=='binary':\n",
    "        # Binary Encoding\n",
    "        cols=[]\n",
    "        #cols.extend(ordinal_features)\n",
    "        cols.extend(categorical_features)\n",
    "        cols.extend(df_all.select_dtypes(object).columns)\n",
    "        # process columns, apply BinaryEncoder to categorical features\n",
    "        for c in cols:\n",
    "            if c in df_all.columns:\n",
    "                bnr = ce.binary.BinaryEncoder() \n",
    "                bnr.fit(list(df_all[c].values)) \n",
    "                df_all[c] = bnr.transform(list(df_all[c].values))\n",
    "    if encoding=='onehot':\n",
    "        df_all=pd.get_dummies(df_all)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_check_score(df):\n",
    "    X_train, X_valid, y_train, y_valid=quick_get_dumm(df)\n",
    "    # Random Forest\n",
    "    m_rf.fit(X_train, y_train)\n",
    "    print ('Random Forest Score: ')#; print_score(m_rf)\n",
    "    res = [rmse(m_rf.predict(X_train), y_train), rmse(m_rf.predict(X_valid), y_valid),\n",
    "                m_rf.score(X_train, y_train), m_rf.score(X_valid, y_valid)]\n",
    "    if hasattr(m_rf, 'oob_score_'): res.append(m_rf.oob_score_)\n",
    "    print(res)\n",
    "    \n",
    "    # XGBoost\n",
    "    m_xgb.fit(X_train, y_train)\n",
    "    print ('XGBoost Score: ')#; print_score(m_xgb)\n",
    "    res = [rmse(m_xgb.predict(X_train), y_train), rmse(m_xgb.predict(X_valid), y_valid),\n",
    "                m_xgb.score(X_train, y_train), m_xgb.score(X_valid, y_valid)]\n",
    "    #if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_measure (df, feature):\n",
    "    enc=['ordinal','onehot','label','binary']\n",
    "    for encoding in enc:\n",
    "        if encoding=='ordinal':\n",
    "        # As Is encoding\n",
    "            df_ordinal=df.copy()\n",
    "            print (feature, 'Ordinal Encoding')\n",
    "            encoding_check_score(df_ordinal)\n",
    "        if encoding=='onehot':\n",
    "        # OneHot encoding\n",
    "            df_onehot=df.copy()\n",
    "            df_onehot[feature]=df_onehot[feature].astype(str)\n",
    "            df_onehot=pd.get_dummies(df_onehot)\n",
    "            print (feature, 'OneHot Encoding')\n",
    "            encoding_check_score(df_onehot)\n",
    "        if encoding=='label':\n",
    "        # Label Encoding\n",
    "            df_le=df.copy()\n",
    "            df_le[feature]=df_le[feature].astype(str)\n",
    "            lbl = LabelEncoder() \n",
    "            lbl.fit(list(df_le[feature].values)) \n",
    "            df_le[feature] = lbl.transform(list(df_le[feature].values))\n",
    "            print (feature, 'Label Encoding')\n",
    "            encoding_check_score(df_le)\n",
    "        if encoding=='binary':\n",
    "        # Binary Encoding\n",
    "            df_be=df.copy()\n",
    "            df_be[feature]=df_be[feature].astype(str)\n",
    "            bnr = ce.binary.BinaryEncoder() \n",
    "            bnr.fit(list(df_be[feature].values)) \n",
    "            df_be[feature] = bnr.transform(list(df_be[feature].values))\n",
    "            print (feature, 'Binary Encoding')\n",
    "            encoding_check_score(df_be)\n",
    "        print ('\\n\\n')\n",
    "        #return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Ordinal values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding quality columns with dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Encode Quality columns with:\n",
    "Ex\tExcellent\n",
    "Gd\tGood\n",
    "TA\tAverage/Typical\n",
    "Fa\tFair\n",
    "Po\tPoor\n",
    "NA\tNo \"Garage/Basement/Fireplace/...\"\n",
    "\n",
    "To decode we use same Disctionary as used in other dataset columns:\n",
    "OverallCond: Rates the overall condition of the house\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\t\n",
    "       5\tAverage\n",
    "       4\tBelow Average\t\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "\"\"\"\n",
    "\n",
    "qual_cleanup = {\"Ex\": 9, \"Gd\": 7, \"TA\": 5, \"Fa\": 3,\"Po\": 2, \"None\": 0}\n",
    "\n",
    "# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\n",
    "for col in ('ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual',\n",
    "            'FireplaceQu','GarageQual','GarageCond','PoolQC'):\n",
    "    df_all_tmp=df_all.copy()\n",
    "    df_all_tmp[col].replace(qual_cleanup, inplace=True)\n",
    "    ordinal_features.append(col)\n",
    "    df_all_tmp[col]=df_all_tmp[col].astype(float)\n",
    "    encoding_measure (df_all_tmp, feature=col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing Ordinal Encoding for Ordinal Data as most effective\n",
    "for col in ('ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual',\n",
    "            'FireplaceQu','GarageQual','GarageCond','PoolQC'):\n",
    "    df_all[col].replace(qual_cleanup, inplace=True)\n",
    "    df_all[col]=df_all[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_all['BsmtCond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['BsmtCond'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "BsmtFinType1: Rating of basement finished area\n",
    "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\"\"\"\n",
    "\n",
    "qual_cleanup = {\"GLQ\": 10, \"ALQ\": 8, \"BLQ\": 6, \"Rec\": 4, \"LwQ\": 3,\"Unf\": 2, \"None\": 0}\n",
    "\n",
    "# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\n",
    "for col in ('BsmtFinType1','BsmtFinType2'):\n",
    "    df_all_tmp=df_all.copy()\n",
    "    df_all_tmp[col].replace(qual_cleanup, inplace=True)\n",
    "    ordinal_features.append(col)\n",
    "    df_all_tmp[col]=df_all_tmp[col].astype(float)    \n",
    "    encoding_measure (df_all_tmp, feature=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing Ordinal Encoding for Ordinal Data as most effective\n",
    "for col in ('BsmtFinType1','BsmtFinType2'):\n",
    "    df_all[col].replace(qual_cleanup, inplace=True)\n",
    "    df_all[col]=df_all[col].astype(float)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "       Gd\tGood Exposure\n",
    "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
    "       Mn\tMimimum Exposure\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "\"\"\"\n",
    "qual_cleanup = {\"Gd\": 10, \"Av\": 7, \"Mn\": 4, \"No\": 2, \"None\": 0}\n",
    "\n",
    "# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\n",
    "df_all_tmp=df_all.copy()\n",
    "df_all_tmp['BsmtExposure'].replace(qual_cleanup, inplace=True)\n",
    "ordinal_features.append('BsmtExposure')\n",
    "df_all_tmp['BsmtExposure']=df_all_tmp['BsmtExposure'].astype(float)\n",
    "encoding_measure (df_all_tmp, feature='BsmtExposure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing Ordinal Encoding for Ordinal Data as most effective\n",
    "df_all['BsmtExposure'].replace(qual_cleanup, inplace=True)\n",
    "df_all['BsmtExposure']=df_all['BsmtExposure'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Functional (seems decrease score, not used now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_all['Functional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
    "       Typ\tTypical Functionality\n",
    "       Min1\tMinor Deductions 1\n",
    "       Min2\tMinor Deductions 2\n",
    "       Mod\tModerate Deductions\n",
    "       Maj1\tMajor Deductions 1\n",
    "       Maj2\tMajor Deductions 2\n",
    "       Sev\tSeverely Damaged\n",
    "       Sal\tSalvage only\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qual_cleanup = {\"Typ\": 10, \"Min1\": 9, \"Min2\": 8, \"Mod\": 6, \"Maj1\": 4,\"Maj2\": 3, \"Sev\": 1, \"Sal\": 0}\n",
    "\n",
    "# Checking/Evaluation effectiveness (error) of different encoding approaches (AsIs, OneHot, Label, Binary)\n",
    "df_all_tmp=df_all.copy()\n",
    "df_all_tmp['Functional'].replace(qual_cleanup, inplace=True)\n",
    "ordinal_features.append('Functional')\n",
    "df_all_tmp['Functional']=df_all_tmp['Functional'].astype(float)\n",
    "encoding_measure (df_all_tmp, feature='Functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing Ordinal Encoding for Ordinal Data as most effective\n",
    "df_all['Functional'].replace(qual_cleanup, inplace=True)\n",
    "df_all['Functional']=df_all['Functional'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Functional'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with GarageFinish (seems decrease score, not used now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_all['GarageFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_cleanup = {\"Fin\": 10, \"RFn\": 7, \"Unf\": 4, \"None\": 0}\n",
    "\n",
    "df_all_tmp=df_all.copy()\n",
    "df_all_tmp['GarageFinish'].replace(qual_cleanup, inplace=True)\n",
    "ordinal_features.append('GarageFinish')\n",
    "df_all_tmp['GarageFinish']=df_all_tmp['GarageFinish'].astype(float)\n",
    "encoding_measure (df_all_tmp, feature='GarageFinish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing Ordinal Encoding for Ordinal Data as most effective\n",
    "df_all['GarageFinish'].replace(qual_cleanup, inplace=True)\n",
    "df_all['GarageFinish']=df_all['GarageFinish'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_object_columns(df):\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_object_columns(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CentralAir\n",
    "CentralAir_cleanup = {\"Y\": 1, \"N\": 0}\n",
    "\n",
    "df_all['CentralAir'].replace(CentralAir_cleanup, inplace=True)\n",
    "categorical_features.append('CentralAir')\n",
    "#df_all['CentralAir']=df_all['CentralAir'].astype(str)\n",
    "encoding_measure (df_all, feature='CentralAir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.MSSubClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming some numerical variables that are really categorical\n",
    "\n",
    "# MSSubClass=The building class\n",
    "\"\"\"\n",
    "MSSubClass: Identifies the type of dwelling involved in the sale.\t\n",
    "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
    "        30\t1-STORY 1945 & OLDER\n",
    "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
    "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
    "        50\t1-1/2 STORY FINISHED ALL AGES\n",
    "        60\t2-STORY 1946 & NEWER\n",
    "        70\t2-STORY 1945 & OLDER\n",
    "        75\t2-1/2 STORY ALL AGES\n",
    "        80\tSPLIT OR MULTI-LEVEL\n",
    "        85\tSPLIT FOYER\n",
    "        90\tDUPLEX - ALL STYLES AND AGES\n",
    "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "       150\t1-1/2 STORY PUD - ALL AGES\n",
    "       160\t2-STORY PUD - 1946 & NEWER\n",
    "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "\"\"\"\n",
    "#df_all['MSSubClass'] = df_all['MSSubClass'].astype(str)\n",
    "#categorical_features.append('MSSubClass')\n",
    "encoding_measure (df_all, feature='MSSubClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.MSSubClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing OverallCond into a categorical variable\n",
    "\"\"\"\n",
    "OverallCond: Rates the overall condition of the house\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\t\n",
    "       5\tAverage\n",
    "       4\tBelow Average\t\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "\"\"\"\n",
    "#df_all['OverallCond'] = df_all['OverallCond'].astype(str)\n",
    "#categorical_features.append('OverallCond')\n",
    "encoding_measure (df_all, feature='OverallCond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing OverallQual into a categorical variable\n",
    "\"\"\"\n",
    "OverallQual: Rates the overall material and finish of the house\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "\"\"\"\n",
    "#df_all['OverallQual'] = df_all['OverallQual'].astype(str)\n",
    "#categorical_features.append('OverallQual')\n",
    "encoding_measure (df_all, feature='OverallQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year and month sold are transformed into categorical features.\n",
    "#df_all['YrSold'] = df_all['YrSold'].astype(str)\n",
    "#df_all['MoSold'] = df_all['MoSold'].astype(str)\n",
    "#categorical_features.append('YrSold')\n",
    "encoding_measure (df_all, feature='YrSold')\n",
    "#categorical_features.append('MoSold')\n",
    "encoding_measure (df_all, feature='MoSold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all['YearBuilt']=df_all['YearBuilt'].astype(str)\n",
    "#categorical_features.append('YearBuilt')\n",
    "encoding_measure (df_all, feature='YearBuilt')\n",
    "\n",
    "#df_all['YearRemodAdd']=df_all['YearRemodAdd'].astype(str)\n",
    "#categorical_features.append('YearRemodAdd')\n",
    "encoding_measure (df_all, feature='YearRemodAdd')\n",
    "\n",
    "#df_all['GarageYrBlt']=df_all['GarageYrBlt'].astype(str)\n",
    "#categorical_features.append('GarageYrBlt')\n",
    "encoding_measure (df_all, feature='GarageYrBlt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info(all)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# convert object columns to categorical\n",
    "def conv_obj_to_categories(df):\n",
    "    \"\"\"\n",
    "    Convert Object columns to Categorical\n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            df[col]=df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#conv_obj_to_categories(df_all)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def show_categorical_columns(df):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Number, Name and Codes of unique values in corresponding column \n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            print(sum(np.unique(df[col].cat.categories,return_counts=True)[1]), col ,df[col].cat.categories)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "show_categorical_columns(df_all)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def unique_categories(df,n=float(\"inf\")):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Names and Number of unique values in corresponding column \n",
    "    df - DataFrame\n",
    "    n - show only columns with less then N unique values, \n",
    "        as default - not show column if more than 10000 unique value - not pseudo categorical\n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            if sum(np.unique(df[col].cat.categories,return_counts=True)[1])<n:\n",
    "                print(col, sum(np.unique(df[col].cat.categories,return_counts=True)[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "unique_categories(df_all)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check numeric columns (if they are actually Categorical, like Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting - heavily convert NUMERICAL to CATEGORICAL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_allcats=df_all.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Experimenting with Numerical Categories\n",
    "def conv_num_cat (df):\n",
    "    for col in df:\n",
    "        if is_numeric_dtype(df[col]): \n",
    "            df[col]=df[col].astype('category')\n",
    "        else:\n",
    "            df.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "conv_num_cat(df_allcats)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "unique_categories(df_allcats,20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "conv_to_cat_shortlist=['MSSubClass', 'MoSold','YrSold']#'OverallCond', 'OverallQual']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#for cat in conv_to_cat_longlist:\n",
    "#    df_all[cat]=df_all[cat].astype('category')\n",
    "\n",
    "for cat in conv_to_cat_shortlist:\n",
    "    df_all[cat]=df_all[cat].astype('category')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#conv_to_cat_longlist=['BedroomAbvGr', 'BsmtFullBath','BsmtHalfBath', 'Fireplaces', 'FullBath',\\\n",
    "#             'GarageCars','HalfBath','KitchenAbvGr','MSSubClass','MoSold','OverallCond',\\\n",
    "#             'OverallQual','PoolArea','TotRmsAbvGrd','YrSold']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using list of quntative and qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative=['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    " 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    " 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
    " 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    " 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative=['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    " 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    " 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    " 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
    " 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
    " 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.select_dtypes(object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all['TotalSF'] = df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "#m_xgb.fit(X_train, y_train)\n",
    "#print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Age_Build']=df_all['YrSold'].astype(int)-df_all['YearBuilt'].astype(int)\n",
    "df_all['Age_Remod']=df_all['YrSold'].astype(int)-df_all['YearRemodAdd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "#m_xgb.fit(X_train, y_train)\n",
    "#print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all['Sizes_Total']=df_all['GrLivArea']+df_all['GarageCars']+df_all['GarageArea']+df_all['TotalBsmtSF']+df_all['1stFlrSF']+df_all['2ndFlrSF']+df_all['OpenPorchSF']+df_all['MasVnrArea']\n",
    "#df_all['Quantity_Total']=df_all['Fireplaces']+df_all['FullBath']+df_all['KitchenAbvGr']+df_all['TotRmsAbvGrd']+df_all['BedroomAbvGr']+df_all['BsmtFullBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)\n",
    "#fi[:20]\n",
    "fi.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Garage_Age_Build']=df_all['YrSold'].astype(float)-df_all['GarageYrBlt'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "#m_xgb.fit(X_train, y_train)\n",
    "#print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all['Quality_Aggregated']=df_all['ExterQual'].astype(int)+df_all['ExterCond'].astype(int)+df_all['BsmtQual'].astype(int)+df_all['BsmtCond'].astype(int)+df_all['KitchenQual'].astype(int)+df_all['OverallQual'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "#m_xgb.fit(X_train, y_train)\n",
    "#print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Feature generation here\n",
    "#df_all['Basement']=df_all['TotalBsmtSF']+df_all['BsmtFinSF1']+df_all['BsmtFinSF2']-df_all['BsmtUnfSF'])*\n",
    "#(df_all['BsmtQual']+df_all['BsmtCond']+df_all['BsmtFinType1']+df_all['BsmtExposure']+df_all['BsmtFinType2'])*\n",
    "#df_all['BsmtFullBath']*0.5*df_all['BsmtHalfBath']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garage=\n",
    "#House="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['YrBltAndRemod']=df_all['YearBuilt']+df_all['YearRemodAdd']\n",
    "df_all['TotalSF']=df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']\n",
    "\n",
    "df_all['Total_sqr_footage'] = (df_all['BsmtFinSF1'] + df_all['BsmtFinSF2'] +\n",
    "                                 df_all['1stFlrSF'] + df_all['2ndFlrSF'])\n",
    "\n",
    "df_all['Total_Bathrooms'] = (df_all['FullBath'] + (0.5 * df_all['HalfBath']) +\n",
    "                               df_all['BsmtFullBath'] + (0.5 * df_all['BsmtHalfBath']))\n",
    "\n",
    "df_all['Total_porch_sf'] = (df_all['OpenPorchSF'] + df_all['3SsnPorch'] +\n",
    "                              df_all['EnclosedPorch'] + df_all['ScreenPorch'] +\n",
    "                              df_all['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['haspool'] = df_all['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_all['has2ndfloor'] = df_all['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_all['hasgarage'] = df_all['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_all['hasbsmt'] = df_all['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_all['hasfireplace'] = df_all['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=quick_get_dumm(df_all)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)\n",
    "#m_xgb.fit(X_train, y_train)\n",
    "#print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data examining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.select_dtypes(object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Crisis Data 2008-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Dropping"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fi[:50]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def find_features_to_drop(X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\" Using RandomForest identifies important feature \n",
    "    and one by one drop least important features from DataFrame to improve model score\n",
    "    input - X_train, X_valid, y_train, y_valid, same as used in training and evaluation model using train/valid split\n",
    "    \"\"\"\n",
    "    m_feature_to_drop = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=False)\n",
    "    # to try - not use actual feature importance each iteration, but use only first one\n",
    "    #        m_feature_to_drop.fit(X_train, y_train)\n",
    "    #        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    \n",
    "    # Number of features in DataFrame\n",
    "    num_of_features=X_train.shape[1]\n",
    "    \n",
    "    list_of_original_columns=X_train.columns\n",
    "    \n",
    "    best_grade=1\n",
    "    list_of_feature_to_drop=pd.DataFrame()\n",
    "    grades={}\n",
    "    \n",
    "    for iteration in range(0, num_of_features):\n",
    "            \n",
    "        # Iteratively fit model with features without 1 least important (dropped in previos iteration)\n",
    "        m_feature_to_drop.fit(X_train, y_train)\n",
    "        # Evaluating performance withot this feature\n",
    "        grade=math.sqrt(mean_squared_error(y_valid, m_feature_to_drop.predict(X_valid)))\n",
    "\n",
    "        # Updating based on new model list of feature importance\n",
    "        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n",
    "\n",
    "        # Finding best score\n",
    "        if grade<best_grade:\n",
    "            best_grade=grade\n",
    "            best_num_of_features=(num_of_features-iteration)\n",
    "            list_of_feature_to_drop=list_of_original_columns.difference(fi.feature)\n",
    "\n",
    "        # Dropping last 1 (least important feature)\n",
    "        X_train=X_train.drop(columns=fi.feature[-1:])\n",
    "        X_valid=X_valid.drop(columns=fi.feature[-1:])\n",
    "\n",
    "        print ((num_of_features-iteration),grade, fi.feature[-1:])\n",
    "        grades.update({(num_of_features-iteration):grade})\n",
    "    print(best_grade,best_num_of_features) \n",
    "    #return list_of_feature_to_drop\n",
    "    return grades"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#features_to_drop=find_features_to_drop(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "grades=find_features_to_drop(X_train, X_valid, y_train, y_valid)\n",
    "#features_to_drop\n",
    "#fi.feature==fi.feature"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "x=list(grades.keys())\n",
    "y=list(grades.values())\n",
    "\n",
    "ax = plt.axes()\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "ax = plt.axes()\n",
    "plt.xlim(150,300)\n",
    "plt.ylim(0.10,0.145)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#df_all=df_all.drop(columns=features_to_drop)\n",
    "#df_all=df_all.drop(columns=fi.feature[150:])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "df_all = df_all.drop(['Utilities_missed'],['TotalBsmtSF_missed'],['SaleType_missed'],['MSZoning_missed'],\n",
    "                     ['KitchenQual_missed'],['GarageCars_missed'],['GarageArea_missed'],['Exterior2nd_missed'],\n",
    "                     ['Exterior1st_missed'],['BsmtFinSF2_missed'],['BsmtFullBath_missed'],['BsmtUnfSF_missed'],\n",
    "                     ['BsmtHalfBath_missed'],['Functional_missed'],  axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scewed data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "numeric_feats = df_all.dtypes[df_all.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = df_all[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for feature_name in skewness.T.columns:\n",
    "    if '_missed' in feature_name: \n",
    "        skewness.drop(feature_name,inplace=True)\n",
    "        print (feature_name)\n",
    "    if feature_name in ordinal_features or feature_name in categorical_features:\n",
    "        skewness.drop(feature_name,inplace=True)\n",
    "        print (feature_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    df_all[feat] = boxcox1p(df_all[feat], lam)\n",
    "    print(feat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Normalization, the Sigmoid, Log, Cube Root and the Hyperbolic Tangent. \n",
    "#It all depends on what one is trying to accomplish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_encoding (df_all,encoding='onehot'):\n",
    "    if encoding=='label':\n",
    "        # Label Encoding\n",
    "        cols=[]\n",
    "        cols.extend(ordinal_features)\n",
    "        cols.extend(categorical_features)\n",
    "        cols.extend(df_all.select_dtypes(object).columns)\n",
    "        # process columns, apply LabelEncoder to categorical features\n",
    "        for c in cols:\n",
    "            if c in df_all.columns:\n",
    "                lbl = LabelEncoder() \n",
    "                lbl.fit(list(df_all[c].values)) \n",
    "                df_all[c] = lbl.transform(list(df_all[c].values))\n",
    "    if encoding=='binary':\n",
    "        # Binary Encoding\n",
    "        cols=[]\n",
    "        #cols.extend(ordinal_features)\n",
    "        cols.extend(categorical_features)\n",
    "        cols.extend(df_all.select_dtypes(object).columns)\n",
    "        # process columns, apply BinaryEncoder to categorical features\n",
    "        for c in cols:\n",
    "            if c in df_all.columns:\n",
    "                bnr = ce.binary.BinaryEncoder() \n",
    "                bnr.fit(list(df_all[c].values)) \n",
    "                df_all[c] = bnr.transform(list(df_all[c].values))\n",
    "    if encoding=='onehot':\n",
    "        df_all=pd.get_dummies(df_all)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=select_encoding(df_all,'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n",
    "# split Validational/Test set from Training set after Categorical Value Engeneering\n",
    "#def original_train_test(df_all):\n",
    "X_test=df_all.iloc[ntrain:] # Test set\n",
    "X_train_full=df_all.iloc[:ntrain] # Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y=y_train_full; X=X_train_full; X_sub=X_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)               "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.01,n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score = cv_rmse(ridge)\n",
    "score = cv_rmse(lasso)\n",
    "print(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('START Fit')\n",
    "\n",
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
    "\n",
    "print('elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print('Lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "\n",
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "\n",
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Blending Models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.05 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.3 * stack_gen_model.predict(np.array(X))))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Predict submission')\n",
    "#submission = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\n",
    "#submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n",
    "y_pred = np.floor(np.expm1(blend_models_predict(X_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=X_train_full; y_train=y_train_full; test=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, y_train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 4\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Stacking  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensembling StackedRegressor, XGBoost and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RMSE on the entire Train data when averaging'''\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train,stacked_train_pred*0.70 +\n",
    "               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for submission"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m_final_xgb = XGBRegressor(n_estimators=2000, learning_rate=0.05)\n",
    "m_final_xgb.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred = np.expm1(m_final_xgb.predict(X_test)); y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = y_pred\n",
    "sub.to_csv('submittions/submission_29Aug19.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
