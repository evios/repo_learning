{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup and Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"../../../data/house_pricing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(f'{PATH}train.csv')#, index_col='Id')\n",
    "df_test=pd.read_csv(f'{PATH}test.csv')#, index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y (target value) to Log, as stated at Kaggle Evaluation page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for the purpose of evaluation of current competition\n",
    "#df_train.SalePrice = np.log1p(df_train.SalePrice)\n",
    "df_train.SalePrice = np.log1p(df_train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 1460\n",
      "Number of Test Examples = 1459\n",
      "\n",
      "Training X Shape = (1460, 81)\n",
      "Training y Shape = 1460\n",
      "\n",
      "Test X Shape = (1459, 80)\n",
      "Test y Shape = 1459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['SalePrice'].shape[0]))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "#print(df_train.columns)\n",
    "#print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df_train.info())\n",
    "#df_train.sample(3)\n",
    "#print(df_test.info())\n",
    "#df_test.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting outliers\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n",
    "\n",
    "#Check the graphic again\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_train['GrLivArea'], df_train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame concatination and Y separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 81)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set on axis 0\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remember where to divide train and test\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = df_train['Id']\n",
    "test_ID = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dividing Target column (Y)\n",
    "y_train_full = df_train.SalePrice.values\n",
    "df_all.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Create columns to mark originally missed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_missing (df):\n",
    "    for col in df.columns:\n",
    "        if df_all[col].isnull().sum()>0:\n",
    "            df_all[col+'_missed']=df_all[col].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 114)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Replace Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Id 0\n",
      "MSSubClass 0\n",
      "MSZoning 0\n",
      "LotFrontage 259\n",
      "LotArea 0\n",
      "Street 0\n",
      "Alley 1369\n",
      "LotShape 0\n",
      "LandContour 0\n",
      "Utilities 0\n",
      "LotConfig 0\n",
      "LandSlope 0\n",
      "Neighborhood 0\n",
      "Condition1 0\n",
      "Condition2 0\n",
      "BldgType 0\n",
      "HouseStyle 0\n",
      "OverallQual 0\n",
      "OverallCond 0\n",
      "YearBuilt 0\n",
      "YearRemodAdd 0\n",
      "RoofStyle 0\n",
      "RoofMatl 0\n",
      "Exterior1st 0\n",
      "Exterior2nd 0\n",
      "MasVnrType 8\n",
      "MasVnrArea 8\n",
      "ExterQual 0\n",
      "ExterCond 0\n",
      "Foundation 0\n",
      "BsmtQual 37\n",
      "BsmtCond 37\n",
      "BsmtExposure 38\n",
      "BsmtFinType1 37\n",
      "BsmtFinSF1 0\n",
      "BsmtFinType2 38\n",
      "BsmtFinSF2 0\n",
      "BsmtUnfSF 0\n",
      "TotalBsmtSF 0\n",
      "Heating 0\n",
      "HeatingQC 0\n",
      "CentralAir 0\n",
      "Electrical 1\n",
      "1stFlrSF 0\n",
      "2ndFlrSF 0\n",
      "LowQualFinSF 0\n",
      "GrLivArea 0\n",
      "BsmtFullBath 0\n",
      "BsmtHalfBath 0\n",
      "FullBath 0\n",
      "HalfBath 0\n",
      "BedroomAbvGr 0\n",
      "KitchenAbvGr 0\n",
      "KitchenQual 0\n",
      "TotRmsAbvGrd 0\n",
      "Functional 0\n",
      "Fireplaces 0\n",
      "FireplaceQu 690\n",
      "GarageType 81\n",
      "GarageYrBlt 81\n",
      "GarageFinish 81\n",
      "GarageCars 0\n",
      "GarageArea 0\n",
      "GarageQual 81\n",
      "GarageCond 81\n",
      "PavedDrive 0\n",
      "WoodDeckSF 0\n",
      "OpenPorchSF 0\n",
      "EnclosedPorch 0\n",
      "3SsnPorch 0\n",
      "ScreenPorch 0\n",
      "PoolArea 0\n",
      "PoolQC 1453\n",
      "Fence 1179\n",
      "MiscFeature 1406\n",
      "MiscVal 0\n",
      "MoSold 0\n",
      "YrSold 0\n",
      "SaleType 0\n",
      "SaleCondition 0\n",
      "SalePrice 0\n",
      "\n",
      "\n",
      "Test Set\n",
      "Id 0\n",
      "MSSubClass 0\n",
      "MSZoning 4\n",
      "LotFrontage 227\n",
      "LotArea 0\n",
      "Street 0\n",
      "Alley 1352\n",
      "LotShape 0\n",
      "LandContour 0\n",
      "Utilities 2\n",
      "LotConfig 0\n",
      "LandSlope 0\n",
      "Neighborhood 0\n",
      "Condition1 0\n",
      "Condition2 0\n",
      "BldgType 0\n",
      "HouseStyle 0\n",
      "OverallQual 0\n",
      "OverallCond 0\n",
      "YearBuilt 0\n",
      "YearRemodAdd 0\n",
      "RoofStyle 0\n",
      "RoofMatl 0\n",
      "Exterior1st 1\n",
      "Exterior2nd 1\n",
      "MasVnrType 16\n",
      "MasVnrArea 15\n",
      "ExterQual 0\n",
      "ExterCond 0\n",
      "Foundation 0\n",
      "BsmtQual 44\n",
      "BsmtCond 45\n",
      "BsmtExposure 44\n",
      "BsmtFinType1 42\n",
      "BsmtFinSF1 1\n",
      "BsmtFinType2 42\n",
      "BsmtFinSF2 1\n",
      "BsmtUnfSF 1\n",
      "TotalBsmtSF 1\n",
      "Heating 0\n",
      "HeatingQC 0\n",
      "CentralAir 0\n",
      "Electrical 0\n",
      "1stFlrSF 0\n",
      "2ndFlrSF 0\n",
      "LowQualFinSF 0\n",
      "GrLivArea 0\n",
      "BsmtFullBath 2\n",
      "BsmtHalfBath 2\n",
      "FullBath 0\n",
      "HalfBath 0\n",
      "BedroomAbvGr 0\n",
      "KitchenAbvGr 0\n",
      "KitchenQual 1\n",
      "TotRmsAbvGrd 0\n",
      "Functional 2\n",
      "Fireplaces 0\n",
      "FireplaceQu 730\n",
      "GarageType 76\n",
      "GarageYrBlt 78\n",
      "GarageFinish 78\n",
      "GarageCars 1\n",
      "GarageArea 1\n",
      "GarageQual 78\n",
      "GarageCond 78\n",
      "PavedDrive 0\n",
      "WoodDeckSF 0\n",
      "OpenPorchSF 0\n",
      "EnclosedPorch 0\n",
      "3SsnPorch 0\n",
      "ScreenPorch 0\n",
      "PoolArea 0\n",
      "PoolQC 1456\n",
      "Fence 1169\n",
      "MiscFeature 1408\n",
      "MiscVal 0\n",
      "MoSold 0\n",
      "YrSold 0\n",
      "SaleType 1\n",
      "SaleCondition 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_missing(df):\n",
    "    for col in df.columns:\n",
    "        print(col, df[col].isnull().sum())\n",
    "    print('\\n')\n",
    "    \n",
    "for df in dfs:\n",
    "    print(format(df.name))\n",
    "    display_missing(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Check remaining missing values if any \n",
    "def display_only_missing(df):\n",
    "    all_data_na = (df.isnull().sum() / len(df)) * 100\n",
    "    all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "    print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC            99.657417\n",
      "MiscFeature       96.402878\n",
      "Alley             93.216855\n",
      "Fence             80.438506\n",
      "FireplaceQu       48.646797\n",
      "LotFrontage       16.649538\n",
      "GarageQual         5.447071\n",
      "GarageCond         5.447071\n",
      "GarageFinish       5.447071\n",
      "GarageYrBlt        5.447071\n",
      "GarageType         5.378554\n",
      "BsmtExposure       2.809181\n",
      "BsmtCond           2.809181\n",
      "BsmtQual           2.774923\n",
      "BsmtFinType2       2.740665\n",
      "BsmtFinType1       2.706406\n",
      "MasVnrType         0.822199\n",
      "MasVnrArea         0.787941\n",
      "MSZoning           0.137033\n",
      "BsmtFullBath       0.068517\n",
      "BsmtHalfBath       0.068517\n",
      "Utilities          0.068517\n",
      "Functional         0.068517\n",
      "Electrical         0.034258\n",
      "BsmtUnfSF          0.034258\n",
      "Exterior1st        0.034258\n",
      "Exterior2nd        0.034258\n",
      "TotalBsmtSF        0.034258\n",
      "GarageArea         0.034258\n",
      "GarageCars         0.034258\n",
      "BsmtFinSF2         0.034258\n",
      "BsmtFinSF1         0.034258\n",
      "KitchenQual        0.034258\n",
      "SaleType           0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace non-missing but \"NA\", \"None\", etc values by Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace NA in Object columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Alley: Type of alley access to property\n",
    "       NA \tNo alley access\n",
    "MasVnrType: Masonry veneer type\n",
    "       None\tNone\n",
    "BsmtQual: Evaluates the height of the basement\n",
    "       NA\tNo Basement\n",
    "BsmtCond: Evaluates the general condition of the basement\n",
    "       NA\tNo Basement\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "BsmtFinType1: Rating of basement finished area\n",
    "       NA\tNo Basement\n",
    "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "       NA\tNo Basement\n",
    "CentralAir: Central air conditioning\n",
    "       N\tNo\n",
    "FireplaceQu: Fireplace quality\n",
    "       NA\tNo Fireplace\n",
    "GarageType: Garage location\n",
    "       NA\tNo Garage\n",
    "GarageFinish: Interior finish of the garage\n",
    "       NA\tNo Garage\n",
    "GarageQual: Garage quality\n",
    "       NA\tNo Garage\n",
    "GarageCond: Garage condition\n",
    "       NA\tNo Garage\n",
    "PavedDrive: Paved driveway\n",
    "       N\tDirt/Gravel\n",
    "PoolQC: Pool quality\n",
    "       NA\tNo Pool\n",
    "Fence: Fence quality\n",
    "       NA\tNo Fence\n",
    "MiscFeature: Miscellaneous feature not covered in other categories\n",
    "       NA\tNone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC            99.657417\n",
      "MiscFeature       96.402878\n",
      "Alley             93.216855\n",
      "Fence             80.438506\n",
      "FireplaceQu       48.646797\n",
      "LotFrontage       16.649538\n",
      "GarageQual         5.447071\n",
      "GarageCond         5.447071\n",
      "GarageFinish       5.447071\n",
      "GarageYrBlt        5.447071\n",
      "GarageType         5.378554\n",
      "BsmtExposure       2.809181\n",
      "BsmtCond           2.809181\n",
      "BsmtQual           2.774923\n",
      "BsmtFinType2       2.740665\n",
      "BsmtFinType1       2.706406\n",
      "MasVnrType         0.822199\n",
      "MasVnrArea         0.787941\n",
      "MSZoning           0.137033\n",
      "BsmtFullBath       0.068517\n",
      "BsmtHalfBath       0.068517\n",
      "Utilities          0.068517\n",
      "Functional         0.068517\n",
      "Electrical         0.034258\n",
      "BsmtUnfSF          0.034258\n",
      "Exterior1st        0.034258\n",
      "Exterior2nd        0.034258\n",
      "TotalBsmtSF        0.034258\n",
      "GarageArea         0.034258\n",
      "GarageCars         0.034258\n",
      "BsmtFinSF2         0.034258\n",
      "BsmtFinSF1         0.034258\n",
      "KitchenQual        0.034258\n",
      "SaleType           0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values (not missed) with None - based on data description -  - for non-Numerical (object) Columns\n",
    "for col in ('Alley','MasVnrType','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "            'BsmtFinType2','FireplaceQu','GarageType', 'GarageFinish', 'GarageQual', \n",
    "            'GarageCond','PoolQC','Fence','MiscFeature'):\n",
    "    df_all[col] = df_all[col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace NA in Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "LotFrontage       16.649538\n",
      "GarageYrBlt        5.447071\n",
      "MasVnrArea         0.787941\n",
      "MSZoning           0.137033\n",
      "Utilities          0.068517\n",
      "BsmtFullBath       0.068517\n",
      "BsmtHalfBath       0.068517\n",
      "Functional         0.068517\n",
      "Exterior1st        0.034258\n",
      "BsmtFinSF2         0.034258\n",
      "BsmtUnfSF          0.034258\n",
      "Electrical         0.034258\n",
      "GarageArea         0.034258\n",
      "Exterior2nd        0.034258\n",
      "TotalBsmtSF        0.034258\n",
      "GarageCars         0.034258\n",
      "KitchenQual        0.034258\n",
      "SaleType           0.034258\n",
      "BsmtFinSF1         0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fill NA numerical value with '0' - based on data description of correspondent Object columns - for Numerical Columns\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath','MasVnrArea'):\n",
    "    df_all[col] = df_all[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace NA missing values by most often in column (only for columns with 2 and less NA values, where do not make sense to invest hugely into Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "LotFrontage      16.649538\n",
      "MSZoning          0.137033\n",
      "Utilities         0.068517\n",
      "Functional        0.068517\n",
      "SaleType          0.034258\n",
      "KitchenQual       0.034258\n",
      "Exterior2nd       0.034258\n",
      "Exterior1st       0.034258\n",
      "Electrical        0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill missing value in corresponding columns with most frequent value in column\n",
    "for col in ('Utilities','Functional','SaleType','KitchenQual','Exterior2nd','Exterior1st','Electrical'):\n",
    "    df_all[col].fillna(df_all[col].mode()[0], inplace=True)\n",
    "    \n",
    "# Functional : data description says NA means typical\n",
    "# BTW we just used df_all.Functional.mode() = use most frequent value (as 'Typ' is most frequent value)\n",
    "#df_all[\"Functional\"] = df_all[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing real missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with missing values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "LotFrontage      16.649538\n",
      "MSZoning          0.137033\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with MSZoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.MSZoning.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\"\n",
    "! To reconsider MSZoning - we can specify \"None\" or something like this\n",
    "Also we can try to use most frequent value (as we can se only 4 NA values)\n",
    "MSZoning: Identifies the general zoning classification of the sale.\n",
    "       A\tAgriculture\n",
    "       C\tCommercial\n",
    "       FV\tFloating Village Residential\n",
    "       I\tIndustrial\n",
    "       RH\tResidential High Density\n",
    "       RL\tResidential Low Density\n",
    "       RP\tResidential Low Density Park \n",
    "       RM\tResidential Medium Density\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"MSZoning\"] = df_all[\"MSZoning\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "LotFrontage      16.649538\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_na_with_predictions(df, feature):\n",
    "    \"\"\"\n",
    "    df - DataFrame without target column y. Train+Test DataFrame (df_all)\n",
    "    feature - feature (column), containing real NA values we will fill\n",
    "\n",
    "    Assumption:\n",
    "    All other columns do not have NA values. In case of having we have to impute with some Statistical method (Median, etc)\n",
    "    We do not do it inside this function\n",
    "    \"\"\"\n",
    "\n",
    "    flag_object=0\n",
    "    \n",
    "    if df[feature].isnull().sum()>0:\n",
    "        ## Store Indexes of rows with NA values (we can just call \"_missed\" column with True values, to check those indexes as well)\n",
    "        ## Creating index based on NA values present in column\n",
    "        na_rows_idxs=df[df[feature].isnull()].index \n",
    "            ## Creating index based on NA values being present in original DF column\n",
    "            #na_rows_idxs=df.index[df[feature+'_missed'] == True].tolist()\n",
    "\n",
    "        ## For fitting and predictiong - convert DF to dummies DF, ready for ML\n",
    "        #df=pd.get_dummies(df)\n",
    "        ## If feature object we cant just dummy all, we shouldn't dummy feature column\n",
    "        df=pd.concat([ pd.Series(df[feature]), pd.get_dummies(df.drop([feature], axis=1)) ], axis=1)\n",
    "\n",
    "\n",
    "        ## Splitting DF to Feature_Train_X, Feature_Train_y, Feature_Predict_X:\n",
    "        ## Feature_Train_X = DF without NA values in \"feature_with_NA\"column\n",
    "        ## Feature_Train_y = target values that we have. All values in \"feature_with_NA\" except NA values\n",
    "        ## Feature_Predict_X = DF of correcponding to NA values in \"feature_with_NA\" without target vales (basically because they is equal to NA)\n",
    "        Feature_Train_X=df.drop(df[df[feature].isnull()].index).drop([feature], axis=1)\n",
    "        Feature_Train_y=df[feature].drop(df[df[feature].isnull()].index).values\n",
    "        Feature_Predict_X=df[df[feature].isnull()].drop([feature], axis=1)\n",
    "\n",
    "        ## If feature is NOT Numerical\n",
    "        ## Label encoding of y values in case it is not numerical\n",
    "        if is_string_dtype(df[feature]) or is_categorical_dtype(df[feature]):\n",
    "            flag_object=1\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            le.fit(Feature_Train_y)\n",
    "            Feature_Train_y=le.transform(Feature_Train_y)\n",
    "             \n",
    "        ## Making predictions, what might be in NA fields based on Train DF\n",
    "        m_xgb = XGBRegressor(n_estimators=400, learning_rate=0.05)\n",
    "        m_xgb.fit(Feature_Train_X, Feature_Train_y)\n",
    "    \n",
    "        ## Creating (Predicting) values to impute NA\n",
    "        fillna_values=m_xgb.predict(Feature_Predict_X)\n",
    "\n",
    "        ## If feature is NOT Numerical\n",
    "        ## Return Encoded values back to Object/Category if feature NOT numerical\n",
    "        if flag_object==1:\n",
    "            fillna_values=le.inverse_transform(np.around(fillna_values).astype(int))\n",
    "        \n",
    "        ## Replacing NA values with predicted Series of values\n",
    "        df[feature]=df[feature].fillna(pd.Series(index=na_rows_idxs,data=fillna_values))\n",
    "\n",
    "        ## Returning feature column without NA values    \n",
    "        return df[feature]\n",
    "    else:\n",
    "        print ('There were no NA values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:45:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "df_all['LotFrontage']=filling_na_with_predictions(df_all, \"LotFrontage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Missing Ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2919 entries, 0 to 2918\n",
      "Columns: 114 entries, 1stFlrSF to Utilities_missed\n",
      "dtypes: bool(34), float64(11), int64(26), object(43)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Once again dealing with missed MSZoning values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returning original NA back\n",
    "\n",
    "def return_original_na(df, feature):\n",
    "    df[feature].loc[df.index[df[feature+'_missed'] == True].tolist()]=np.nan\n",
    "    return df[feature]\n",
    "    \n",
    "df_all['MSZoning']=return_original_na(df_all, 'MSZoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Missing Ratio\n",
      "MSZoning       0.137033\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1915, 2216, 2250, 2904], dtype='int64')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all['MSZoning'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:45:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "df_all['MSZoning']=filling_na_with_predictions(df_all, 'MSZoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915    RH\n",
       "2216    RL\n",
       "2250    RL\n",
       "2904    RL\n",
       "Name: MSZoning, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['MSZoning'].loc[df_all.index[df_all['MSZoning'+'_missed'] == True].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with Missing values we replaced with most common - now replacing them with predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Utilities         0.068517\n",
    "Functional        0.068517\n",
    "SaleType          0.034258\n",
    "KitchenQual       0.034258\n",
    "Exterior2nd       0.034258\n",
    "Exterior1st       0.034258\n",
    "Electrical        0.034258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in ('Utilities','Functional','SaleType','KitchenQual','Exterior2nd','Exterior1st','Electrical'):\n",
    "#    print ('Filling with most common:\\n',df_all[col].loc[df_all.index[df_all[col+'_missed'] == True].tolist()])\n",
    "#    df_all[col]=return_original_na(df_all, col)\n",
    "#    df_all[col]=filling_na_with_predictions(df_all, col)\n",
    "#    print ('Filling with predictions:\\n',df_all[col].loc[df_all.index[df_all[col+'_missed'] == True].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Seems no missed values\n",
    "Missing Values = DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Evaluation - benchmarking before Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Training, Validation, Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n",
    "# split Validational/Test set from Training set after Categorical Value Engeneering\n",
    "#def original_train_test(df_all):\n",
    "X_test=df_all.iloc[ntrain:] # Test set\n",
    "X_train_full=df_all.iloc[:ntrain] # Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919, 114), (1460,), (1459, 114), (1460, 114))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape, y_train_full.shape, X_test.shape, X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 337), (365, 337))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05446730035614242, 0.11611444151610519, 0.9819695172626995, 0.9061902014709694, 0.8700809297354569]\n"
     ]
    }
   ],
   "source": [
    "m_rf = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:46:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "CPU times: user 17.1 s, sys: 57.8 ms, total: 17.2 s\n",
      "Wall time: 17.4 s\n",
      "[0.03857017532293831, 0.10831367586529637, 0.990958533449573, 0.9183714057230711]\n"
     ]
    }
   ],
   "source": [
    "m_xgb = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "# using early_stop to find out where validation scores don't improve\n",
    "#m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "%time m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.concat([df_all, pd.Series(y_train_full, name='SalePrice')], axis=1)\n",
    "df_idxs_submission=pd.DataFrame(pd.Series(test_ID, name='Id'))\n",
    "#y_df=pd.DataFrame(pd.Series(y_train_full, name='SalePrice'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)\n",
    "df_raw.reset_index(drop=True, inplace=True)\n",
    "df_raw.to_feather('tmp/house-after-cleaning')\n",
    "#df_all.to_feather('tmp/house-after-cleaning')\n",
    "#y_df.to_feather('tmp/house-y-after-cleaning')\n",
    "\n",
    "#Save the 'Id' column for submission\n",
    "df_idxs_submission.to_feather('tmp/house-testDF-idxs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.347077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.133022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>0.060721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.054491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>0.039720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>0.038199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>0.030378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FullBath</td>\n",
       "      <td>0.030027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>0.022180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ExterQual_TA</td>\n",
       "      <td>0.021423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>0.014328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>0.013437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>0.012911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>0.012309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>0.010792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>0.007988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>CentralAir_Y</td>\n",
       "      <td>0.006761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>CentralAir_N</td>\n",
       "      <td>0.005863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>FireplaceQu_None</td>\n",
       "      <td>0.005557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fireplaces</td>\n",
       "      <td>0.005485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FireplaceQu_missed</td>\n",
       "      <td>0.005470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>0.005417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "      <td>0.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>MSZoning_RM</td>\n",
       "      <td>0.004006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OpenPorchSF</td>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>BsmtQual_Ex</td>\n",
       "      <td>0.003865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Id</td>\n",
       "      <td>0.003682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MSSubClass</td>\n",
       "      <td>0.003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>0.002891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MoSold</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>WoodDeckSF</td>\n",
       "      <td>0.002756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>GarageFinish_Unf</td>\n",
       "      <td>0.002661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>GarageType_Attchd</td>\n",
       "      <td>0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>KitchenQual_Ex</td>\n",
       "      <td>0.002574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>MSZoning_RL</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BedroomAbvGr</td>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>GarageType_Detchd</td>\n",
       "      <td>0.002278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>SaleCondition_Family</td>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KitchenAbvGr</td>\n",
       "      <td>0.001696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>BsmtQual_Gd</td>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>YrSold</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>KitchenQual_Gd</td>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BsmtFullBath</td>\n",
       "      <td>0.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HalfBath</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>ExterCond_Fa</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>KitchenQual_TA</td>\n",
       "      <td>0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>BsmtFinType1_GLQ</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>ExterQual_Gd</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EnclosedPorch</td>\n",
       "      <td>0.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>PavedDrive_N</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance\n",
       "28            OverallQual    0.347077\n",
       "15              GrLivArea    0.133022\n",
       "34              YearBuilt    0.060721\n",
       "32            TotalBsmtSF    0.054491\n",
       "12             GarageArea    0.039720\n",
       "13             GarageCars    0.038199\n",
       "0                1stFlrSF    0.030378\n",
       "11               FullBath    0.030027\n",
       "4              BsmtFinSF1    0.022180\n",
       "140          ExterQual_TA    0.021423\n",
       "19                LotArea    0.014328\n",
       "14            GarageYrBlt    0.013437\n",
       "1                2ndFlrSF    0.012911\n",
       "35           YearRemodAdd    0.012309\n",
       "27            OverallCond    0.010792\n",
       "20            LotFrontage    0.007988\n",
       "109          CentralAir_Y    0.006761\n",
       "108          CentralAir_N    0.005863\n",
       "180      FireplaceQu_None    0.005557\n",
       "10             Fireplaces    0.005485\n",
       "52     FireplaceQu_missed    0.005470\n",
       "8               BsmtUnfSF    0.005417\n",
       "31           TotRmsAbvGrd    0.004063\n",
       "262           MSZoning_RM    0.004006\n",
       "26            OpenPorchSF    0.003870\n",
       "103           BsmtQual_Ex    0.003865\n",
       "17                     Id    0.003682\n",
       "22             MSSubClass    0.003150\n",
       "23             MasVnrArea    0.002891\n",
       "25                 MoSold    0.002800\n",
       "33             WoodDeckSF    0.002756\n",
       "205      GarageFinish_Unf    0.002661\n",
       "213     GarageType_Attchd    0.002577\n",
       "238        KitchenQual_Ex    0.002574\n",
       "261           MSZoning_RL    0.002319\n",
       "3            BedroomAbvGr    0.002290\n",
       "217     GarageType_Detchd    0.002278\n",
       "321  SaleCondition_Family    0.001912\n",
       "18           KitchenAbvGr    0.001696\n",
       "105           BsmtQual_Gd    0.001510\n",
       "36                 YrSold    0.001509\n",
       "240        KitchenQual_Gd    0.001451\n",
       "6            BsmtFullBath    0.001424\n",
       "16               HalfBath    0.001346\n",
       "133          ExterCond_Fa    0.001340\n",
       "241        KitchenQual_TA    0.001028\n",
       "91       BsmtFinType1_GLQ    0.001010\n",
       "139          ExterQual_Gd    0.001005\n",
       "9           EnclosedPorch    0.000890\n",
       "297          PavedDrive_N    0.000873"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_features_to_drop(X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\" Using RandomForest identifies important feature \n",
    "    and one by one drop least important features from DataFrame to improve model score\n",
    "    input - X_train, X_valid, y_train, y_valid, same as used in training and evaluation model using train/valid split\n",
    "    \"\"\"\n",
    "    m_feature_to_drop = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=False)\n",
    "    # to try - not use actual feature importance each iteration, but use only first one\n",
    "    #        m_feature_to_drop.fit(X_train, y_train)\n",
    "    #        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    \n",
    "    # Number of features in DataFrame\n",
    "    num_of_features=X_train.shape[1]\n",
    "    \n",
    "    list_of_original_columns=X_train.columns\n",
    "    \n",
    "    best_grade=1\n",
    "    list_of_feature_to_drop=pd.DataFrame()\n",
    "    #grades={}\n",
    "    \n",
    "    for iteration in range(0, num_of_features):\n",
    "            \n",
    "        # Iteratively fit model with features without 1 least important (dropped in previos iteration)\n",
    "        m_feature_to_drop.fit(X_train, y_train)\n",
    "        # Evaluating performance withot this feature\n",
    "        grade=math.sqrt(mean_squared_error(y_valid, m_feature_to_drop.predict(X_valid)))\n",
    "\n",
    "        # Updating based on new model list of feature importance\n",
    "        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n",
    "\n",
    "        # Finding best score\n",
    "        if grade<best_grade:\n",
    "            best_grade=grade\n",
    "            best_num_of_features=(num_of_features-iteration)\n",
    "            list_of_feature_to_drop=list_of_original_columns.difference(fi.feature)\n",
    "\n",
    "        # Dropping last 1 (least important feature)\n",
    "        X_train=X_train.drop(columns=fi.feature[-1:])\n",
    "        X_valid=X_valid.drop(columns=fi.feature[-1:])\n",
    "\n",
    "        print ((num_of_features-iteration),grade, fi.feature[-1:])\n",
    "        #grades.update({(num_of_features-iteration):grade})\n",
    "    print(best_grade,best_num_of_features) \n",
    "    return list_of_feature_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#features_to_drop=find_features_to_drop(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_features_to_drop\n",
    "#fi.feature==fi.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=list(grades.keys())\n",
    "y=list(grades.values())\n",
    "\n",
    "ax = plt.axes()\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ax = plt.axes()\n",
    "plt.xlim(150,300)\n",
    "plt.ylim(0.133,0.1350)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all=df_all.drop(columns=features_to_drop)\n",
    "#df_all=df_all.drop(columns=fi.feature[150:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n",
    "# split Validational/Test set from Training set after Categorical Value Engeneering\n",
    "X_test=df_all.iloc[ntrain:] # Test set\n",
    "X_train_full=df_all.iloc[:ntrain] # Train set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['TotalSF'] = df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Sizes_Total']=df_all['GrLivArea']+df_all['GarageCars']+df_all['GarageArea']+df_all['TotalBsmtSF']+df_all['1stFlrSF']+df_all['2ndFlrSF']+df_all['OpenPorchSF']+df_all['MasVnrArea']\n",
    "df_all['Quantity_Total']=df_all['Fireplaces']+df_all['FullBath']+df_all['KitchenAbvGr']+df_all['TotRmsAbvGrd']+df_all['BedroomAbvGr']+df_all['BsmtFullBath']\n",
    "df_all['Age_Build']=df_all['YrSold']-df_all['YearBuilt']\n",
    "df_all['Age_Remod']=df_all['YrSold']-df_all['YearRemodAdd']\n",
    "\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "%time m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real 0.14114 and after full stackNet 0.123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_object_columns(df):\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            print(col)\n",
    "show_object_columns(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforming some numerical variables that are really categorical\n",
    "\n",
    "# MSSubClass=The building class\n",
    "#df_all['MSSubClass'] = df_all['MSSubClass'].astype(str)\n",
    "\n",
    "\n",
    "# Changing OverallCond into a categorical variable\n",
    "#df_all['OverallCond'] = df_all['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "# Year and month sold are transformed into categorical features.\n",
    "#df_all['YrSold'] = df_all['YrSold'].astype(str)\n",
    "#df_all['MoSold'] = df_all['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert object columns to categorical\n",
    "def conv_obj_to_categories(df):\n",
    "    \"\"\"\n",
    "    Convert Object columns to Categorical\n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            df[col]=df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "conv_obj_to_categories(df_all)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_categorical_columns(df):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Number, Name and Codes of unique values in corresponding column \n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            print(sum(np.unique(df[col].cat.categories,return_counts=True)[1]), col ,df[col].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_categorical_columns(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unique_categories(df,n=float(\"inf\")):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Names and Number of unique values in corresponding column \n",
    "    df - DataFrame\n",
    "    n - show only columns with less then N unique values, \n",
    "        as default - not show column if more than 10000 unique value - not pseudo categorical\n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            if sum(np.unique(df[col].cat.categories,return_counts=True)[1])<n:\n",
    "                print(col, sum(np.unique(df[col].cat.categories,return_counts=True)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_categories(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check numeric columns (if they are actually Categorical, like Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting - heavily convert NUMERICAL to CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_allcats=df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Experimenting with Numerical Categories\n",
    "def conv_num_cat (df):\n",
    "    for col in df:\n",
    "        if is_numeric_dtype(df[col]): \n",
    "            df[col]=df[col].astype('category')\n",
    "        else:\n",
    "            df.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_num_cat(df_allcats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_categories(df_allcats,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#conv_to_cat_longlist=['BedroomAbvGr', 'BsmtFullBath','BsmtHalfBath', 'Fireplaces', 'FullBath',\\\n",
    "#             'GarageCars','HalfBath','KitchenAbvGr','MSSubClass','MoSold','OverallCond',\\\n",
    "#             'OverallQual','PoolArea','TotRmsAbvGrd','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_to_cat_shortlist=['HalfBath','MSSubClass', 'MoSold','OverallCond', 'OverallQual','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for cat in conv_to_cat_longlist:\n",
    "#    df_all[cat]=df_all[cat].astype('category')\n",
    "\n",
    "for cat in conv_to_cat_shortlist:\n",
    "    df_all[cat]=df_all[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.info(114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Self made and experiment Evaluation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation of simple Random Forest\n",
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "#print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "math.sqrt(mean_squared_error(y_valid, m.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if you need to evaluate LOG Root mean squared error but wouldn't like to convert y to log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "math.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(m.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"#check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(df_train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(df_test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = df_train['Id']\n",
    "test_ID = df_test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "df_train.drop(\"Id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(df_train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(df_test.shape))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(df_train.corr())\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(df_train.corr(), ax=axs[0], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "sns.heatmap(df_test.corr(), ax=axs[1], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='x', labelsize=14)\n",
    "    axs[i].tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "axs[0].set_title('Training Set Correlations', size=15)\n",
    "axs[1].set_title('Test Set Correlations', size=15)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_corr=df_train.corr().sort_values(kind=\"quicksort\", ascending=False, by='SalePrice').abs()\n",
    "df_corr.drop(axis=1, columns=df_corr.columns.drop('SalePrice'), inplace=True)\n",
    "df_corr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"numeric_feats = df_all.dtypes[df_all.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = df_all[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    df_all[feat] = boxcox1p(df_all[feat], lam)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalization, the Sigmoid, Log, Cube Root and the Hyperbolic Tangent. \n",
    "#It all depends on what one is trying to accomplish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(df_all[c].values)) \n",
    "    df_all[c] = lbl.transform(list(df_all[c].values))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all=pd.get_dummies(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_rf = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_xgb = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "# using early_stop to find out where validation scores don't improve\n",
    "m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "%time m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT (Gradient Boosting Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_gbdt=GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "%time m_gbdt.fit(X_train, y_train)\n",
    "print_score(m_gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing stacking from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.base import TransformerMixin,clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "n_folds=2\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train_full.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train_full.values, y_train_full, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, lasso),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(X_train_full.values, y_train_full)\n",
    "stacked_train_pred = stacked_averaged_models.predict(X_train_full.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(X_test.values))\n",
    "print(rmsle(y_train_full, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_xgb.fit(X_train_full, y_train_full)\n",
    "xgb_train_pred = m_xgb.predict(X_train_full)\n",
    "xgb_pred = np.expm1(m_xgb.predict(X_test))\n",
    "print(rmsle(y_train_full, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_rf.fit(X_train_full, y_train_full)\n",
    "rf_train_pred = m_rf.predict(X_train_full)\n",
    "rf_pred = np.expm1(m_rf.predict(X_test.values))\n",
    "print(rmsle(y_train_full, rf_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''RMSE on the entire Train data when averaging'''\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train_full,stacked_train_pred*0.7 +\n",
    "               xgb_train_pred*0.15+rf_train_pred*0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = stacked_pred*0.7 +xgb_pred*0.15+rf_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_final_xgb = XGBRegressor(n_estimators=2000, learning_rate=0.05)\n",
    "m_final_xgb.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.expm1(m_final_xgb.predict(X_test)); y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = y_pred\n",
    "sub.to_csv('submittions/submission_27Aug19.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
