{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup and Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"../../../data/house_pricing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(f'{PATH}train.csv')#, index_col='Id')\n",
    "df_test=pd.read_csv(f'{PATH}test.csv')#, index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y (target value) to Log, as stated at Kaggle Evaluation page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for the purpose of evaluation of current competition\n",
    "#df_train.SalePrice = np.log1p(df_train.SalePrice)\n",
    "df_train.SalePrice = np.log1p(df_train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 1460\n",
      "Number of Test Examples = 1459\n",
      "\n",
      "Training X Shape = (1460, 81)\n",
      "Training y Shape = 1460\n",
      "\n",
      "Test X Shape = (1459, 80)\n",
      "Test y Shape = 1459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['SalePrice'].shape[0]))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "#print(df_train.columns)\n",
    "#print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df_train.info())\n",
    "#df_train.sample(3)\n",
    "#print(df_test.info())\n",
    "#df_test.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame concatination and Y separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 81)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set on axis 0\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remember where to divide train and test\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = df_train['Id']\n",
    "test_ID = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dividing Target column (Y)\n",
    "y_train_full = df_train.SalePrice.values\n",
    "df_all.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "scrolled": true
   },
   "source": [
    "### Create columns to mark originally missed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mark_missing (df):\n",
    "    for col in df.columns:\n",
    "        if df_all[col].isnull().sum()>0:\n",
    "            df_all[col+'_missed']=df_all[col].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mark_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 114)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "scrolled": true
   },
   "source": [
    "### Replace Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Id 0\n",
      "MSSubClass 0\n",
      "MSZoning 0\n",
      "LotFrontage 259\n",
      "LotArea 0\n",
      "Street 0\n",
      "Alley 1369\n",
      "LotShape 0\n",
      "LandContour 0\n",
      "Utilities 0\n",
      "LotConfig 0\n",
      "LandSlope 0\n",
      "Neighborhood 0\n",
      "Condition1 0\n",
      "Condition2 0\n",
      "BldgType 0\n",
      "HouseStyle 0\n",
      "OverallQual 0\n",
      "OverallCond 0\n",
      "YearBuilt 0\n",
      "YearRemodAdd 0\n",
      "RoofStyle 0\n",
      "RoofMatl 0\n",
      "Exterior1st 0\n",
      "Exterior2nd 0\n",
      "MasVnrType 8\n",
      "MasVnrArea 8\n",
      "ExterQual 0\n",
      "ExterCond 0\n",
      "Foundation 0\n",
      "BsmtQual 37\n",
      "BsmtCond 37\n",
      "BsmtExposure 38\n",
      "BsmtFinType1 37\n",
      "BsmtFinSF1 0\n",
      "BsmtFinType2 38\n",
      "BsmtFinSF2 0\n",
      "BsmtUnfSF 0\n",
      "TotalBsmtSF 0\n",
      "Heating 0\n",
      "HeatingQC 0\n",
      "CentralAir 0\n",
      "Electrical 1\n",
      "1stFlrSF 0\n",
      "2ndFlrSF 0\n",
      "LowQualFinSF 0\n",
      "GrLivArea 0\n",
      "BsmtFullBath 0\n",
      "BsmtHalfBath 0\n",
      "FullBath 0\n",
      "HalfBath 0\n",
      "BedroomAbvGr 0\n",
      "KitchenAbvGr 0\n",
      "KitchenQual 0\n",
      "TotRmsAbvGrd 0\n",
      "Functional 0\n",
      "Fireplaces 0\n",
      "FireplaceQu 690\n",
      "GarageType 81\n",
      "GarageYrBlt 81\n",
      "GarageFinish 81\n",
      "GarageCars 0\n",
      "GarageArea 0\n",
      "GarageQual 81\n",
      "GarageCond 81\n",
      "PavedDrive 0\n",
      "WoodDeckSF 0\n",
      "OpenPorchSF 0\n",
      "EnclosedPorch 0\n",
      "3SsnPorch 0\n",
      "ScreenPorch 0\n",
      "PoolArea 0\n",
      "PoolQC 1453\n",
      "Fence 1179\n",
      "MiscFeature 1406\n",
      "MiscVal 0\n",
      "MoSold 0\n",
      "YrSold 0\n",
      "SaleType 0\n",
      "SaleCondition 0\n",
      "SalePrice 0\n",
      "\n",
      "\n",
      "Test Set\n",
      "Id 0\n",
      "MSSubClass 0\n",
      "MSZoning 4\n",
      "LotFrontage 227\n",
      "LotArea 0\n",
      "Street 0\n",
      "Alley 1352\n",
      "LotShape 0\n",
      "LandContour 0\n",
      "Utilities 2\n",
      "LotConfig 0\n",
      "LandSlope 0\n",
      "Neighborhood 0\n",
      "Condition1 0\n",
      "Condition2 0\n",
      "BldgType 0\n",
      "HouseStyle 0\n",
      "OverallQual 0\n",
      "OverallCond 0\n",
      "YearBuilt 0\n",
      "YearRemodAdd 0\n",
      "RoofStyle 0\n",
      "RoofMatl 0\n",
      "Exterior1st 1\n",
      "Exterior2nd 1\n",
      "MasVnrType 16\n",
      "MasVnrArea 15\n",
      "ExterQual 0\n",
      "ExterCond 0\n",
      "Foundation 0\n",
      "BsmtQual 44\n",
      "BsmtCond 45\n",
      "BsmtExposure 44\n",
      "BsmtFinType1 42\n",
      "BsmtFinSF1 1\n",
      "BsmtFinType2 42\n",
      "BsmtFinSF2 1\n",
      "BsmtUnfSF 1\n",
      "TotalBsmtSF 1\n",
      "Heating 0\n",
      "HeatingQC 0\n",
      "CentralAir 0\n",
      "Electrical 0\n",
      "1stFlrSF 0\n",
      "2ndFlrSF 0\n",
      "LowQualFinSF 0\n",
      "GrLivArea 0\n",
      "BsmtFullBath 2\n",
      "BsmtHalfBath 2\n",
      "FullBath 0\n",
      "HalfBath 0\n",
      "BedroomAbvGr 0\n",
      "KitchenAbvGr 0\n",
      "KitchenQual 1\n",
      "TotRmsAbvGrd 0\n",
      "Functional 2\n",
      "Fireplaces 0\n",
      "FireplaceQu 730\n",
      "GarageType 76\n",
      "GarageYrBlt 78\n",
      "GarageFinish 78\n",
      "GarageCars 1\n",
      "GarageArea 1\n",
      "GarageQual 78\n",
      "GarageCond 78\n",
      "PavedDrive 0\n",
      "WoodDeckSF 0\n",
      "OpenPorchSF 0\n",
      "EnclosedPorch 0\n",
      "3SsnPorch 0\n",
      "ScreenPorch 0\n",
      "PoolArea 0\n",
      "PoolQC 1456\n",
      "Fence 1169\n",
      "MiscFeature 1408\n",
      "MiscVal 0\n",
      "MoSold 0\n",
      "YrSold 0\n",
      "SaleType 1\n",
      "SaleCondition 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_missing(df):\n",
    "    for col in df.columns:\n",
    "        print(col, df[col].isnull().sum())\n",
    "    print('\\n')\n",
    "    \n",
    "for df in dfs:\n",
    "    print(format(df.name))\n",
    "    display_missing(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Check remaining missing values if any \n",
    "def display_only_missing(df):\n",
    "    all_data_na = (df.isnull().sum() / len(df)) * 100\n",
    "    all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "    print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC            99.657417\n",
      "MiscFeature       96.402878\n",
      "Alley             93.216855\n",
      "Fence             80.438506\n",
      "FireplaceQu       48.646797\n",
      "LotFrontage       16.649538\n",
      "GarageQual         5.447071\n",
      "GarageCond         5.447071\n",
      "GarageFinish       5.447071\n",
      "GarageYrBlt        5.447071\n",
      "GarageType         5.378554\n",
      "BsmtExposure       2.809181\n",
      "BsmtCond           2.809181\n",
      "BsmtQual           2.774923\n",
      "BsmtFinType2       2.740665\n",
      "BsmtFinType1       2.706406\n",
      "MasVnrType         0.822199\n",
      "MasVnrArea         0.787941\n",
      "MSZoning           0.137033\n",
      "BsmtFullBath       0.068517\n",
      "BsmtHalfBath       0.068517\n",
      "Utilities          0.068517\n",
      "Functional         0.068517\n",
      "Electrical         0.034258\n",
      "BsmtUnfSF          0.034258\n",
      "Exterior1st        0.034258\n",
      "Exterior2nd        0.034258\n",
      "TotalBsmtSF        0.034258\n",
      "GarageArea         0.034258\n",
      "GarageCars         0.034258\n",
      "BsmtFinSF2         0.034258\n",
      "BsmtFinSF1         0.034258\n",
      "KitchenQual        0.034258\n",
      "SaleType           0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Replace non-missing but \"NA\", \"None\", etc values by Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Replace NA in Object columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\"\"\"\n",
    "Alley: Type of alley access to property\n",
    "       NA \tNo alley access\n",
    "MasVnrType: Masonry veneer type\n",
    "       None\tNone\n",
    "BsmtQual: Evaluates the height of the basement\n",
    "       NA\tNo Basement\n",
    "BsmtCond: Evaluates the general condition of the basement\n",
    "       NA\tNo Basement\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "BsmtFinType1: Rating of basement finished area\n",
    "       NA\tNo Basement\n",
    "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "       NA\tNo Basement\n",
    "CentralAir: Central air conditioning\n",
    "       N\tNo\n",
    "FireplaceQu: Fireplace quality\n",
    "       NA\tNo Fireplace\n",
    "GarageType: Garage location\n",
    "       NA\tNo Garage\n",
    "GarageFinish: Interior finish of the garage\n",
    "       NA\tNo Garage\n",
    "GarageQual: Garage quality\n",
    "       NA\tNo Garage\n",
    "GarageCond: Garage condition\n",
    "       NA\tNo Garage\n",
    "PavedDrive: Paved driveway\n",
    "       N\tDirt/Gravel\n",
    "PoolQC: Pool quality\n",
    "       NA\tNo Pool\n",
    "Fence: Fence quality\n",
    "       NA\tNo Fence\n",
    "MiscFeature: Miscellaneous feature not covered in other categories\n",
    "       NA\tNone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC            99.657417\n",
      "MiscFeature       96.402878\n",
      "Alley             93.216855\n",
      "Fence             80.438506\n",
      "FireplaceQu       48.646797\n",
      "LotFrontage       16.649538\n",
      "GarageQual         5.447071\n",
      "GarageCond         5.447071\n",
      "GarageFinish       5.447071\n",
      "GarageYrBlt        5.447071\n",
      "GarageType         5.378554\n",
      "BsmtExposure       2.809181\n",
      "BsmtCond           2.809181\n",
      "BsmtQual           2.774923\n",
      "BsmtFinType2       2.740665\n",
      "BsmtFinType1       2.706406\n",
      "MasVnrType         0.822199\n",
      "MasVnrArea         0.787941\n",
      "MSZoning           0.137033\n",
      "BsmtFullBath       0.068517\n",
      "BsmtHalfBath       0.068517\n",
      "Utilities          0.068517\n",
      "Functional         0.068517\n",
      "Electrical         0.034258\n",
      "BsmtUnfSF          0.034258\n",
      "Exterior1st        0.034258\n",
      "Exterior2nd        0.034258\n",
      "TotalBsmtSF        0.034258\n",
      "GarageArea         0.034258\n",
      "GarageCars         0.034258\n",
      "BsmtFinSF2         0.034258\n",
      "BsmtFinSF1         0.034258\n",
      "KitchenQual        0.034258\n",
      "SaleType           0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fill NA values (not missed) with None - based on data description -  - for non-Numerical (object) Columns\n",
    "for col in ('Alley','MasVnrType','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','FireplaceQu','GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "            'PoolQC','Fence','MiscFeature'):\n",
    "    df_all[col] = df_all[col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Replace NA in Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "LotFrontage       16.649538\n",
      "GarageYrBlt        5.447071\n",
      "MasVnrArea         0.787941\n",
      "MSZoning           0.137033\n",
      "Utilities          0.068517\n",
      "BsmtFullBath       0.068517\n",
      "BsmtHalfBath       0.068517\n",
      "Functional         0.068517\n",
      "Exterior1st        0.034258\n",
      "BsmtFinSF2         0.034258\n",
      "BsmtUnfSF          0.034258\n",
      "Electrical         0.034258\n",
      "GarageArea         0.034258\n",
      "Exterior2nd        0.034258\n",
      "TotalBsmtSF        0.034258\n",
      "GarageCars         0.034258\n",
      "KitchenQual        0.034258\n",
      "SaleType           0.034258\n",
      "BsmtFinSF1         0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fill NA numerical value with '0' - based on data description of correspondent Object columns - for Numerical Columns\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath','MasVnrArea'):\n",
    "    df_all[col] = df_all[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Replace NA missing values by most often in column (only for columns with 2 and less NA values, where do not make sense to invest hugely into Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "LotFrontage      16.649538\n",
      "MSZoning          0.137033\n",
      "Utilities         0.068517\n",
      "Functional        0.068517\n",
      "SaleType          0.034258\n",
      "KitchenQual       0.034258\n",
      "Exterior2nd       0.034258\n",
      "Exterior1st       0.034258\n",
      "Electrical        0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill missing value in corresponding columns with most frequent value in column\n",
    "for col in ('Utilities','Functional','SaleType','KitchenQual','Exterior2nd','Exterior1st','Electrical'):\n",
    "    df_all[col].fillna(df_all[col].mode()[0], inplace=True)\n",
    "    \n",
    "# Functional : data description says NA means typical\n",
    "# BTW we just used df_all.Functional.mode() = use most frequent value (as 'Typ' is most frequent value)\n",
    "#df_all[\"Functional\"] = df_all[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing real missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with missing values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "LotFrontage      16.649538\n",
      "MSZoning          0.137033\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with MSZoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.MSZoning.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\"\n",
    "! To reconsider MSZoning - we can specify \"None\" or something like this\n",
    "Also we can try to use most frequent value (as we can se only 4 NA values)\n",
    "MSZoning: Identifies the general zoning classification of the sale.\n",
    "       A\tAgriculture\n",
    "       C\tCommercial\n",
    "       FV\tFloating Village Residential\n",
    "       I\tIndustrial\n",
    "       RH\tResidential High Density\n",
    "       RL\tResidential Low Density\n",
    "       RP\tResidential Low Density Park \n",
    "       RM\tResidential Medium Density\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"MSZoning\"] = df_all[\"MSZoning\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "LotFrontage      16.649538\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies=pd.get_dummies(df_all)\n",
    "#DF with rows without NA values\n",
    "df_all_noNA=df_dummies.drop(df_dummies[df_dummies['LotFrontage'].isnull()].index)\n",
    "\n",
    "#Rows with NA values\n",
    "df_all_tmp_na=df_dummies[df_dummies['LotFrontage'].isnull()].drop(['LotFrontage'], axis=1)\n",
    "#Indexes of rows with NA values\n",
    "df_all_tmp_na_idxs=df_dummies[df_dummies['LotFrontage'].isnull()].drop(['LotFrontage'], axis=1).index\n",
    "\n",
    "# make column with NA values as target\n",
    "na_feature=df_all_noNA['LotFrontage'].values\n",
    "# prepare training set without column with NA\n",
    "df_to_predict_na=pd.get_dummies(df_all_noNA.drop(['LotFrontage'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=0.5, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,\n",
       "                      oob_score=False, random_state=None, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_rf = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1)\n",
    "\n",
    "#m_xgb = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "# using early_stop to find out where validation scores don't improve\n",
    "m_rf.fit(df_to_predict_na, na_feature)\n",
    "#m_xgb.fit(df_to_predict_na, na_feature, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LotFrontage=m_xgb.predict(df_all_tmp_na)\n",
    "LotFrontage=m_rf.predict(df_all_tmp_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row in df_all_tmp_na_idxs:\n",
    "#    df_all[row]=\n",
    "#df_all[df_all_tmp_na_idxs]\n",
    "#LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage\n",
       "7          NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.loc[[7],['LotFrontage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotFrontage\n",
      "7          NaN\n",
      "    LotFrontage\n",
      "12          NaN\n",
      "    LotFrontage\n",
      "14          NaN\n",
      "    LotFrontage\n",
      "16          NaN\n",
      "    LotFrontage\n",
      "24          NaN\n",
      "    LotFrontage\n",
      "31          NaN\n",
      "    LotFrontage\n",
      "42          NaN\n",
      "    LotFrontage\n",
      "43          NaN\n",
      "    LotFrontage\n",
      "50          NaN\n",
      "    LotFrontage\n",
      "64          NaN\n",
      "    LotFrontage\n",
      "66          NaN\n",
      "    LotFrontage\n",
      "76          NaN\n",
      "    LotFrontage\n",
      "84          NaN\n",
      "    LotFrontage\n",
      "95          NaN\n",
      "     LotFrontage\n",
      "100          NaN\n",
      "     LotFrontage\n",
      "104          NaN\n",
      "     LotFrontage\n",
      "111          NaN\n",
      "     LotFrontage\n",
      "113          NaN\n",
      "     LotFrontage\n",
      "116          NaN\n",
      "     LotFrontage\n",
      "120          NaN\n",
      "     LotFrontage\n",
      "126          NaN\n",
      "     LotFrontage\n",
      "131          NaN\n",
      "     LotFrontage\n",
      "133          NaN\n",
      "     LotFrontage\n",
      "136          NaN\n",
      "     LotFrontage\n",
      "147          NaN\n",
      "     LotFrontage\n",
      "149          NaN\n",
      "     LotFrontage\n",
      "152          NaN\n",
      "     LotFrontage\n",
      "153          NaN\n",
      "     LotFrontage\n",
      "160          NaN\n",
      "     LotFrontage\n",
      "166          NaN\n",
      "     LotFrontage\n",
      "169          NaN\n",
      "     LotFrontage\n",
      "170          NaN\n",
      "     LotFrontage\n",
      "177          NaN\n",
      "     LotFrontage\n",
      "180          NaN\n",
      "     LotFrontage\n",
      "186          NaN\n",
      "     LotFrontage\n",
      "191          NaN\n",
      "     LotFrontage\n",
      "203          NaN\n",
      "     LotFrontage\n",
      "207          NaN\n",
      "     LotFrontage\n",
      "208          NaN\n",
      "     LotFrontage\n",
      "214          NaN\n",
      "     LotFrontage\n",
      "218          NaN\n",
      "     LotFrontage\n",
      "221          NaN\n",
      "     LotFrontage\n",
      "234          NaN\n",
      "     LotFrontage\n",
      "237          NaN\n",
      "     LotFrontage\n",
      "244          NaN\n",
      "     LotFrontage\n",
      "249          NaN\n",
      "     LotFrontage\n",
      "269          NaN\n",
      "     LotFrontage\n",
      "287          NaN\n",
      "     LotFrontage\n",
      "288          NaN\n",
      "     LotFrontage\n",
      "293          NaN\n",
      "     LotFrontage\n",
      "307          NaN\n",
      "     LotFrontage\n",
      "308          NaN\n",
      "     LotFrontage\n",
      "310          NaN\n",
      "     LotFrontage\n",
      "319          NaN\n",
      "     LotFrontage\n",
      "328          NaN\n",
      "     LotFrontage\n",
      "330          NaN\n",
      "     LotFrontage\n",
      "335          NaN\n",
      "     LotFrontage\n",
      "342          NaN\n",
      "     LotFrontage\n",
      "346          NaN\n",
      "     LotFrontage\n",
      "347          NaN\n",
      "     LotFrontage\n",
      "351          NaN\n",
      "     LotFrontage\n",
      "356          NaN\n",
      "     LotFrontage\n",
      "360          NaN\n",
      "     LotFrontage\n",
      "361          NaN\n",
      "     LotFrontage\n",
      "364          NaN\n",
      "     LotFrontage\n",
      "366          NaN\n",
      "     LotFrontage\n",
      "369          NaN\n",
      "     LotFrontage\n",
      "370          NaN\n",
      "     LotFrontage\n",
      "375          NaN\n",
      "     LotFrontage\n",
      "384          NaN\n",
      "     LotFrontage\n",
      "392          NaN\n",
      "     LotFrontage\n",
      "393          NaN\n",
      "     LotFrontage\n",
      "404          NaN\n",
      "     LotFrontage\n",
      "405          NaN\n",
      "     LotFrontage\n",
      "412          NaN\n",
      "     LotFrontage\n",
      "421          NaN\n",
      "     LotFrontage\n",
      "426          NaN\n",
      "     LotFrontage\n",
      "447          NaN\n",
      "     LotFrontage\n",
      "452          NaN\n",
      "     LotFrontage\n",
      "457          NaN\n",
      "     LotFrontage\n",
      "458          NaN\n",
      "     LotFrontage\n",
      "459          NaN\n",
      "     LotFrontage\n",
      "465          NaN\n",
      "     LotFrontage\n",
      "470          NaN\n",
      "     LotFrontage\n",
      "484          NaN\n",
      "     LotFrontage\n",
      "490          NaN\n",
      "     LotFrontage\n",
      "496          NaN\n",
      "     LotFrontage\n",
      "516          NaN\n",
      "     LotFrontage\n",
      "518          NaN\n",
      "     LotFrontage\n",
      "529          NaN\n",
      "     LotFrontage\n",
      "537          NaN\n",
      "     LotFrontage\n",
      "538          NaN\n",
      "     LotFrontage\n",
      "539          NaN\n",
      "     LotFrontage\n",
      "541          NaN\n",
      "     LotFrontage\n",
      "545          NaN\n",
      "     LotFrontage\n",
      "559          NaN\n",
      "     LotFrontage\n",
      "560          NaN\n",
      "     LotFrontage\n",
      "564          NaN\n",
      "     LotFrontage\n",
      "569          NaN\n",
      "     LotFrontage\n",
      "580          NaN\n",
      "     LotFrontage\n",
      "593          NaN\n",
      "     LotFrontage\n",
      "610          NaN\n",
      "     LotFrontage\n",
      "611          NaN\n",
      "     LotFrontage\n",
      "612          NaN\n",
      "     LotFrontage\n",
      "616          NaN\n",
      "     LotFrontage\n",
      "623          NaN\n",
      "     LotFrontage\n",
      "626          NaN\n",
      "     LotFrontage\n",
      "641          NaN\n",
      "     LotFrontage\n",
      "645          NaN\n",
      "     LotFrontage\n",
      "660          NaN\n",
      "     LotFrontage\n",
      "666          NaN\n",
      "     LotFrontage\n",
      "668          NaN\n",
      "     LotFrontage\n",
      "672          NaN\n",
      "     LotFrontage\n",
      "679          NaN\n",
      "     LotFrontage\n",
      "682          NaN\n",
      "     LotFrontage\n",
      "685          NaN\n",
      "     LotFrontage\n",
      "687          NaN\n",
      "     LotFrontage\n",
      "690          NaN\n",
      "     LotFrontage\n",
      "706          NaN\n",
      "     LotFrontage\n",
      "709          NaN\n",
      "     LotFrontage\n",
      "714          NaN\n",
      "     LotFrontage\n",
      "720          NaN\n",
      "     LotFrontage\n",
      "721          NaN\n",
      "     LotFrontage\n",
      "726          NaN\n",
      "     LotFrontage\n",
      "734          NaN\n",
      "     LotFrontage\n",
      "745          NaN\n",
      "     LotFrontage\n",
      "746          NaN\n",
      "     LotFrontage\n",
      "751          NaN\n",
      "     LotFrontage\n",
      "757          NaN\n",
      "     LotFrontage\n",
      "770          NaN\n",
      "     LotFrontage\n",
      "783          NaN\n",
      "     LotFrontage\n",
      "785          NaN\n",
      "     LotFrontage\n",
      "789          NaN\n",
      "     LotFrontage\n",
      "791          NaN\n",
      "     LotFrontage\n",
      "794          NaN\n",
      "     LotFrontage\n",
      "811          NaN\n",
      "     LotFrontage\n",
      "816          NaN\n",
      "     LotFrontage\n",
      "817          NaN\n",
      "     LotFrontage\n",
      "822          NaN\n",
      "     LotFrontage\n",
      "828          NaN\n",
      "     LotFrontage\n",
      "840          NaN\n",
      "     LotFrontage\n",
      "845          NaN\n",
      "     LotFrontage\n",
      "851          NaN\n",
      "     LotFrontage\n",
      "853          NaN\n",
      "     LotFrontage\n",
      "855          NaN\n",
      "     LotFrontage\n",
      "856          NaN\n",
      "     LotFrontage\n",
      "859          NaN\n",
      "     LotFrontage\n",
      "865          NaN\n",
      "     LotFrontage\n",
      "868          NaN\n",
      "     LotFrontage\n",
      "879          NaN\n",
      "     LotFrontage\n",
      "882          NaN\n",
      "     LotFrontage\n",
      "893          NaN\n",
      "     LotFrontage\n",
      "900          NaN\n",
      "     LotFrontage\n",
      "904          NaN\n",
      "     LotFrontage\n",
      "908          NaN\n",
      "     LotFrontage\n",
      "911          NaN\n",
      "     LotFrontage\n",
      "917          NaN\n",
      "     LotFrontage\n",
      "925          NaN\n",
      "     LotFrontage\n",
      "927          NaN\n",
      "     LotFrontage\n",
      "928          NaN\n",
      "     LotFrontage\n",
      "929          NaN\n",
      "     LotFrontage\n",
      "939          NaN\n",
      "     LotFrontage\n",
      "941          NaN\n",
      "     LotFrontage\n",
      "944          NaN\n",
      "     LotFrontage\n",
      "953          NaN\n",
      "     LotFrontage\n",
      "961          NaN\n",
      "     LotFrontage\n",
      "967          NaN\n",
      "     LotFrontage\n",
      "975          NaN\n",
      "     LotFrontage\n",
      "980          NaN\n",
      "     LotFrontage\n",
      "983          NaN\n",
      "     LotFrontage\n",
      "988          NaN\n",
      "     LotFrontage\n",
      "996          NaN\n",
      "     LotFrontage\n",
      "997          NaN\n",
      "      LotFrontage\n",
      "1003          NaN\n",
      "      LotFrontage\n",
      "1006          NaN\n",
      "      LotFrontage\n",
      "1017          NaN\n",
      "      LotFrontage\n",
      "1018          NaN\n",
      "      LotFrontage\n",
      "1024          NaN\n",
      "      LotFrontage\n",
      "1030          NaN\n",
      "      LotFrontage\n",
      "1032          NaN\n",
      "      LotFrontage\n",
      "1033          NaN\n",
      "      LotFrontage\n",
      "1035          NaN\n",
      "      LotFrontage\n",
      "1037          NaN\n",
      "      LotFrontage\n",
      "1041          NaN\n",
      "      LotFrontage\n",
      "1045          NaN\n",
      "      LotFrontage\n",
      "1057          NaN\n",
      "      LotFrontage\n",
      "1059          NaN\n",
      "      LotFrontage\n",
      "1064          NaN\n",
      "      LotFrontage\n",
      "1077          NaN\n",
      "      LotFrontage\n",
      "1084          NaN\n",
      "      LotFrontage\n",
      "1086          NaN\n",
      "      LotFrontage\n",
      "1097          NaN\n",
      "      LotFrontage\n",
      "1108          NaN\n",
      "      LotFrontage\n",
      "1110          NaN\n",
      "      LotFrontage\n",
      "1116          NaN\n",
      "      LotFrontage\n",
      "1122          NaN\n",
      "      LotFrontage\n",
      "1124          NaN\n",
      "      LotFrontage\n",
      "1138          NaN\n",
      "      LotFrontage\n",
      "1141          NaN\n",
      "      LotFrontage\n",
      "1143          NaN\n",
      "      LotFrontage\n",
      "1146          NaN\n",
      "      LotFrontage\n",
      "1148          NaN\n",
      "      LotFrontage\n",
      "1153          NaN\n",
      "      LotFrontage\n",
      "1154          NaN\n",
      "      LotFrontage\n",
      "1161          NaN\n",
      "      LotFrontage\n",
      "1164          NaN\n",
      "      LotFrontage\n",
      "1177          NaN\n",
      "      LotFrontage\n",
      "1180          NaN\n",
      "      LotFrontage\n",
      "1190          NaN\n",
      "      LotFrontage\n",
      "1193          NaN\n",
      "      LotFrontage\n",
      "1206          NaN\n",
      "      LotFrontage\n",
      "1213          NaN\n",
      "      LotFrontage\n",
      "1230          NaN\n",
      "      LotFrontage\n",
      "1233          NaN\n",
      "      LotFrontage\n",
      "1244          NaN\n",
      "      LotFrontage\n",
      "1247          NaN\n",
      "      LotFrontage\n",
      "1251          NaN\n",
      "      LotFrontage\n",
      "1253          NaN\n",
      "      LotFrontage\n",
      "1260          NaN\n",
      "      LotFrontage\n",
      "1262          NaN\n",
      "      LotFrontage\n",
      "1268          NaN\n",
      "      LotFrontage\n",
      "1270          NaN\n",
      "      LotFrontage\n",
      "1271          NaN\n",
      "      LotFrontage\n",
      "1272          NaN\n",
      "      LotFrontage\n",
      "1276          NaN\n",
      "      LotFrontage\n",
      "1277          NaN\n",
      "      LotFrontage\n",
      "1286          NaN\n",
      "      LotFrontage\n",
      "1287          NaN\n",
      "      LotFrontage\n",
      "1290          NaN\n",
      "      LotFrontage\n",
      "1300          NaN\n",
      "      LotFrontage\n",
      "1301          NaN\n",
      "      LotFrontage\n",
      "1309          NaN\n",
      "      LotFrontage\n",
      "1312          NaN\n",
      "      LotFrontage\n",
      "1318          NaN\n",
      "      LotFrontage\n",
      "1321          NaN\n",
      "      LotFrontage\n",
      "1342          NaN\n",
      "      LotFrontage\n",
      "1346          NaN\n",
      "      LotFrontage\n",
      "1348          NaN\n",
      "      LotFrontage\n",
      "1354          NaN\n",
      "      LotFrontage\n",
      "1356          NaN\n",
      "      LotFrontage\n",
      "1357          NaN\n",
      "      LotFrontage\n",
      "1358          NaN\n",
      "      LotFrontage\n",
      "1362          NaN\n",
      "      LotFrontage\n",
      "1365          NaN\n",
      "      LotFrontage\n",
      "1368          NaN\n",
      "      LotFrontage\n",
      "1373          NaN\n",
      "      LotFrontage\n",
      "1381          NaN\n",
      "      LotFrontage\n",
      "1383          NaN\n",
      "      LotFrontage\n",
      "1396          NaN\n",
      "      LotFrontage\n",
      "1407          NaN\n",
      "      LotFrontage\n",
      "1417          NaN\n",
      "      LotFrontage\n",
      "1419          NaN\n",
      "      LotFrontage\n",
      "1423          NaN\n",
      "      LotFrontage\n",
      "1424          NaN\n",
      "      LotFrontage\n",
      "1429          NaN\n",
      "      LotFrontage\n",
      "1431          NaN\n",
      "      LotFrontage\n",
      "1441          NaN\n",
      "      LotFrontage\n",
      "1443          NaN\n",
      "      LotFrontage\n",
      "1446          NaN\n",
      "      LotFrontage\n",
      "1466          NaN\n",
      "      LotFrontage\n",
      "1500          NaN\n",
      "      LotFrontage\n",
      "1501          NaN\n",
      "      LotFrontage\n",
      "1505          NaN\n",
      "      LotFrontage\n",
      "1507          NaN\n",
      "      LotFrontage\n",
      "1512          NaN\n",
      "      LotFrontage\n",
      "1519          NaN\n",
      "      LotFrontage\n",
      "1535          NaN\n",
      "      LotFrontage\n",
      "1542          NaN\n",
      "      LotFrontage\n",
      "1558          NaN\n",
      "      LotFrontage\n",
      "1563          NaN\n",
      "      LotFrontage\n",
      "1565          NaN\n",
      "      LotFrontage\n",
      "1567          NaN\n",
      "      LotFrontage\n",
      "1573          NaN\n",
      "      LotFrontage\n",
      "1579          NaN\n",
      "      LotFrontage\n",
      "1584          NaN\n",
      "      LotFrontage\n",
      "1592          NaN\n",
      "      LotFrontage\n",
      "1606          NaN\n",
      "      LotFrontage\n",
      "1612          NaN\n",
      "      LotFrontage\n",
      "1627          NaN\n",
      "      LotFrontage\n",
      "1634          NaN\n",
      "      LotFrontage\n",
      "1637          NaN\n",
      "      LotFrontage\n",
      "1639          NaN\n",
      "      LotFrontage\n",
      "1642          NaN\n",
      "      LotFrontage\n",
      "1643          NaN\n",
      "      LotFrontage\n",
      "1644          NaN\n",
      "      LotFrontage\n",
      "1647          NaN\n",
      "      LotFrontage\n",
      "1648          NaN\n",
      "      LotFrontage\n",
      "1659          NaN\n",
      "      LotFrontage\n",
      "1689          NaN\n",
      "      LotFrontage\n",
      "1690          NaN\n",
      "      LotFrontage\n",
      "1691          NaN\n",
      "      LotFrontage\n",
      "1695          NaN\n",
      "      LotFrontage\n",
      "1698          NaN\n",
      "      LotFrontage\n",
      "1700          NaN\n",
      "      LotFrontage\n",
      "1728          NaN\n",
      "      LotFrontage\n",
      "1731          NaN\n",
      "      LotFrontage\n",
      "1732          NaN\n",
      "      LotFrontage\n",
      "1733          NaN\n",
      "      LotFrontage\n",
      "1734          NaN\n",
      "      LotFrontage\n",
      "1736          NaN\n",
      "      LotFrontage\n",
      "1737          NaN\n",
      "      LotFrontage\n",
      "1739          NaN\n",
      "      LotFrontage\n",
      "1740          NaN\n",
      "      LotFrontage\n",
      "1743          NaN\n",
      "      LotFrontage\n",
      "1746          NaN\n",
      "      LotFrontage\n",
      "1750          NaN\n",
      "      LotFrontage\n",
      "1754          NaN\n",
      "      LotFrontage\n",
      "1757          NaN\n",
      "      LotFrontage\n",
      "1758          NaN\n",
      "      LotFrontage\n",
      "1761          NaN\n",
      "      LotFrontage\n",
      "1768          NaN\n",
      "      LotFrontage\n",
      "1819          NaN\n",
      "      LotFrontage\n",
      "1823          NaN\n",
      "      LotFrontage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1833          NaN\n",
      "      LotFrontage\n",
      "1840          NaN\n",
      "      LotFrontage\n",
      "1843          NaN\n",
      "      LotFrontage\n",
      "1846          NaN\n",
      "      LotFrontage\n",
      "1847          NaN\n",
      "      LotFrontage\n",
      "1848          NaN\n",
      "      LotFrontage\n",
      "1861          NaN\n",
      "      LotFrontage\n",
      "1862          NaN\n",
      "      LotFrontage\n",
      "1863          NaN\n",
      "      LotFrontage\n",
      "1872          NaN\n",
      "      LotFrontage\n",
      "1878          NaN\n",
      "      LotFrontage\n",
      "1881          NaN\n",
      "      LotFrontage\n",
      "1883          NaN\n",
      "      LotFrontage\n",
      "1885          NaN\n",
      "      LotFrontage\n",
      "1902          NaN\n",
      "      LotFrontage\n",
      "1910          NaN\n",
      "      LotFrontage\n",
      "1911          NaN\n",
      "      LotFrontage\n",
      "1922          NaN\n",
      "      LotFrontage\n",
      "1936          NaN\n",
      "      LotFrontage\n",
      "1941          NaN\n",
      "      LotFrontage\n",
      "1945          NaN\n",
      "      LotFrontage\n",
      "1947          NaN\n",
      "      LotFrontage\n",
      "1949          NaN\n",
      "      LotFrontage\n",
      "1955          NaN\n",
      "      LotFrontage\n",
      "1957          NaN\n",
      "      LotFrontage\n",
      "1984          NaN\n",
      "      LotFrontage\n",
      "1985          NaN\n",
      "      LotFrontage\n",
      "1988          NaN\n",
      "      LotFrontage\n",
      "1989          NaN\n",
      "      LotFrontage\n",
      "1992          NaN\n",
      "      LotFrontage\n",
      "1996          NaN\n",
      "      LotFrontage\n",
      "1999          NaN\n",
      "      LotFrontage\n",
      "2023          NaN\n",
      "      LotFrontage\n",
      "2029          NaN\n",
      "      LotFrontage\n",
      "2030          NaN\n",
      "      LotFrontage\n",
      "2039          NaN\n",
      "      LotFrontage\n",
      "2041          NaN\n",
      "      LotFrontage\n",
      "2042          NaN\n",
      "      LotFrontage\n",
      "2044          NaN\n",
      "      LotFrontage\n",
      "2049          NaN\n",
      "      LotFrontage\n",
      "2052          NaN\n",
      "      LotFrontage\n",
      "2064          NaN\n",
      "      LotFrontage\n",
      "2074          NaN\n",
      "      LotFrontage\n",
      "2110          NaN\n",
      "      LotFrontage\n",
      "2111          NaN\n",
      "      LotFrontage\n",
      "2122          NaN\n",
      "      LotFrontage\n",
      "2128          NaN\n",
      "      LotFrontage\n",
      "2131          NaN\n",
      "      LotFrontage\n",
      "2137          NaN\n",
      "      LotFrontage\n",
      "2140          NaN\n",
      "      LotFrontage\n",
      "2141          NaN\n",
      "      LotFrontage\n",
      "2142          NaN\n",
      "      LotFrontage\n",
      "2146          NaN\n",
      "      LotFrontage\n",
      "2148          NaN\n",
      "      LotFrontage\n",
      "2155          NaN\n",
      "      LotFrontage\n",
      "2157          NaN\n",
      "      LotFrontage\n",
      "2163          NaN\n",
      "      LotFrontage\n",
      "2164          NaN\n",
      "      LotFrontage\n",
      "2166          NaN\n",
      "      LotFrontage\n",
      "2167          NaN\n",
      "      LotFrontage\n",
      "2170          NaN\n",
      "      LotFrontage\n",
      "2171          NaN\n",
      "      LotFrontage\n",
      "2173          NaN\n",
      "      LotFrontage\n",
      "2174          NaN\n",
      "      LotFrontage\n",
      "2175          NaN\n",
      "      LotFrontage\n",
      "2178          NaN\n",
      "      LotFrontage\n",
      "2186          NaN\n",
      "      LotFrontage\n",
      "2202          NaN\n",
      "      LotFrontage\n",
      "2203          NaN\n",
      "      LotFrontage\n",
      "2204          NaN\n"
     ]
    }
   ],
   "source": [
    "for i in df_all[df_all['LotFrontage'].isnull()].index:\n",
    "    print(df_all.loc[[i],['LotFrontage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.LotFrontage(df_all_tmp_na_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LotFrontage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_copy=df_all['LotFrontage'].fillna(pd.Series(index=df_all[df_all['LotFrontage'].isnull()].index,data=LotFrontage))#, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7        94.45625\n",
       "12       76.86250\n",
       "14       93.91250\n",
       "16       52.57500\n",
       "24       69.78125\n",
       "31       64.46250\n",
       "42       55.99375\n",
       "43       54.46875\n",
       "50       90.95625\n",
       "64       77.56250\n",
       "66      107.94375\n",
       "76       69.56250\n",
       "84       62.79375\n",
       "95       79.18125\n",
       "100      78.59375\n",
       "104      67.92500\n",
       "111      62.08125\n",
       "113     120.27500\n",
       "116      79.56250\n",
       "120      74.90625\n",
       "126      46.05000\n",
       "131      89.35000\n",
       "133      63.91875\n",
       "136      88.87500\n",
       "147      64.75000\n",
       "149      54.21875\n",
       "152      57.58125\n",
       "153      93.58750\n",
       "160      51.73750\n",
       "166      80.81250\n",
       "          ...    \n",
       "2684     91.40625\n",
       "2700     65.58750\n",
       "2703     71.56875\n",
       "2704     53.96875\n",
       "2706     69.71250\n",
       "2707     44.63750\n",
       "2708     68.23125\n",
       "2709     79.31875\n",
       "2714     33.11875\n",
       "2715     36.08750\n",
       "2724     73.51875\n",
       "2727     61.30000\n",
       "2737     69.66875\n",
       "2738     80.16875\n",
       "2741     89.72500\n",
       "2764    100.28125\n",
       "2807     81.41875\n",
       "2810     82.03750\n",
       "2811     63.35625\n",
       "2812     76.99375\n",
       "2814     83.71250\n",
       "2815    109.46250\n",
       "2818     25.98125\n",
       "2839     63.52500\n",
       "2845     71.26875\n",
       "2847     95.71250\n",
       "2850     85.26250\n",
       "2900    106.74375\n",
       "2901     70.66250\n",
       "2908    106.49375\n",
       "Length: 486, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(index=df_all[df_all['LotFrontage'].isnull()].index,data=LotFrontage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        65.00000\n",
       "1        80.00000\n",
       "2        68.00000\n",
       "3        60.00000\n",
       "4        84.00000\n",
       "5        85.00000\n",
       "6        75.00000\n",
       "7        54.46875\n",
       "8        51.00000\n",
       "9        50.00000\n",
       "10       70.00000\n",
       "11       85.00000\n",
       "12       62.79375\n",
       "13       91.00000\n",
       "14       78.59375\n",
       "15       51.00000\n",
       "16       62.08125\n",
       "17       72.00000\n",
       "18       66.00000\n",
       "19       70.00000\n",
       "20      101.00000\n",
       "21       57.00000\n",
       "22       75.00000\n",
       "23       44.00000\n",
       "24       64.75000\n",
       "25      110.00000\n",
       "26       60.00000\n",
       "27       98.00000\n",
       "28       47.00000\n",
       "29       60.00000\n",
       "          ...    \n",
       "2889     50.00000\n",
       "2890     75.00000\n",
       "2891     69.00000\n",
       "2892     50.00000\n",
       "2893     60.00000\n",
       "2894     41.00000\n",
       "2895     44.00000\n",
       "2896     69.00000\n",
       "2897     65.00000\n",
       "2898     70.00000\n",
       "2899    140.00000\n",
       "2900          NaN\n",
       "2901          NaN\n",
       "2902     95.00000\n",
       "2903     88.00000\n",
       "2904    125.00000\n",
       "2905     78.00000\n",
       "2906     41.00000\n",
       "2907     58.00000\n",
       "2908          NaN\n",
       "2909     21.00000\n",
       "2910     21.00000\n",
       "2911     80.00000\n",
       "2912     21.00000\n",
       "2913     21.00000\n",
       "2914     21.00000\n",
       "2915     21.00000\n",
       "2916    160.00000\n",
       "2917     62.00000\n",
       "2918     74.00000\n",
       "Name: LotFrontage, Length: 2919, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7        True\n",
       "8       False\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12       True\n",
       "13      False\n",
       "14       True\n",
       "15      False\n",
       "16       True\n",
       "17      False\n",
       "18      False\n",
       "19      False\n",
       "20      False\n",
       "21      False\n",
       "22      False\n",
       "23      False\n",
       "24       True\n",
       "25      False\n",
       "26      False\n",
       "27      False\n",
       "28      False\n",
       "29      False\n",
       "        ...  \n",
       "2889    False\n",
       "2890    False\n",
       "2891    False\n",
       "2892    False\n",
       "2893    False\n",
       "2894    False\n",
       "2895    False\n",
       "2896    False\n",
       "2897    False\n",
       "2898    False\n",
       "2899    False\n",
       "2900     True\n",
       "2901     True\n",
       "2902    False\n",
       "2903    False\n",
       "2904    False\n",
       "2905    False\n",
       "2906    False\n",
       "2907    False\n",
       "2908     True\n",
       "2909    False\n",
       "2910    False\n",
       "2911    False\n",
       "2912    False\n",
       "2913    False\n",
       "2914    False\n",
       "2915    False\n",
       "2916    False\n",
       "2917    False\n",
       "2918    False\n",
       "Name: LotFrontage_missed, Length: 2919, dtype: bool"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['LotFrontage_missed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df_train.corr().sort_values(kind=\"quicksort\", ascending=False, by='LotFrontage').abs()\n",
    "df_corr.drop(axis=1, columns=df_corr.columns.drop('LotFrontage'), inplace=True)\n",
    "df_corr.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(\"Neighborhood\")[\"LotFrontage\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(\"MSSubClass\")[\"LotFrontage\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LotFrontage : Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood.\n",
    "# Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "df_all[\"LotFrontage\"] = df_all.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['LotFrontage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Seems no missed values\n",
    "Missing Values = DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Evaluation - benchmarking before Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Training, Validation, Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n",
    "# split Validational/Test set from Training set after Categorical Value Engeneering\n",
    "#def original_train_test(df_all):\n",
    "X_test=df_all.iloc[ntrain:] # Test set\n",
    "X_train_full=df_all.iloc[:ntrain] # Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all.shape, y_train_full.shape, X_test.shape, X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(pd.get_dummies(X_train_full), y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train.shape, X_valid.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_rf = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_xgb = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "# using early_stop to find out where validation scores don't improve\n",
    "m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "%time m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_object_columns(df):\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            print(col)\n",
    "show_object_columns(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforming some numerical variables that are really categorical\n",
    "\n",
    "# MSSubClass=The building class\n",
    "#df_all['MSSubClass'] = df_all['MSSubClass'].astype(str)\n",
    "\n",
    "\n",
    "# Changing OverallCond into a categorical variable\n",
    "#df_all['OverallCond'] = df_all['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "# Year and month sold are transformed into categorical features.\n",
    "#df_all['YrSold'] = df_all['YrSold'].astype(str)\n",
    "#df_all['MoSold'] = df_all['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.info(114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert object columns to categorical\n",
    "def conv_obj_to_categories(df):\n",
    "    \"\"\"\n",
    "    Convert Object columns to Categorical\n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            df[col]=df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "conv_obj_to_categories(df_all)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_categorical_columns(df):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Number, Name and Codes of unique values in corresponding column \n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            print(sum(np.unique(df[col].cat.categories,return_counts=True)[1]), col ,df[col].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_categorical_columns(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unique_categories(df,n=float(\"inf\")):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Names and Number of unique values in corresponding column \n",
    "    df - DataFrame\n",
    "    n - show only columns with less then N unique values, \n",
    "        as default - not show column if more than 10000 unique value - not pseudo categorical\n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            if sum(np.unique(df[col].cat.categories,return_counts=True)[1])<n:\n",
    "                print(col, sum(np.unique(df[col].cat.categories,return_counts=True)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_categories(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check numeric columns (if they are actually Categorical, like Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting - heavily convert NUMERICAL to CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_allcats=df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Experimenting with Numerical Categories\n",
    "def conv_num_cat (df):\n",
    "    for col in df:\n",
    "        if is_numeric_dtype(df[col]): \n",
    "            df[col]=df[col].astype('category')\n",
    "        else:\n",
    "            df.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_num_cat(df_allcats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_categories(df_allcats,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#conv_to_cat_longlist=['BedroomAbvGr', 'BsmtFullBath','BsmtHalfBath', 'Fireplaces', 'FullBath',\\\n",
    "#             'GarageCars','HalfBath','KitchenAbvGr','MSSubClass','MoSold','OverallCond',\\\n",
    "#             'OverallQual','PoolArea','TotRmsAbvGrd','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_to_cat_shortlist=['HalfBath','MSSubClass', 'MoSold','OverallCond', 'OverallQual','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for cat in conv_to_cat_longlist:\n",
    "#    df_all[cat]=df_all[cat].astype('category')\n",
    "\n",
    "for cat in conv_to_cat_shortlist:\n",
    "    df_all[cat]=df_all[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.info(114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_rf.feature_importances_}).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_features_to_drop(X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\" Using RandomForest identifies important feature \n",
    "    and one by one drop least important features from DataFrame to improve model score\n",
    "    input - X_train, X_valid, y_train, y_valid, same as used in training and evaluation model using train/valid split\n",
    "    \"\"\"\n",
    "    m_feature_to_drop = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=False)\n",
    "    # to try - not use actual feature importance each iteration, but use only first one\n",
    "    #        m_feature_to_drop.fit(X_train, y_train)\n",
    "    #        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    \n",
    "    # Number of features in DataFrame\n",
    "    num_of_features=X_train.shape[1]\n",
    "    \n",
    "    list_of_original_columns=X_train.columns\n",
    "    \n",
    "    best_grade=1\n",
    "    list_of_feature_to_drop=pd.DataFrame()\n",
    "    #grades={}\n",
    "    \n",
    "    for iteration in range(0, num_of_features):\n",
    "            \n",
    "        # Iteratively fit model with features without 1 least important (dropped in previos iteration)\n",
    "        m_feature_to_drop.fit(X_train, y_train)\n",
    "        # Evaluating performance withot this feature\n",
    "        grade=math.sqrt(mean_squared_error(y_valid, m_feature_to_drop.predict(X_valid)))\n",
    "\n",
    "        # Updating based on new model list of feature importance\n",
    "        fi = pd.DataFrame({'feature': list(X_train.columns), 'importance':m_feature_to_drop.feature_importances_}).sort_values('importance',ascending=False)\n",
    "\n",
    "        # Finding best score\n",
    "        if grade<best_grade:\n",
    "            best_grade=grade\n",
    "            best_num_of_features=(num_of_features-iteration)\n",
    "            list_of_feature_to_drop=list_of_original_columns.difference(fi.feature)\n",
    "\n",
    "        # Dropping last 1 (least important feature)\n",
    "        X_train=X_train.drop(columns=fi.feature[-1:])\n",
    "        X_valid=X_valid.drop(columns=fi.feature[-1:])\n",
    "\n",
    "        print ((num_of_features-iteration),grade, fi.feature[-1:])\n",
    "        #grades.update({(num_of_features-iteration):grade})\n",
    "    print(best_grade,best_num_of_features) \n",
    "    return list_of_feature_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#features_to_drop=find_features_to_drop(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_to_drop\n",
    "#fi.feature==fi.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=list(grades.keys())\n",
    "y=list(grades.values())\n",
    "\n",
    "ax = plt.axes()\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ax = plt.axes()\n",
    "plt.xlim(150,300)\n",
    "plt.ylim(0.133,0.1350)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all=df_all.drop(columns=features_to_drop)\n",
    "#df_all=df_all.drop(columns=fi.feature[150:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n",
    "# split Validational/Test set from Training set after Categorical Value Engeneering\n",
    "X_test=df_all.iloc[ntrain:] # Test set\n",
    "X_train_full=df_all.iloc[:ntrain] # Train set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['TotalSF'] = df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Sizes_Total']=df_all['GrLivArea']+df_all['GarageCars']+df_all['GarageArea']+df_all['TotalBsmtSF']+df_all['1stFlrSF']+df_all['2ndFlrSF']+df_all['OpenPorchSF']+df_all['MasVnrArea']\n",
    "df_all['Quantity_Total']=df_all['Fireplaces']+df_all['FullBath']+df_all['KitchenAbvGr']+df_all['TotRmsAbvGrd']+df_all['BedroomAbvGr']+df_all['BsmtFullBath']\n",
    "df_all['Age_Build']=df_all['YrSold']-df_all['YearBuilt']\n",
    "df_all['Age_Remod']=df_all['YrSold']-df_all['YearRemodAdd']\n",
    "\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "%time m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real 0.14114 and after full stackNet 0.123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Self made and experiment Evaluation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation of simple Random Forest\n",
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "#print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "math.sqrt(mean_squared_error(y_valid, m.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if you need to evaluate LOG Root mean squared error but wouldn't like to convert y to log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "math.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(m.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dealing with Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### -> To delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"#check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(df_train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(df_test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = df_train['Id']\n",
    "test_ID = df_test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "df_train.drop(\"Id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(df_train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(df_test.shape))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(df_train.corr())\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(df_train.corr(), ax=axs[0], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "sns.heatmap(df_test.corr(), ax=axs[1], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='x', labelsize=14)\n",
    "    axs[i].tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "axs[0].set_title('Training Set Correlations', size=15)\n",
    "axs[1].set_title('Test Set Correlations', size=15)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_corr=df_train.corr().sort_values(kind=\"quicksort\", ascending=False, by='SalePrice').abs()\n",
    "df_corr.drop(axis=1, columns=df_corr.columns.drop('SalePrice'), inplace=True)\n",
    "df_corr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"numeric_feats = df_all.dtypes[df_all.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = df_all[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    df_all[feat] = boxcox1p(df_all[feat], lam)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalization, the Sigmoid, Log, Cube Root and the Hyperbolic Tangent. \n",
    "#It all depends on what one is trying to accomplish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(df_all[c].values)) \n",
    "    df_all[c] = lbl.transform(list(df_all[c].values))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all=pd.get_dummies(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Experimenting with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_rf = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_xgb = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "# using early_stop to find out where validation scores don't improve\n",
    "m_xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "%time m_xgb.fit(X_train, y_train)\n",
    "print_score(m_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### GBDT (Gradient Boosting Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_gbdt=GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "%time m_gbdt.fit(X_train, y_train)\n",
    "print_score(m_gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing stacking from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.base import TransformerMixin,clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "n_folds=2\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train_full.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train_full.values, y_train_full, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, lasso),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(X_train_full.values, y_train_full)\n",
    "stacked_train_pred = stacked_averaged_models.predict(X_train_full.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(X_test.values))\n",
    "print(rmsle(y_train_full, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_xgb.fit(X_train_full, y_train_full)\n",
    "xgb_train_pred = m_xgb.predict(X_train_full)\n",
    "xgb_pred = np.expm1(m_xgb.predict(X_test))\n",
    "print(rmsle(y_train_full, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_rf.fit(X_train_full, y_train_full)\n",
    "rf_train_pred = m_rf.predict(X_train_full)\n",
    "rf_pred = np.expm1(m_rf.predict(X_test.values))\n",
    "print(rmsle(y_train_full, rf_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''RMSE on the entire Train data when averaging'''\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train_full,stacked_train_pred*0.7 +\n",
    "               xgb_train_pred*0.15+rf_train_pred*0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = stacked_pred*0.7 +xgb_pred*0.15+rf_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m_final_xgb = XGBRegressor(n_estimators=2000, learning_rate=0.05)\n",
    "m_final_xgb.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.expm1(m_final_xgb.predict(X_test)); y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = y_pred\n",
    "sub.to_csv('submittions/submission_26Aug19.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
