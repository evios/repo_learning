{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastaiold.structured import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../../data/house_pricing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(f'{PATH}train.csv')#, index_col='Id')\n",
    "df_test=pd.read_csv(f'{PATH}test.csv')#, index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y (target value) to Log, as stated at Kaggle Evaluation page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the purpose of evaluation of current competition\n",
    "#df_train.SalePrice = np.log1p(df_train.SalePrice)\n",
    "df_train.SalePrice = np.log1p(df_train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 1460\n",
      "Number of Test Examples = 1459\n",
      "\n",
      "Training X Shape = (1460, 81)\n",
      "Training y Shape = 1460\n",
      "\n",
      "Test X Shape = (1459, 80)\n",
      "Test y Shape = 1459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['SalePrice'].shape[0]))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "#print(df_train.columns)\n",
    "#print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_train.info())\n",
    "#df_train.sample(3)\n",
    "#print(df_test.info())\n",
    "#df_test.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> To delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting outliers\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n",
    "\n",
    "#Check the graphic again\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_train['GrLivArea'], df_train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations with Target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size before dropping Id feature is : (1460, 81) \n",
      "The test data size before dropping Id feature is : (1459, 80) \n",
      "\n",
      "The train data size after dropping Id feature is : (1460, 80) \n",
      "The test data size after dropping Id feature is : (1459, 79) \n"
     ]
    }
   ],
   "source": [
    "#check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(df_train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(df_test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = df_train['Id']\n",
    "test_ID = df_test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "df_train.drop(\"Id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(df_train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(df_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(df_train.corr())\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(df_train.corr(), ax=axs[0], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "sns.heatmap(df_test.corr(), ax=axs[1], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='x', labelsize=14)\n",
    "    axs[i].tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "axs[0].set_title('Training Set Correlations', size=15)\n",
    "axs[1].set_title('Test Set Correlations', size=15)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df_train.corr().sort_values(kind=\"quicksort\", ascending=False, by='SalePrice').abs()\n",
    "df_corr.drop(axis=1, columns=df_corr.columns.drop('SalePrice'), inplace=True)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set on axis 0\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember where to divide train and test\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing Target column (Y)\n",
    "y_train = df_train.SalePrice.values\n",
    "df_all.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "MSSubClass 0\n",
      "MSZoning 0\n",
      "LotFrontage 259\n",
      "LotArea 0\n",
      "Street 0\n",
      "Alley 1369\n",
      "LotShape 0\n",
      "LandContour 0\n",
      "Utilities 0\n",
      "LotConfig 0\n",
      "LandSlope 0\n",
      "Neighborhood 0\n",
      "Condition1 0\n",
      "Condition2 0\n",
      "BldgType 0\n",
      "HouseStyle 0\n",
      "OverallQual 0\n",
      "OverallCond 0\n",
      "YearBuilt 0\n",
      "YearRemodAdd 0\n",
      "RoofStyle 0\n",
      "RoofMatl 0\n",
      "Exterior1st 0\n",
      "Exterior2nd 0\n",
      "MasVnrType 8\n",
      "MasVnrArea 8\n",
      "ExterQual 0\n",
      "ExterCond 0\n",
      "Foundation 0\n",
      "BsmtQual 37\n",
      "BsmtCond 37\n",
      "BsmtExposure 38\n",
      "BsmtFinType1 37\n",
      "BsmtFinSF1 0\n",
      "BsmtFinType2 38\n",
      "BsmtFinSF2 0\n",
      "BsmtUnfSF 0\n",
      "TotalBsmtSF 0\n",
      "Heating 0\n",
      "HeatingQC 0\n",
      "CentralAir 0\n",
      "Electrical 1\n",
      "1stFlrSF 0\n",
      "2ndFlrSF 0\n",
      "LowQualFinSF 0\n",
      "GrLivArea 0\n",
      "BsmtFullBath 0\n",
      "BsmtHalfBath 0\n",
      "FullBath 0\n",
      "HalfBath 0\n",
      "BedroomAbvGr 0\n",
      "KitchenAbvGr 0\n",
      "KitchenQual 0\n",
      "TotRmsAbvGrd 0\n",
      "Functional 0\n",
      "Fireplaces 0\n",
      "FireplaceQu 690\n",
      "GarageType 81\n",
      "GarageYrBlt 81\n",
      "GarageFinish 81\n",
      "GarageCars 0\n",
      "GarageArea 0\n",
      "GarageQual 81\n",
      "GarageCond 81\n",
      "PavedDrive 0\n",
      "WoodDeckSF 0\n",
      "OpenPorchSF 0\n",
      "EnclosedPorch 0\n",
      "3SsnPorch 0\n",
      "ScreenPorch 0\n",
      "PoolArea 0\n",
      "PoolQC 1453\n",
      "Fence 1179\n",
      "MiscFeature 1406\n",
      "MiscVal 0\n",
      "MoSold 0\n",
      "YrSold 0\n",
      "SaleType 0\n",
      "SaleCondition 0\n",
      "SalePrice 0\n",
      "\n",
      "\n",
      "Test Set\n",
      "MSSubClass 0\n",
      "MSZoning 4\n",
      "LotFrontage 227\n",
      "LotArea 0\n",
      "Street 0\n",
      "Alley 1352\n",
      "LotShape 0\n",
      "LandContour 0\n",
      "Utilities 2\n",
      "LotConfig 0\n",
      "LandSlope 0\n",
      "Neighborhood 0\n",
      "Condition1 0\n",
      "Condition2 0\n",
      "BldgType 0\n",
      "HouseStyle 0\n",
      "OverallQual 0\n",
      "OverallCond 0\n",
      "YearBuilt 0\n",
      "YearRemodAdd 0\n",
      "RoofStyle 0\n",
      "RoofMatl 0\n",
      "Exterior1st 1\n",
      "Exterior2nd 1\n",
      "MasVnrType 16\n",
      "MasVnrArea 15\n",
      "ExterQual 0\n",
      "ExterCond 0\n",
      "Foundation 0\n",
      "BsmtQual 44\n",
      "BsmtCond 45\n",
      "BsmtExposure 44\n",
      "BsmtFinType1 42\n",
      "BsmtFinSF1 1\n",
      "BsmtFinType2 42\n",
      "BsmtFinSF2 1\n",
      "BsmtUnfSF 1\n",
      "TotalBsmtSF 1\n",
      "Heating 0\n",
      "HeatingQC 0\n",
      "CentralAir 0\n",
      "Electrical 0\n",
      "1stFlrSF 0\n",
      "2ndFlrSF 0\n",
      "LowQualFinSF 0\n",
      "GrLivArea 0\n",
      "BsmtFullBath 2\n",
      "BsmtHalfBath 2\n",
      "FullBath 0\n",
      "HalfBath 0\n",
      "BedroomAbvGr 0\n",
      "KitchenAbvGr 0\n",
      "KitchenQual 1\n",
      "TotRmsAbvGrd 0\n",
      "Functional 2\n",
      "Fireplaces 0\n",
      "FireplaceQu 730\n",
      "GarageType 76\n",
      "GarageYrBlt 78\n",
      "GarageFinish 78\n",
      "GarageCars 1\n",
      "GarageArea 1\n",
      "GarageQual 78\n",
      "GarageCond 78\n",
      "PavedDrive 0\n",
      "WoodDeckSF 0\n",
      "OpenPorchSF 0\n",
      "EnclosedPorch 0\n",
      "3SsnPorch 0\n",
      "ScreenPorch 0\n",
      "PoolArea 0\n",
      "PoolQC 1456\n",
      "Fence 1169\n",
      "MiscFeature 1408\n",
      "MiscVal 0\n",
      "MoSold 0\n",
      "YrSold 0\n",
      "SaleType 1\n",
      "SaleCondition 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_missing(df):\n",
    "    for col in df.columns:\n",
    "        print(col, df[col].isnull().sum())\n",
    "    print('\\n')\n",
    "    \n",
    "for df in dfs:\n",
    "    print(format(df.name))\n",
    "    display_missing(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Check remaining missing values if any \n",
    "def display_only_missing(df):\n",
    "    all_data_na = (df.isnull().sum() / len(df)) * 100\n",
    "    all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "    print(missing_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Dealing with missing values\n",
    "to improve in future - may be not median of overall but \n",
    "Missing values in 'LotFrontage' feature are filled with the median LotFrontage, but using the median age of the whole data set is not a good choice. Median age of a group is much better because the new values would be more informative. Median age of Pclass groups is the best choice because of its high correlation with Age (0.408106) and Survived (0.338481) features\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# change NA values in test set - to median\\ndef nan_to_mean(df):\\n    for col in df.columns:\\n        if is_numeric_dtype(col):\\n            df[col].fillna(value=df[col].median(), inplace=True)\\n            print(col, df[col].median())\\n            \\n#nan_to_mean(df_all)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# change NA values in test set - to median\n",
    "def nan_to_mean(df):\n",
    "    for col in df.columns:\n",
    "        if is_numeric_dtype(col):\n",
    "            df[col].fillna(value=df[col].median(), inplace=True)\n",
    "            print(col, df[col].median())\n",
    "            \n",
    "#nan_to_mean(df_all)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill value with None - based on data description -  - for non-Numerical (object) Columns\n",
    "for col in ('PoolQC','MiscFeature','Alley','Fence','FireplaceQu','GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType','MSSubClass'):\n",
    "    df_all[col] = df_all[col].fillna('None')\n",
    "    \n",
    "#fill value with '0' - based on data description - for Numerical Columns\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath','MasVnrArea'):\n",
    "    df_all[col] = df_all[col].fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, \\\n",
    "# this feature won't help in predictive modelling. We can then safely remove it.\n",
    "df_all = df_all.drop(['Utilities'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "SalePrice        49.982871\n",
      "LotFrontage      16.649538\n",
      "MSZoning          0.137033\n",
      "Functional        0.068517\n",
      "SaleType          0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# !for the begining I use just median of whole Dataset!\n",
    "\n",
    "### -> in future try to use grouped median by neighborhood\n",
    "LotFrontage : Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood.\n",
    "#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "df_all[\"LotFrontage\"] = df_all.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\"\"\"\n",
    "\n",
    "df_all['LotFrontage'].fillna(value=df_all['LotFrontage'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['LotFrontage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Ratio\n",
      "SalePrice        49.982871\n",
      "MSZoning          0.137033\n",
      "Functional        0.068517\n",
      "SaleType          0.034258\n",
      "KitchenQual       0.034258\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RL\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find most frequent value for MSZoning\n",
    "df_all.MSZoning.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing value in corresponding columns with most frequent value in column\n",
    "for col in ('MSZoning','Electrical','KitchenQual','Exterior1st','Exterior2nd','SaleType'):\n",
    "    df_all[col]=df_all[col].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Missing Ratio\n",
      "SalePrice       49.982871\n",
      "Functional       0.068517\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Typ\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.Functional.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional : data description says NA means typical\n",
    "# BTW we can just use df_all.Functional.mode() = use most frequent value (as 'Typ' is most frequent value)\n",
    "df_all[\"Functional\"] = df_all[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Missing Ratio\n",
      "SalePrice      49.982871\n"
     ]
    }
   ],
   "source": [
    "display_only_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2919 entries, 0 to 2918\n",
      "Data columns (total 79 columns):\n",
      "1stFlrSF         2919 non-null int64\n",
      "2ndFlrSF         2919 non-null int64\n",
      "3SsnPorch        2919 non-null int64\n",
      "Alley            2919 non-null object\n",
      "BedroomAbvGr     2919 non-null int64\n",
      "BldgType         2919 non-null object\n",
      "BsmtCond         2919 non-null object\n",
      "BsmtExposure     2919 non-null object\n",
      "BsmtFinSF1       2919 non-null float64\n",
      "BsmtFinSF2       2919 non-null float64\n",
      "BsmtFinType1     2919 non-null object\n",
      "BsmtFinType2     2919 non-null object\n",
      "BsmtFullBath     2919 non-null float64\n",
      "BsmtHalfBath     2919 non-null float64\n",
      "BsmtQual         2919 non-null object\n",
      "BsmtUnfSF        2919 non-null float64\n",
      "CentralAir       2919 non-null object\n",
      "Condition1       2919 non-null object\n",
      "Condition2       2919 non-null object\n",
      "Electrical       2919 non-null object\n",
      "EnclosedPorch    2919 non-null int64\n",
      "ExterCond        2919 non-null object\n",
      "ExterQual        2919 non-null object\n",
      "Exterior1st      2919 non-null object\n",
      "Exterior2nd      2919 non-null object\n",
      "Fence            2919 non-null object\n",
      "FireplaceQu      2919 non-null object\n",
      "Fireplaces       2919 non-null int64\n",
      "Foundation       2919 non-null object\n",
      "FullBath         2919 non-null int64\n",
      "Functional       2919 non-null object\n",
      "GarageArea       2919 non-null float64\n",
      "GarageCars       2919 non-null float64\n",
      "GarageCond       2919 non-null object\n",
      "GarageFinish     2919 non-null object\n",
      "GarageQual       2919 non-null object\n",
      "GarageType       2919 non-null object\n",
      "GarageYrBlt      2919 non-null float64\n",
      "GrLivArea        2919 non-null int64\n",
      "HalfBath         2919 non-null int64\n",
      "Heating          2919 non-null object\n",
      "HeatingQC        2919 non-null object\n",
      "HouseStyle       2919 non-null object\n",
      "KitchenAbvGr     2919 non-null int64\n",
      "KitchenQual      2919 non-null object\n",
      "LandContour      2919 non-null object\n",
      "LandSlope        2919 non-null object\n",
      "LotArea          2919 non-null int64\n",
      "LotConfig        2919 non-null object\n",
      "LotFrontage      2919 non-null float64\n",
      "LotShape         2919 non-null object\n",
      "LowQualFinSF     2919 non-null int64\n",
      "MSSubClass       2919 non-null int64\n",
      "MSZoning         2919 non-null object\n",
      "MasVnrArea       2919 non-null float64\n",
      "MasVnrType       2919 non-null object\n",
      "MiscFeature      2919 non-null object\n",
      "MiscVal          2919 non-null int64\n",
      "MoSold           2919 non-null int64\n",
      "Neighborhood     2919 non-null object\n",
      "OpenPorchSF      2919 non-null int64\n",
      "OverallCond      2919 non-null int64\n",
      "OverallQual      2919 non-null int64\n",
      "PavedDrive       2919 non-null object\n",
      "PoolArea         2919 non-null int64\n",
      "PoolQC           2919 non-null object\n",
      "RoofMatl         2919 non-null object\n",
      "RoofStyle        2919 non-null object\n",
      "SaleCondition    2919 non-null object\n",
      "SalePrice        1460 non-null float64\n",
      "SaleType         2919 non-null object\n",
      "ScreenPorch      2919 non-null int64\n",
      "Street           2919 non-null object\n",
      "TotRmsAbvGrd     2919 non-null int64\n",
      "TotalBsmtSF      2919 non-null float64\n",
      "WoodDeckSF       2919 non-null int64\n",
      "YearBuilt        2919 non-null int64\n",
      "YearRemodAdd     2919 non-null int64\n",
      "YrSold           2919 non-null int64\n",
      "dtypes: float64(12), int64(25), object(42)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems no missed values, except SalePrice from Test DataSet\n",
    "Missing Values = DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley\n",
      "BldgType\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "BsmtQual\n",
      "CentralAir\n",
      "Condition1\n",
      "Condition2\n",
      "Electrical\n",
      "ExterCond\n",
      "ExterQual\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "Fence\n",
      "FireplaceQu\n",
      "Foundation\n",
      "Functional\n",
      "GarageCond\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageType\n",
      "Heating\n",
      "HeatingQC\n",
      "HouseStyle\n",
      "KitchenQual\n",
      "LandContour\n",
      "LandSlope\n",
      "LotConfig\n",
      "LotShape\n",
      "MSSubClass\n",
      "MSZoning\n",
      "MasVnrType\n",
      "MiscFeature\n",
      "MoSold\n",
      "Neighborhood\n",
      "OverallCond\n",
      "PavedDrive\n",
      "PoolQC\n",
      "RoofMatl\n",
      "RoofStyle\n",
      "SaleCondition\n",
      "SaleType\n",
      "Street\n",
      "YrSold\n"
     ]
    }
   ],
   "source": [
    "def show_object_columns(df):\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            print(col)\n",
    "show_object_columns(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming some numerical variables that are really categorical\n",
    "\n",
    "#MSSubClass=The building class\n",
    "df_all['MSSubClass'] = df_all['MSSubClass'].astype(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "df_all['OverallCond'] = df_all['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "df_all['YrSold'] = df_all['YrSold'].astype(str)\n",
    "df_all['MoSold'] = df_all['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2919 entries, 0 to 2918\n",
      "Data columns (total 79 columns):\n",
      "1stFlrSF         2919 non-null int64\n",
      "2ndFlrSF         2919 non-null int64\n",
      "3SsnPorch        2919 non-null int64\n",
      "Alley            2919 non-null object\n",
      "BedroomAbvGr     2919 non-null int64\n",
      "BldgType         2919 non-null object\n",
      "BsmtCond         2919 non-null object\n",
      "BsmtExposure     2919 non-null object\n",
      "BsmtFinSF1       2919 non-null float64\n",
      "BsmtFinSF2       2919 non-null float64\n",
      "BsmtFinType1     2919 non-null object\n",
      "BsmtFinType2     2919 non-null object\n",
      "BsmtFullBath     2919 non-null float64\n",
      "BsmtHalfBath     2919 non-null float64\n",
      "BsmtQual         2919 non-null object\n",
      "BsmtUnfSF        2919 non-null float64\n",
      "CentralAir       2919 non-null object\n",
      "Condition1       2919 non-null object\n",
      "Condition2       2919 non-null object\n",
      "Electrical       2919 non-null object\n",
      "EnclosedPorch    2919 non-null int64\n",
      "ExterCond        2919 non-null object\n",
      "ExterQual        2919 non-null object\n",
      "Exterior1st      2919 non-null object\n",
      "Exterior2nd      2919 non-null object\n",
      "Fence            2919 non-null object\n",
      "FireplaceQu      2919 non-null object\n",
      "Fireplaces       2919 non-null int64\n",
      "Foundation       2919 non-null object\n",
      "FullBath         2919 non-null int64\n",
      "Functional       2919 non-null object\n",
      "GarageArea       2919 non-null float64\n",
      "GarageCars       2919 non-null float64\n",
      "GarageCond       2919 non-null object\n",
      "GarageFinish     2919 non-null object\n",
      "GarageQual       2919 non-null object\n",
      "GarageType       2919 non-null object\n",
      "GarageYrBlt      2919 non-null float64\n",
      "GrLivArea        2919 non-null int64\n",
      "HalfBath         2919 non-null int64\n",
      "Heating          2919 non-null object\n",
      "HeatingQC        2919 non-null object\n",
      "HouseStyle       2919 non-null object\n",
      "KitchenAbvGr     2919 non-null int64\n",
      "KitchenQual      2919 non-null object\n",
      "LandContour      2919 non-null object\n",
      "LandSlope        2919 non-null object\n",
      "LotArea          2919 non-null int64\n",
      "LotConfig        2919 non-null object\n",
      "LotFrontage      2919 non-null float64\n",
      "LotShape         2919 non-null object\n",
      "LowQualFinSF     2919 non-null int64\n",
      "MSSubClass       2919 non-null object\n",
      "MSZoning         2919 non-null object\n",
      "MasVnrArea       2919 non-null float64\n",
      "MasVnrType       2919 non-null object\n",
      "MiscFeature      2919 non-null object\n",
      "MiscVal          2919 non-null int64\n",
      "MoSold           2919 non-null object\n",
      "Neighborhood     2919 non-null object\n",
      "OpenPorchSF      2919 non-null int64\n",
      "OverallCond      2919 non-null object\n",
      "OverallQual      2919 non-null int64\n",
      "PavedDrive       2919 non-null object\n",
      "PoolArea         2919 non-null int64\n",
      "PoolQC           2919 non-null object\n",
      "RoofMatl         2919 non-null object\n",
      "RoofStyle        2919 non-null object\n",
      "SaleCondition    2919 non-null object\n",
      "SalePrice        1460 non-null float64\n",
      "SaleType         2919 non-null object\n",
      "ScreenPorch      2919 non-null int64\n",
      "Street           2919 non-null object\n",
      "TotRmsAbvGrd     2919 non-null int64\n",
      "TotalBsmtSF      2919 non-null float64\n",
      "WoodDeckSF       2919 non-null int64\n",
      "YearBuilt        2919 non-null int64\n",
      "YearRemodAdd     2919 non-null int64\n",
      "YrSold           2919 non-null object\n",
      "dtypes: float64(12), int64(21), object(46)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cats(df):\n",
    "    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n",
    "    categorical values. This applies the changes inplace.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values.\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "    note the type of col2 is string\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "    now the type of col2 is category\n",
    "    \"\"\"\n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_cats(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object columns to categorical\n",
    "def conv_obj_to_categories(df):\n",
    "    \"\"\"\n",
    "    Convert Object columns to Categorical\n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_string_dtype(df[col]):\n",
    "            df[col]=df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_obj_to_categories(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_categorical_columns(df):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Number, Name and Codes of unique values in corresponding column \n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            print(sum(np.unique(df[col].cat.categories,return_counts=True)[1]), col ,df[col].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Alley Index(['Grvl', 'None', 'Pave'], dtype='object')\n",
      "5 BldgType Index(['1Fam', '2fmCon', 'Duplex', 'Twnhs', 'TwnhsE'], dtype='object')\n",
      "5 BsmtCond Index(['Fa', 'Gd', 'None', 'Po', 'TA'], dtype='object')\n",
      "5 BsmtExposure Index(['Av', 'Gd', 'Mn', 'No', 'None'], dtype='object')\n",
      "7 BsmtFinType1 Index(['ALQ', 'BLQ', 'GLQ', 'LwQ', 'None', 'Rec', 'Unf'], dtype='object')\n",
      "7 BsmtFinType2 Index(['ALQ', 'BLQ', 'GLQ', 'LwQ', 'None', 'Rec', 'Unf'], dtype='object')\n",
      "5 BsmtQual Index(['Ex', 'Fa', 'Gd', 'None', 'TA'], dtype='object')\n",
      "2 CentralAir Index(['N', 'Y'], dtype='object')\n",
      "9 Condition1 Index(['Artery', 'Feedr', 'Norm', 'PosA', 'PosN', 'RRAe', 'RRAn', 'RRNe',\n",
      "       'RRNn'],\n",
      "      dtype='object')\n",
      "8 Condition2 Index(['Artery', 'Feedr', 'Norm', 'PosA', 'PosN', 'RRAe', 'RRAn', 'RRNn'], dtype='object')\n",
      "1 Electrical Index(['SBrkr'], dtype='object')\n",
      "5 ExterCond Index(['Ex', 'Fa', 'Gd', 'Po', 'TA'], dtype='object')\n",
      "4 ExterQual Index(['Ex', 'Fa', 'Gd', 'TA'], dtype='object')\n",
      "1 Exterior1st Index(['VinylSd'], dtype='object')\n",
      "1 Exterior2nd Index(['VinylSd'], dtype='object')\n",
      "5 Fence Index(['GdPrv', 'GdWo', 'MnPrv', 'MnWw', 'None'], dtype='object')\n",
      "6 FireplaceQu Index(['Ex', 'Fa', 'Gd', 'None', 'Po', 'TA'], dtype='object')\n",
      "6 Foundation Index(['BrkTil', 'CBlock', 'PConc', 'Slab', 'Stone', 'Wood'], dtype='object')\n",
      "7 Functional Index(['Maj1', 'Maj2', 'Min1', 'Min2', 'Mod', 'Sev', 'Typ'], dtype='object')\n",
      "6 GarageCond Index(['Ex', 'Fa', 'Gd', 'None', 'Po', 'TA'], dtype='object')\n",
      "4 GarageFinish Index(['Fin', 'None', 'RFn', 'Unf'], dtype='object')\n",
      "6 GarageQual Index(['Ex', 'Fa', 'Gd', 'None', 'Po', 'TA'], dtype='object')\n",
      "7 GarageType Index(['2Types', 'Attchd', 'Basment', 'BuiltIn', 'CarPort', 'Detchd', 'None'], dtype='object')\n",
      "6 Heating Index(['Floor', 'GasA', 'GasW', 'Grav', 'OthW', 'Wall'], dtype='object')\n",
      "5 HeatingQC Index(['Ex', 'Fa', 'Gd', 'Po', 'TA'], dtype='object')\n",
      "8 HouseStyle Index(['1.5Fin', '1.5Unf', '1Story', '2.5Fin', '2.5Unf', '2Story', 'SFoyer',\n",
      "       'SLvl'],\n",
      "      dtype='object')\n",
      "1 KitchenQual Index(['TA'], dtype='object')\n",
      "4 LandContour Index(['Bnk', 'HLS', 'Low', 'Lvl'], dtype='object')\n",
      "3 LandSlope Index(['Gtl', 'Mod', 'Sev'], dtype='object')\n",
      "5 LotConfig Index(['Corner', 'CulDSac', 'FR2', 'FR3', 'Inside'], dtype='object')\n",
      "4 LotShape Index(['IR1', 'IR2', 'IR3', 'Reg'], dtype='object')\n",
      "16 MSSubClass Index(['120', '150', '160', '180', '190', '20', '30', '40', '45', '50', '60',\n",
      "       '70', '75', '80', '85', '90'],\n",
      "      dtype='object')\n",
      "1 MSZoning Index(['RL'], dtype='object')\n",
      "4 MasVnrType Index(['BrkCmn', 'BrkFace', 'None', 'Stone'], dtype='object')\n",
      "5 MiscFeature Index(['Gar2', 'None', 'Othr', 'Shed', 'TenC'], dtype='object')\n",
      "12 MoSold Index(['1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "25 Neighborhood Index(['Blmngtn', 'Blueste', 'BrDale', 'BrkSide', 'ClearCr', 'CollgCr',\n",
      "       'Crawfor', 'Edwards', 'Gilbert', 'IDOTRR', 'MeadowV', 'Mitchel',\n",
      "       'NAmes', 'NPkVill', 'NWAmes', 'NoRidge', 'NridgHt', 'OldTown', 'SWISU',\n",
      "       'Sawyer', 'SawyerW', 'Somerst', 'StoneBr', 'Timber', 'Veenker'],\n",
      "      dtype='object')\n",
      "9 OverallCond Index(['1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='object')\n",
      "3 PavedDrive Index(['N', 'P', 'Y'], dtype='object')\n",
      "4 PoolQC Index(['Ex', 'Fa', 'Gd', 'None'], dtype='object')\n",
      "8 RoofMatl Index(['ClyTile', 'CompShg', 'Membran', 'Metal', 'Roll', 'Tar&Grv', 'WdShake',\n",
      "       'WdShngl'],\n",
      "      dtype='object')\n",
      "6 RoofStyle Index(['Flat', 'Gable', 'Gambrel', 'Hip', 'Mansard', 'Shed'], dtype='object')\n",
      "6 SaleCondition Index(['Abnorml', 'AdjLand', 'Alloca', 'Family', 'Normal', 'Partial'], dtype='object')\n",
      "1 SaleType Index(['WD'], dtype='object')\n",
      "2 Street Index(['Grvl', 'Pave'], dtype='object')\n",
      "5 YrSold Index(['2006', '2007', '2008', '2009', '2010'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "show_categorical_columns(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#for col in df_all.columns:\n",
    "#    if is_categorical_dtype(col):\n",
    "#        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(df_all[c].values)) \n",
    "    df_all[c] = lbl.transform(list(df_all[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(df_all.shape))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley 3\n",
      "BldgType 5\n",
      "BsmtCond 5\n",
      "BsmtExposure 5\n",
      "BsmtFinType1 7\n",
      "BsmtFinType2 7\n",
      "BsmtQual 5\n",
      "CentralAir 2\n",
      "Condition1 9\n",
      "Condition2 8\n",
      "Electrical 1\n",
      "ExterCond 5\n",
      "ExterQual 4\n",
      "Exterior1st 1\n",
      "Exterior2nd 1\n",
      "Fence 5\n",
      "FireplaceQu 6\n",
      "Foundation 6\n",
      "Functional 7\n",
      "GarageCond 6\n",
      "GarageFinish 4\n",
      "GarageQual 6\n",
      "GarageType 7\n",
      "Heating 6\n",
      "HeatingQC 5\n",
      "HouseStyle 8\n",
      "KitchenQual 1\n",
      "LandContour 4\n",
      "LandSlope 3\n",
      "LotConfig 5\n",
      "LotShape 4\n",
      "MSSubClass 16\n",
      "MSZoning 1\n",
      "MasVnrType 4\n",
      "MiscFeature 5\n",
      "MoSold 12\n",
      "Neighborhood 25\n",
      "OverallCond 9\n",
      "PavedDrive 3\n",
      "PoolQC 4\n",
      "RoofMatl 8\n",
      "RoofStyle 6\n",
      "SaleCondition 6\n",
      "SaleType 1\n",
      "Street 2\n",
      "YrSold 5\n"
     ]
    }
   ],
   "source": [
    "def unique_categories(df):\n",
    "    \"\"\"\n",
    "    Print only categorical columns Names and Number of unique values in corresponding column \n",
    "    \"\"\"\n",
    "    for col in df:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            print(col, sum(np.unique(df[col].cat.categories,return_counts=True)[1]))\n",
    "unique_categories(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=pd.get_dummies(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization, the Sigmoid, Log, Cube Root and the Hyperbolic Tangent. \n",
    "#It all depends on what one is trying to accomplish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dividing working DataFrame back to Train and Test\"\"\"\n",
    "# split Validational/Test set from Training set after Categorical Value Engeneering\n",
    "X_valid_testset=df_all.iloc[ntrain:] # Test set\n",
    "X_train=df_all.iloc[:ntrain] # Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1459, 79), (1460,), (1459, 291), (1460, 291))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, y_train.shape, X_valid_testset.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 291), (365, 291))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 268 ms, sys: 4.4 ms, total: 273 ms\n",
      "Wall time: 214 ms\n",
      "[0.012097015715977669, 0.012182697874411728, 0.9990805832488423, 0.9990661634406787]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of simple Random Forest\n",
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012182697874411572"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "math.sqrt(mean_squared_error(y_valid, m.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to evaluate LOG Root mean squared error but wouldn't like to convert y to log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010642917135558443"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(m.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.010537460345837978, 0.010642917135558327, 0.9993023656937409, 0.9992873024170605]\n"
     ]
    }
   ],
   "source": [
    "y_pred = m.predict(X_valid)\n",
    "\n",
    "#mean_squared_error(y_valid, y_pred)\n",
    "#def rmse1(y, y_pred):\n",
    "#    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "#rmse1 (y_valid, y_pred)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013316339347677002, 0.03140497004908063, 0.9988858962647397, 0.9937944441098655, 0.9918014177704907]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True, )\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def print_score_robustscaler(m):\n",
    "    res = [rmse(m.predict(Xtr_r), y_train), rmse(m.predict(Xte_r), y_valid),\n",
    "                m.score(Xtr_r, y_train), m.score(Xte_r, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)\n",
    "    \n",
    "robust_scaler = RobustScaler()\n",
    "#Xtr_r = robust_scaler.fit_transform(X_train)\n",
    "Xtr_r = robust_scaler.fit_transform(X_train)\n",
    "Xte_r = robust_scaler.transform(X_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0145743508260406, 0.032239174237771756, 0.9986654515010421, 0.9934603915976654, 0.9907117485975234]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=160, min_samples_leaf=1, max_features=0.5, n_jobs=-1, oob_score=True, )\n",
    "m.fit(Xtr_r, y_train)\n",
    "print_score_robustscaler(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of XGboost\n",
    "from xgboost import XGBRegressor\n",
    "import re\n",
    "\n",
    "#from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "#import xgboost as xgb\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "X_train.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train.columns.values]\n",
    "X_valid.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_valid.columns.values]\n",
    "\n",
    "\n",
    "\n",
    "m = XGBRegressor()\n",
    "#%time m.fit(X_train, y_train)\n",
    "#print_score(m)\n",
    "m.fit(Xtr_r, y_train)\n",
    "print_score_robustscaler(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Lasso(alpha =0.0005, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "#import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking models\n",
    "Simplest Stacking approach : Averaging base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)  \n",
    "\n",
    "#averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n",
    "averaged_models = AveragingModels(models = (ENet, GBoost, lasso))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less simple Stacking : Adding a Meta-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rmsle(y, y_pred):\n",
    "#    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked_averaged_models.fit(train.values, y_train)\n",
    "#stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "#stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "#print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all ,[] symbols from dataframe columns and values\n",
    "X_valid_testset.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_valid_testset.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = m.predict(X_valid_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBoost.fit(X_train, y_train)\n",
    "#y_pred = np.expm1(GBoost.predict(X_valid_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'averaged_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-f6a68861d438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maveraged_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maveraged_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_testset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'averaged_models' is not defined"
     ]
    }
   ],
   "source": [
    "#averaged_models.fit(X_train, y_train)\n",
    "#y_pred = np.expm1(averaged_models.predict(X_valid_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-c4470db41651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_testset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "y_pred = np.expm1(m.predict(X_valid_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = y_pred\n",
    "sub.to_csv('submission_03Aug19.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
